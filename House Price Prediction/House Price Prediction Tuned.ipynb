{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Data Science Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "holdout = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
       "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
       "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
       "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
       "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
       "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0       0      6    2010        WD         Normal  \n",
       "1   12500      6    2010        WD         Normal  \n",
       "2       0      3    2010        WD         Normal  \n",
       "3       0      6    2010        WD         Normal  \n",
       "4       0      1    2010        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels= False, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(holdout.isnull(),yticklabels= False, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_count_df = len(df)/2\n",
    "df = df.dropna(thresh=half_count_df,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_count_test = len(holdout)/2\n",
    "holdout = holdout.dropna(thresh=half_count_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 77 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   LotShape       1460 non-null   object \n",
      " 7   LandContour    1460 non-null   object \n",
      " 8   Utilities      1460 non-null   object \n",
      " 9   LotConfig      1460 non-null   object \n",
      " 10  LandSlope      1460 non-null   object \n",
      " 11  Neighborhood   1460 non-null   object \n",
      " 12  Condition1     1460 non-null   object \n",
      " 13  Condition2     1460 non-null   object \n",
      " 14  BldgType       1460 non-null   object \n",
      " 15  HouseStyle     1460 non-null   object \n",
      " 16  OverallQual    1460 non-null   int64  \n",
      " 17  OverallCond    1460 non-null   int64  \n",
      " 18  YearBuilt      1460 non-null   int64  \n",
      " 19  YearRemodAdd   1460 non-null   int64  \n",
      " 20  RoofStyle      1460 non-null   object \n",
      " 21  RoofMatl       1460 non-null   object \n",
      " 22  Exterior1st    1460 non-null   object \n",
      " 23  Exterior2nd    1460 non-null   object \n",
      " 24  MasVnrType     1452 non-null   object \n",
      " 25  MasVnrArea     1452 non-null   float64\n",
      " 26  ExterQual      1460 non-null   object \n",
      " 27  ExterCond      1460 non-null   object \n",
      " 28  Foundation     1460 non-null   object \n",
      " 29  BsmtQual       1423 non-null   object \n",
      " 30  BsmtCond       1423 non-null   object \n",
      " 31  BsmtExposure   1422 non-null   object \n",
      " 32  BsmtFinType1   1423 non-null   object \n",
      " 33  BsmtFinSF1     1460 non-null   int64  \n",
      " 34  BsmtFinType2   1422 non-null   object \n",
      " 35  BsmtFinSF2     1460 non-null   int64  \n",
      " 36  BsmtUnfSF      1460 non-null   int64  \n",
      " 37  TotalBsmtSF    1460 non-null   int64  \n",
      " 38  Heating        1460 non-null   object \n",
      " 39  HeatingQC      1460 non-null   object \n",
      " 40  CentralAir     1460 non-null   object \n",
      " 41  Electrical     1459 non-null   object \n",
      " 42  1stFlrSF       1460 non-null   int64  \n",
      " 43  2ndFlrSF       1460 non-null   int64  \n",
      " 44  LowQualFinSF   1460 non-null   int64  \n",
      " 45  GrLivArea      1460 non-null   int64  \n",
      " 46  BsmtFullBath   1460 non-null   int64  \n",
      " 47  BsmtHalfBath   1460 non-null   int64  \n",
      " 48  FullBath       1460 non-null   int64  \n",
      " 49  HalfBath       1460 non-null   int64  \n",
      " 50  BedroomAbvGr   1460 non-null   int64  \n",
      " 51  KitchenAbvGr   1460 non-null   int64  \n",
      " 52  KitchenQual    1460 non-null   object \n",
      " 53  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 54  Functional     1460 non-null   object \n",
      " 55  Fireplaces     1460 non-null   int64  \n",
      " 56  FireplaceQu    770 non-null    object \n",
      " 57  GarageType     1379 non-null   object \n",
      " 58  GarageYrBlt    1379 non-null   float64\n",
      " 59  GarageFinish   1379 non-null   object \n",
      " 60  GarageCars     1460 non-null   int64  \n",
      " 61  GarageArea     1460 non-null   int64  \n",
      " 62  GarageQual     1379 non-null   object \n",
      " 63  GarageCond     1379 non-null   object \n",
      " 64  PavedDrive     1460 non-null   object \n",
      " 65  WoodDeckSF     1460 non-null   int64  \n",
      " 66  OpenPorchSF    1460 non-null   int64  \n",
      " 67  EnclosedPorch  1460 non-null   int64  \n",
      " 68  3SsnPorch      1460 non-null   int64  \n",
      " 69  ScreenPorch    1460 non-null   int64  \n",
      " 70  PoolArea       1460 non-null   int64  \n",
      " 71  MiscVal        1460 non-null   int64  \n",
      " 72  MoSold         1460 non-null   int64  \n",
      " 73  YrSold         1460 non-null   int64  \n",
      " 74  SaleType       1460 non-null   object \n",
      " 75  SaleCondition  1460 non-null   object \n",
      " 76  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(39)\n",
      "memory usage: 878.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels= False, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(holdout.isnull(),yticklabels= False, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 77 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   LotShape       1460 non-null   object \n",
      " 7   LandContour    1460 non-null   object \n",
      " 8   Utilities      1460 non-null   object \n",
      " 9   LotConfig      1460 non-null   object \n",
      " 10  LandSlope      1460 non-null   object \n",
      " 11  Neighborhood   1460 non-null   object \n",
      " 12  Condition1     1460 non-null   object \n",
      " 13  Condition2     1460 non-null   object \n",
      " 14  BldgType       1460 non-null   object \n",
      " 15  HouseStyle     1460 non-null   object \n",
      " 16  OverallQual    1460 non-null   int64  \n",
      " 17  OverallCond    1460 non-null   int64  \n",
      " 18  YearBuilt      1460 non-null   int64  \n",
      " 19  YearRemodAdd   1460 non-null   int64  \n",
      " 20  RoofStyle      1460 non-null   object \n",
      " 21  RoofMatl       1460 non-null   object \n",
      " 22  Exterior1st    1460 non-null   object \n",
      " 23  Exterior2nd    1460 non-null   object \n",
      " 24  MasVnrType     1452 non-null   object \n",
      " 25  MasVnrArea     1452 non-null   float64\n",
      " 26  ExterQual      1460 non-null   object \n",
      " 27  ExterCond      1460 non-null   object \n",
      " 28  Foundation     1460 non-null   object \n",
      " 29  BsmtQual       1423 non-null   object \n",
      " 30  BsmtCond       1423 non-null   object \n",
      " 31  BsmtExposure   1422 non-null   object \n",
      " 32  BsmtFinType1   1423 non-null   object \n",
      " 33  BsmtFinSF1     1460 non-null   int64  \n",
      " 34  BsmtFinType2   1422 non-null   object \n",
      " 35  BsmtFinSF2     1460 non-null   int64  \n",
      " 36  BsmtUnfSF      1460 non-null   int64  \n",
      " 37  TotalBsmtSF    1460 non-null   int64  \n",
      " 38  Heating        1460 non-null   object \n",
      " 39  HeatingQC      1460 non-null   object \n",
      " 40  CentralAir     1460 non-null   object \n",
      " 41  Electrical     1459 non-null   object \n",
      " 42  1stFlrSF       1460 non-null   int64  \n",
      " 43  2ndFlrSF       1460 non-null   int64  \n",
      " 44  LowQualFinSF   1460 non-null   int64  \n",
      " 45  GrLivArea      1460 non-null   int64  \n",
      " 46  BsmtFullBath   1460 non-null   int64  \n",
      " 47  BsmtHalfBath   1460 non-null   int64  \n",
      " 48  FullBath       1460 non-null   int64  \n",
      " 49  HalfBath       1460 non-null   int64  \n",
      " 50  BedroomAbvGr   1460 non-null   int64  \n",
      " 51  KitchenAbvGr   1460 non-null   int64  \n",
      " 52  KitchenQual    1460 non-null   object \n",
      " 53  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 54  Functional     1460 non-null   object \n",
      " 55  Fireplaces     1460 non-null   int64  \n",
      " 56  FireplaceQu    770 non-null    object \n",
      " 57  GarageType     1379 non-null   object \n",
      " 58  GarageYrBlt    1379 non-null   float64\n",
      " 59  GarageFinish   1379 non-null   object \n",
      " 60  GarageCars     1460 non-null   int64  \n",
      " 61  GarageArea     1460 non-null   int64  \n",
      " 62  GarageQual     1379 non-null   object \n",
      " 63  GarageCond     1379 non-null   object \n",
      " 64  PavedDrive     1460 non-null   object \n",
      " 65  WoodDeckSF     1460 non-null   int64  \n",
      " 66  OpenPorchSF    1460 non-null   int64  \n",
      " 67  EnclosedPorch  1460 non-null   int64  \n",
      " 68  3SsnPorch      1460 non-null   int64  \n",
      " 69  ScreenPorch    1460 non-null   int64  \n",
      " 70  PoolArea       1460 non-null   int64  \n",
      " 71  MiscVal        1460 non-null   int64  \n",
      " 72  MoSold         1460 non-null   int64  \n",
      " 73  YrSold         1460 non-null   int64  \n",
      " 74  SaleType       1460 non-null   object \n",
      " 75  SaleCondition  1460 non-null   object \n",
      " 76  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(39)\n",
      "memory usage: 878.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['LotFrontage']=holdout.fillna(holdout['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu'] = df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageType'] = df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageYrBlt'] = df['GarageYrBlt'].fillna(df['GarageYrBlt'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish'] = df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtQual'] = df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageQual'] = df['GarageQual'].fillna(df['GarageQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageCond'] = df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageCond'] = df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond'] = df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['BsmtQual'] = holdout['BsmtQual'].fillna(holdout['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['GarageType'] = holdout['GarageType'].fillna(holdout['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['GarageYrBlt'] = holdout['GarageYrBlt'].fillna(holdout['GarageYrBlt'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['GarageFinish'] = holdout['GarageFinish'].fillna(holdout['GarageFinish'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['GarageFinish'] = holdout['GarageFinish'].fillna(holdout['GarageFinish'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['GarageQual'] = holdout['GarageQual'].fillna(holdout['GarageQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['GarageCond'] = holdout['GarageCond'].fillna(holdout['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['GarageCond'] = holdout['GarageCond'].fillna(holdout['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['MasVnrArea'] = holdout['MasVnrArea'].fillna(holdout['MasVnrArea'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id'], axis =1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 76)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure'] = df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType1'] = df['BsmtFinType1'].fillna(df['BsmtFinType1'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType2'] = df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['BsmtCond'] = holdout['BsmtCond'].fillna(holdout['BsmtCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['BsmtExposure'] = holdout['BsmtExposure'].fillna(holdout['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['BsmtFinType1'] = holdout['BsmtFinType1'].fillna(holdout['BsmtFinType1'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['BsmtFinType2'] = holdout['BsmtFinType2'].fillna(holdout['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['Utilities']=holdout['Utilities'].fillna(holdout['Utilities'].mode()[0])\n",
    "holdout['Exterior1st']=holdout['Exterior1st'].fillna(holdout['Exterior1st'].mode()[0])\n",
    "holdout['Exterior2nd']=holdout['Exterior2nd'].fillna(holdout['Exterior2nd'].mode()[0])\n",
    "\n",
    "holdout['BsmtFinSF1']=holdout['BsmtFinSF1'].fillna(holdout['BsmtFinSF1'].mean())\n",
    "holdout['BsmtFinSF2']=holdout['BsmtFinSF2'].fillna(holdout['BsmtFinSF2'].mean())\n",
    "holdout['BsmtUnfSF']=holdout['BsmtUnfSF'].fillna(holdout['BsmtUnfSF'].mean())\n",
    "holdout['TotalBsmtSF']=holdout['TotalBsmtSF'].fillna(holdout['TotalBsmtSF'].mean())\n",
    "holdout['BsmtFullBath']=holdout['BsmtFullBath'].fillna(holdout['BsmtFullBath'].mode()[0])\n",
    "holdout['BsmtHalfBath']=holdout['BsmtHalfBath'].fillna(holdout['BsmtHalfBath'].mode()[0])\n",
    "holdout['KitchenQual']=holdout['KitchenQual'].fillna(holdout['KitchenQual'].mode()[0])\n",
    "holdout['Functional']=holdout['Functional'].fillna(holdout['Functional'].mode()[0])\n",
    "holdout['GarageCars']=holdout['GarageCars'].fillna(holdout['GarageCars'].mean())\n",
    "holdout['GarageArea']=holdout['GarageArea'].fillna(holdout['GarageArea'].mean())\n",
    "holdout['SaleType']=holdout['SaleType'].fillna(holdout['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels= False, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "holdout.to_csv('formulate_holdout.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 76)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1451 entries, 0 to 1459\n",
      "Data columns (total 76 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1451 non-null   int64  \n",
      " 1   MSZoning       1451 non-null   object \n",
      " 2   LotFrontage    1451 non-null   float64\n",
      " 3   LotArea        1451 non-null   int64  \n",
      " 4   Street         1451 non-null   object \n",
      " 5   LotShape       1451 non-null   object \n",
      " 6   LandContour    1451 non-null   object \n",
      " 7   Utilities      1451 non-null   object \n",
      " 8   LotConfig      1451 non-null   object \n",
      " 9   LandSlope      1451 non-null   object \n",
      " 10  Neighborhood   1451 non-null   object \n",
      " 11  Condition1     1451 non-null   object \n",
      " 12  Condition2     1451 non-null   object \n",
      " 13  BldgType       1451 non-null   object \n",
      " 14  HouseStyle     1451 non-null   object \n",
      " 15  OverallQual    1451 non-null   int64  \n",
      " 16  OverallCond    1451 non-null   int64  \n",
      " 17  YearBuilt      1451 non-null   int64  \n",
      " 18  YearRemodAdd   1451 non-null   int64  \n",
      " 19  RoofStyle      1451 non-null   object \n",
      " 20  RoofMatl       1451 non-null   object \n",
      " 21  Exterior1st    1451 non-null   object \n",
      " 22  Exterior2nd    1451 non-null   object \n",
      " 23  MasVnrType     1451 non-null   object \n",
      " 24  MasVnrArea     1451 non-null   float64\n",
      " 25  ExterQual      1451 non-null   object \n",
      " 26  ExterCond      1451 non-null   object \n",
      " 27  Foundation     1451 non-null   object \n",
      " 28  BsmtQual       1451 non-null   object \n",
      " 29  BsmtCond       1451 non-null   object \n",
      " 30  BsmtExposure   1451 non-null   object \n",
      " 31  BsmtFinType1   1451 non-null   object \n",
      " 32  BsmtFinSF1     1451 non-null   int64  \n",
      " 33  BsmtFinType2   1451 non-null   object \n",
      " 34  BsmtFinSF2     1451 non-null   int64  \n",
      " 35  BsmtUnfSF      1451 non-null   int64  \n",
      " 36  TotalBsmtSF    1451 non-null   int64  \n",
      " 37  Heating        1451 non-null   object \n",
      " 38  HeatingQC      1451 non-null   object \n",
      " 39  CentralAir     1451 non-null   object \n",
      " 40  Electrical     1451 non-null   object \n",
      " 41  1stFlrSF       1451 non-null   int64  \n",
      " 42  2ndFlrSF       1451 non-null   int64  \n",
      " 43  LowQualFinSF   1451 non-null   int64  \n",
      " 44  GrLivArea      1451 non-null   int64  \n",
      " 45  BsmtFullBath   1451 non-null   int64  \n",
      " 46  BsmtHalfBath   1451 non-null   int64  \n",
      " 47  FullBath       1451 non-null   int64  \n",
      " 48  HalfBath       1451 non-null   int64  \n",
      " 49  BedroomAbvGr   1451 non-null   int64  \n",
      " 50  KitchenAbvGr   1451 non-null   int64  \n",
      " 51  KitchenQual    1451 non-null   object \n",
      " 52  TotRmsAbvGrd   1451 non-null   int64  \n",
      " 53  Functional     1451 non-null   object \n",
      " 54  Fireplaces     1451 non-null   int64  \n",
      " 55  FireplaceQu    1451 non-null   object \n",
      " 56  GarageType     1451 non-null   object \n",
      " 57  GarageYrBlt    1451 non-null   float64\n",
      " 58  GarageFinish   1451 non-null   object \n",
      " 59  GarageCars     1451 non-null   int64  \n",
      " 60  GarageArea     1451 non-null   int64  \n",
      " 61  GarageQual     1451 non-null   object \n",
      " 62  GarageCond     1451 non-null   object \n",
      " 63  PavedDrive     1451 non-null   object \n",
      " 64  WoodDeckSF     1451 non-null   int64  \n",
      " 65  OpenPorchSF    1451 non-null   int64  \n",
      " 66  EnclosedPorch  1451 non-null   int64  \n",
      " 67  3SsnPorch      1451 non-null   int64  \n",
      " 68  ScreenPorch    1451 non-null   int64  \n",
      " 69  PoolArea       1451 non-null   int64  \n",
      " 70  MiscVal        1451 non-null   int64  \n",
      " 71  MoSold         1451 non-null   int64  \n",
      " 72  YrSold         1451 non-null   int64  \n",
      " 73  SaleType       1451 non-null   object \n",
      " 74  SaleCondition  1451 non-null   object \n",
      " 75  SalePrice      1451 non-null   int64  \n",
      "dtypes: float64(3), int64(34), object(39)\n",
      "memory usage: 872.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond', 'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure',\n",
    "         'BsmtFinType1','BsmtFinType2', 'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType',\n",
    "         'Heating','HeatingQC', 'CentralAir', 'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 76)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL         1145\n",
      "RM          218\n",
      "FV           62\n",
      "RH           16\n",
      "C (all)      10\n",
      "Name: MSZoning, dtype: int64\n",
      "Pave    1445\n",
      "Grvl       6\n",
      "Name: Street, dtype: int64\n",
      "Reg    918\n",
      "IR1    482\n",
      "IR2     41\n",
      "IR3     10\n",
      "Name: LotShape, dtype: int64\n",
      "Lvl    1302\n",
      "Bnk      63\n",
      "HLS      50\n",
      "Low      36\n",
      "Name: LandContour, dtype: int64\n",
      "AllPub    1450\n",
      "NoSeWa       1\n",
      "Name: Utilities, dtype: int64\n",
      "Inside     1045\n",
      "Corner      262\n",
      "CulDSac      93\n",
      "FR2          47\n",
      "FR3           4\n",
      "Name: LotConfig, dtype: int64\n",
      "Gtl    1373\n",
      "Mod      65\n",
      "Sev      13\n",
      "Name: LandSlope, dtype: int64\n",
      "NAmes      225\n",
      "CollgCr    149\n",
      "OldTown    113\n",
      "Edwards    100\n",
      "Somerst     83\n",
      "Gilbert     78\n",
      "NridgHt     76\n",
      "Sawyer      74\n",
      "NWAmes      73\n",
      "BrkSide     58\n",
      "SawyerW     58\n",
      "Crawfor     50\n",
      "Mitchel     49\n",
      "NoRidge     41\n",
      "IDOTRR      37\n",
      "Timber      37\n",
      "ClearCr     28\n",
      "StoneBr     25\n",
      "SWISU       25\n",
      "Blmngtn     17\n",
      "MeadowV     17\n",
      "BrDale      16\n",
      "Veenker     11\n",
      "NPkVill      9\n",
      "Blueste      2\n",
      "Name: Neighborhood, dtype: int64\n",
      "Norm      1436\n",
      "Feedr        6\n",
      "PosN         2\n",
      "RRNn         2\n",
      "Artery       2\n",
      "RRAn         1\n",
      "PosA         1\n",
      "RRAe         1\n",
      "Name: Condition2, dtype: int64\n",
      "1Fam      1212\n",
      "TwnhsE     113\n",
      "Duplex      52\n",
      "Twnhs       43\n",
      "2fmCon      31\n",
      "Name: BldgType, dtype: int64\n",
      "Norm      1251\n",
      "Feedr       81\n",
      "Artery      48\n",
      "RRAn        26\n",
      "PosN        19\n",
      "RRAe        11\n",
      "PosA         8\n",
      "RRNn         5\n",
      "RRNe         2\n",
      "Name: Condition1, dtype: int64\n",
      "1Story    721\n",
      "2Story    442\n",
      "1.5Fin    154\n",
      "SLvl       64\n",
      "SFoyer     37\n",
      "1.5Unf     14\n",
      "2.5Unf     11\n",
      "2.5Fin      8\n",
      "Name: HouseStyle, dtype: int64\n",
      "WD       1261\n",
      "New       119\n",
      "COD        43\n",
      "ConLD       9\n",
      "ConLI       5\n",
      "ConLw       5\n",
      "CWD         4\n",
      "Oth         3\n",
      "Con         2\n",
      "Name: SaleType, dtype: int64\n",
      "Normal     1193\n",
      "Partial     122\n",
      "Abnorml     101\n",
      "Family       20\n",
      "Alloca       11\n",
      "AdjLand       4\n",
      "Name: SaleCondition, dtype: int64\n",
      "TA    1273\n",
      "Gd     146\n",
      "Fa      28\n",
      "Ex       3\n",
      "Po       1\n",
      "Name: ExterCond, dtype: int64\n",
      "TA    905\n",
      "Gd    481\n",
      "Ex     51\n",
      "Fa     14\n",
      "Name: ExterQual, dtype: int64\n",
      "PConc     638\n",
      "CBlock    634\n",
      "BrkTil    146\n",
      "Slab       24\n",
      "Stone       6\n",
      "Wood        3\n",
      "Name: Foundation, dtype: int64\n",
      "TA    685\n",
      "Gd    611\n",
      "Ex    120\n",
      "Fa     35\n",
      "Name: BsmtQual, dtype: int64\n",
      "TA    1340\n",
      "Gd      64\n",
      "Fa      45\n",
      "Po       2\n",
      "Name: BsmtCond, dtype: int64\n",
      "No    983\n",
      "Av    221\n",
      "Gd    133\n",
      "Mn    114\n",
      "Name: BsmtExposure, dtype: int64\n",
      "Unf    464\n",
      "GLQ    413\n",
      "ALQ    220\n",
      "BLQ    148\n",
      "Rec    132\n",
      "LwQ     74\n",
      "Name: BsmtFinType1, dtype: int64\n",
      "Unf    1285\n",
      "Rec      54\n",
      "LwQ      46\n",
      "BLQ      33\n",
      "ALQ      19\n",
      "GLQ      14\n",
      "Name: BsmtFinType2, dtype: int64\n",
      "Gable      1133\n",
      "Hip         285\n",
      "Flat         13\n",
      "Gambrel      11\n",
      "Mansard       7\n",
      "Shed          2\n",
      "Name: RoofStyle, dtype: int64\n",
      "CompShg    1425\n",
      "Tar&Grv      11\n",
      "WdShngl       6\n",
      "WdShake       5\n",
      "Metal         1\n",
      "Membran       1\n",
      "Roll          1\n",
      "ClyTile       1\n",
      "Name: RoofMatl, dtype: int64\n",
      "VinylSd    509\n",
      "HdBoard    222\n",
      "MetalSd    220\n",
      "Wd Sdng    205\n",
      "Plywood    108\n",
      "CemntBd     59\n",
      "BrkFace     50\n",
      "WdShing     26\n",
      "Stucco      25\n",
      "AsbShng     20\n",
      "BrkComm      2\n",
      "Stone        2\n",
      "ImStucc      1\n",
      "CBlock       1\n",
      "AsphShn      1\n",
      "Name: Exterior1st, dtype: int64\n",
      "VinylSd    498\n",
      "MetalSd    214\n",
      "HdBoard    207\n",
      "Wd Sdng    197\n",
      "Plywood    142\n",
      "CmentBd     58\n",
      "Wd Shng     38\n",
      "Stucco      26\n",
      "BrkFace     25\n",
      "AsbShng     20\n",
      "ImStucc     10\n",
      "Brk Cmn      7\n",
      "Stone        4\n",
      "AsphShn      3\n",
      "Other        1\n",
      "CBlock       1\n",
      "Name: Exterior2nd, dtype: int64\n",
      "None       863\n",
      "BrkFace    445\n",
      "Stone      128\n",
      "BrkCmn      15\n",
      "Name: MasVnrType, dtype: int64\n",
      "GasA     1419\n",
      "GasW       18\n",
      "Grav        7\n",
      "Wall        4\n",
      "OthW        2\n",
      "Floor       1\n",
      "Name: Heating, dtype: int64\n",
      "Ex    734\n",
      "TA    427\n",
      "Gd    240\n",
      "Fa     49\n",
      "Po      1\n",
      "Name: HeatingQC, dtype: int64\n",
      "Y    1356\n",
      "N      95\n",
      "Name: CentralAir, dtype: int64\n",
      "SBrkr    1326\n",
      "FuseA      94\n",
      "FuseF      27\n",
      "FuseP       3\n",
      "Mix         1\n",
      "Name: Electrical, dtype: int64\n",
      "TA    734\n",
      "Gd    579\n",
      "Ex     99\n",
      "Fa     39\n",
      "Name: KitchenQual, dtype: int64\n",
      "Typ     1352\n",
      "Min2      34\n",
      "Min1      31\n",
      "Mod       15\n",
      "Maj1      13\n",
      "Maj2       5\n",
      "Sev        1\n",
      "Name: Functional, dtype: int64\n",
      "Gd    1063\n",
      "TA     311\n",
      "Fa      33\n",
      "Ex      24\n",
      "Po      20\n",
      "Name: FireplaceQu, dtype: int64\n",
      "Attchd     944\n",
      "Detchd     387\n",
      "BuiltIn     86\n",
      "Basment     19\n",
      "CarPort      9\n",
      "2Types       6\n",
      "Name: GarageType, dtype: int64\n",
      "Unf    686\n",
      "RFn    418\n",
      "Fin    347\n",
      "Name: GarageFinish, dtype: int64\n",
      "TA    1383\n",
      "Fa      48\n",
      "Gd      14\n",
      "Po       3\n",
      "Ex       3\n",
      "Name: GarageQual, dtype: int64\n",
      "TA    1398\n",
      "Fa      35\n",
      "Gd       9\n",
      "Po       7\n",
      "Ex       2\n",
      "Name: GarageCond, dtype: int64\n",
      "Y    1331\n",
      "N      90\n",
      "P      30\n",
      "Name: PavedDrive, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in columns:\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Combine Test Data \n",
    "\n",
    "test_df=pd.read_csv('formulate_holdout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
       "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
       "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
       "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
       "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
       "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
       "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
       "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
       "       'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt', 'GarageFinish',\n",
       "       'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive',\n",
       "       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_df.head()\n",
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500.0\n",
       "1       181500.0\n",
       "2       223500.0\n",
       "3       140000.0\n",
       "4       250000.0\n",
       "          ...   \n",
       "1454         NaN\n",
       "1455         NaN\n",
       "1456         NaN\n",
       "1457         NaN\n",
       "1458         NaN\n",
       "Name: SalePrice, Length: 2910, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2910, 76)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2910, 237)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2910, 177)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',300)\n",
    "pd.set_option('display.max_rows',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>FV</th>\n",
       "      <th>RH</th>\n",
       "      <th>RL</th>\n",
       "      <th>RM</th>\n",
       "      <th>Pave</th>\n",
       "      <th>IR2</th>\n",
       "      <th>IR3</th>\n",
       "      <th>Reg</th>\n",
       "      <th>HLS</th>\n",
       "      <th>Low</th>\n",
       "      <th>Lvl</th>\n",
       "      <th>NoSeWa</th>\n",
       "      <th>CulDSac</th>\n",
       "      <th>FR2</th>\n",
       "      <th>FR3</th>\n",
       "      <th>Inside</th>\n",
       "      <th>Mod</th>\n",
       "      <th>Sev</th>\n",
       "      <th>Blueste</th>\n",
       "      <th>BrDale</th>\n",
       "      <th>BrkSide</th>\n",
       "      <th>ClearCr</th>\n",
       "      <th>CollgCr</th>\n",
       "      <th>Crawfor</th>\n",
       "      <th>Edwards</th>\n",
       "      <th>Gilbert</th>\n",
       "      <th>IDOTRR</th>\n",
       "      <th>MeadowV</th>\n",
       "      <th>Mitchel</th>\n",
       "      <th>NAmes</th>\n",
       "      <th>NPkVill</th>\n",
       "      <th>NWAmes</th>\n",
       "      <th>NoRidge</th>\n",
       "      <th>NridgHt</th>\n",
       "      <th>OldTown</th>\n",
       "      <th>SWISU</th>\n",
       "      <th>Sawyer</th>\n",
       "      <th>SawyerW</th>\n",
       "      <th>Somerst</th>\n",
       "      <th>StoneBr</th>\n",
       "      <th>Timber</th>\n",
       "      <th>Veenker</th>\n",
       "      <th>Feedr</th>\n",
       "      <th>Norm</th>\n",
       "      <th>PosA</th>\n",
       "      <th>PosN</th>\n",
       "      <th>RRAe</th>\n",
       "      <th>RRAn</th>\n",
       "      <th>RRNn</th>\n",
       "      <th>2fmCon</th>\n",
       "      <th>Duplex</th>\n",
       "      <th>Twnhs</th>\n",
       "      <th>TwnhsE</th>\n",
       "      <th>RRNe</th>\n",
       "      <th>1.5Unf</th>\n",
       "      <th>1Story</th>\n",
       "      <th>2.5Fin</th>\n",
       "      <th>2.5Unf</th>\n",
       "      <th>2Story</th>\n",
       "      <th>SFoyer</th>\n",
       "      <th>SLvl</th>\n",
       "      <th>CWD</th>\n",
       "      <th>Con</th>\n",
       "      <th>ConLD</th>\n",
       "      <th>ConLI</th>\n",
       "      <th>ConLw</th>\n",
       "      <th>New</th>\n",
       "      <th>Oth</th>\n",
       "      <th>WD</th>\n",
       "      <th>AdjLand</th>\n",
       "      <th>Alloca</th>\n",
       "      <th>Family</th>\n",
       "      <th>Normal</th>\n",
       "      <th>Partial</th>\n",
       "      <th>Fa</th>\n",
       "      <th>Gd</th>\n",
       "      <th>Po</th>\n",
       "      <th>TA</th>\n",
       "      <th>CBlock</th>\n",
       "      <th>PConc</th>\n",
       "      <th>Slab</th>\n",
       "      <th>Stone</th>\n",
       "      <th>Wood</th>\n",
       "      <th>Mn</th>\n",
       "      <th>No</th>\n",
       "      <th>BLQ</th>\n",
       "      <th>GLQ</th>\n",
       "      <th>LwQ</th>\n",
       "      <th>Rec</th>\n",
       "      <th>Unf</th>\n",
       "      <th>Gable</th>\n",
       "      <th>Gambrel</th>\n",
       "      <th>Hip</th>\n",
       "      <th>Mansard</th>\n",
       "      <th>Shed</th>\n",
       "      <th>CompShg</th>\n",
       "      <th>Membran</th>\n",
       "      <th>Metal</th>\n",
       "      <th>Roll</th>\n",
       "      <th>Tar&amp;Grv</th>\n",
       "      <th>WdShake</th>\n",
       "      <th>WdShngl</th>\n",
       "      <th>AsphShn</th>\n",
       "      <th>BrkComm</th>\n",
       "      <th>BrkFace</th>\n",
       "      <th>CemntBd</th>\n",
       "      <th>HdBoard</th>\n",
       "      <th>ImStucc</th>\n",
       "      <th>MetalSd</th>\n",
       "      <th>Plywood</th>\n",
       "      <th>Stucco</th>\n",
       "      <th>VinylSd</th>\n",
       "      <th>Wd Sdng</th>\n",
       "      <th>WdShing</th>\n",
       "      <th>Brk Cmn</th>\n",
       "      <th>CmentBd</th>\n",
       "      <th>Other</th>\n",
       "      <th>Wd Shng</th>\n",
       "      <th>None</th>\n",
       "      <th>GasA</th>\n",
       "      <th>GasW</th>\n",
       "      <th>Grav</th>\n",
       "      <th>OthW</th>\n",
       "      <th>Wall</th>\n",
       "      <th>Y</th>\n",
       "      <th>FuseF</th>\n",
       "      <th>FuseP</th>\n",
       "      <th>Mix</th>\n",
       "      <th>SBrkr</th>\n",
       "      <th>Maj2</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          2003       196.0       706.0         0.0      150.0        856.0   \n",
       "1          1976         0.0       978.0         0.0      284.0       1262.0   \n",
       "2          2002       162.0       486.0         0.0      434.0        920.0   \n",
       "3          1970         0.0       216.0         0.0      540.0        756.0   \n",
       "4          2000       350.0       655.0         0.0      490.0       1145.0   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea  BsmtFullBath  BsmtHalfBath  \\\n",
       "0       856       854             0       1710           1.0           0.0   \n",
       "1      1262         0             0       1262           0.0           1.0   \n",
       "2       920       866             0       1786           1.0           0.0   \n",
       "3       961       756             0       1717           1.0           0.0   \n",
       "4      1145      1053             0       2198           1.0           0.0   \n",
       "\n",
       "   FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr  TotRmsAbvGrd  Fireplaces  \\\n",
       "0         2         1             3             1             8           0   \n",
       "1         2         0             3             1             6           1   \n",
       "2         2         1             3             1             6           1   \n",
       "3         1         0             3             1             7           1   \n",
       "4         2         1             4             1             9           1   \n",
       "\n",
       "   GarageYrBlt  GarageCars  GarageArea  WoodDeckSF  OpenPorchSF  \\\n",
       "0       2003.0         2.0       548.0           0           61   \n",
       "1       1976.0         2.0       460.0         298            0   \n",
       "2       2001.0         2.0       608.0           0           42   \n",
       "3       1998.0         3.0       642.0           0           35   \n",
       "4       2000.0         3.0       836.0         192           84   \n",
       "\n",
       "   EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  \\\n",
       "0              0          0            0         0        0       2    2008   \n",
       "1              0          0            0         0        0       5    2007   \n",
       "2              0          0            0         0        0       9    2008   \n",
       "3            272          0            0         0        0       2    2006   \n",
       "4              0          0            0         0        0      12    2008   \n",
       "\n",
       "   SalePrice  FV  RH  RL  RM  Pave  IR2  IR3  Reg  HLS  Low  Lvl  NoSeWa  \\\n",
       "0   208500.0   0   0   1   0     1    0    0    1    0    0    1       0   \n",
       "1   181500.0   0   0   1   0     1    0    0    1    0    0    1       0   \n",
       "2   223500.0   0   0   1   0     1    0    0    0    0    0    1       0   \n",
       "3   140000.0   0   0   1   0     1    0    0    0    0    0    1       0   \n",
       "4   250000.0   0   0   1   0     1    0    0    0    0    0    1       0   \n",
       "\n",
       "   CulDSac  FR2  FR3  Inside  Mod  Sev  Blueste  BrDale  BrkSide  ClearCr  \\\n",
       "0        0    0    0       1    0    0        0       0        0        0   \n",
       "1        0    1    0       0    0    0        0       0        0        0   \n",
       "2        0    0    0       1    0    0        0       0        0        0   \n",
       "3        0    0    0       0    0    0        0       0        0        0   \n",
       "4        0    1    0       0    0    0        0       0        0        0   \n",
       "\n",
       "   CollgCr  Crawfor  Edwards  Gilbert  IDOTRR  MeadowV  Mitchel  NAmes  \\\n",
       "0        1        0        0        0       0        0        0      0   \n",
       "1        0        0        0        0       0        0        0      0   \n",
       "2        1        0        0        0       0        0        0      0   \n",
       "3        0        1        0        0       0        0        0      0   \n",
       "4        0        0        0        0       0        0        0      0   \n",
       "\n",
       "   NPkVill  NWAmes  NoRidge  NridgHt  OldTown  SWISU  Sawyer  SawyerW  \\\n",
       "0        0       0        0        0        0      0       0        0   \n",
       "1        0       0        0        0        0      0       0        0   \n",
       "2        0       0        0        0        0      0       0        0   \n",
       "3        0       0        0        0        0      0       0        0   \n",
       "4        0       0        1        0        0      0       0        0   \n",
       "\n",
       "   Somerst  StoneBr  Timber  Veenker  Feedr  Norm  PosA  PosN  RRAe  RRAn  \\\n",
       "0        0        0       0        0      0     1     0     0     0     0   \n",
       "1        0        0       0        1      0     1     0     0     0     0   \n",
       "2        0        0       0        0      0     1     0     0     0     0   \n",
       "3        0        0       0        0      0     1     0     0     0     0   \n",
       "4        0        0       0        0      0     1     0     0     0     0   \n",
       "\n",
       "   RRNn  2fmCon  Duplex  Twnhs  TwnhsE  RRNe  1.5Unf  1Story  2.5Fin  2.5Unf  \\\n",
       "0     0       0       0      0       0     0       0       0       0       0   \n",
       "1     0       0       0      0       0     0       0       1       0       0   \n",
       "2     0       0       0      0       0     0       0       0       0       0   \n",
       "3     0       0       0      0       0     0       0       0       0       0   \n",
       "4     0       0       0      0       0     0       0       0       0       0   \n",
       "\n",
       "   2Story  SFoyer  SLvl  CWD  Con  ConLD  ConLI  ConLw  New  Oth  WD  AdjLand  \\\n",
       "0       1       0     0    0    0      0      0      0    0    0   1        0   \n",
       "1       0       0     0    0    0      0      0      0    0    0   1        0   \n",
       "2       1       0     0    0    0      0      0      0    0    0   1        0   \n",
       "3       1       0     0    0    0      0      0      0    0    0   1        0   \n",
       "4       1       0     0    0    0      0      0      0    0    0   1        0   \n",
       "\n",
       "   Alloca  Family  Normal  Partial  Fa  Gd  Po  TA  CBlock  PConc  Slab  \\\n",
       "0       0       0       1        0   0   0   0   1       0      1     0   \n",
       "1       0       0       1        0   0   0   0   1       1      0     0   \n",
       "2       0       0       1        0   0   0   0   1       0      1     0   \n",
       "3       0       0       0        0   0   0   0   1       0      0     0   \n",
       "4       0       0       1        0   0   0   0   1       0      1     0   \n",
       "\n",
       "   Stone  Wood  Mn  No  BLQ  GLQ  LwQ  Rec  Unf  Gable  Gambrel  Hip  Mansard  \\\n",
       "0      0     0   0   1    0    1    0    0    0      1        0    0        0   \n",
       "1      0     0   0   0    0    0    0    0    0      1        0    0        0   \n",
       "2      0     0   1   0    0    1    0    0    0      1        0    0        0   \n",
       "3      0     0   0   1    0    0    0    0    0      1        0    0        0   \n",
       "4      0     0   0   0    0    1    0    0    0      1        0    0        0   \n",
       "\n",
       "   Shed  CompShg  Membran  Metal  Roll  Tar&Grv  WdShake  WdShngl  AsphShn  \\\n",
       "0     0        1        0      0     0        0        0        0        0   \n",
       "1     0        1        0      0     0        0        0        0        0   \n",
       "2     0        1        0      0     0        0        0        0        0   \n",
       "3     0        1        0      0     0        0        0        0        0   \n",
       "4     0        1        0      0     0        0        0        0        0   \n",
       "\n",
       "   BrkComm  BrkFace  CemntBd  HdBoard  ImStucc  MetalSd  Plywood  Stucco  \\\n",
       "0        0        0        0        0        0        0        0       0   \n",
       "1        0        0        0        0        0        1        0       0   \n",
       "2        0        0        0        0        0        0        0       0   \n",
       "3        0        0        0        0        0        0        0       0   \n",
       "4        0        0        0        0        0        0        0       0   \n",
       "\n",
       "   VinylSd  Wd Sdng  WdShing  Brk Cmn  CmentBd  Other  Wd Shng  None  GasA  \\\n",
       "0        1        0        0        0        0      0        0     0     1   \n",
       "1        0        0        0        0        0      0        0     1     1   \n",
       "2        1        0        0        0        0      0        0     0     1   \n",
       "3        0        1        0        0        0      0        1     1     1   \n",
       "4        1        0        0        0        0      0        0     0     1   \n",
       "\n",
       "   GasW  Grav  OthW  Wall  Y  FuseF  FuseP  Mix  SBrkr  Maj2  Min1  Min2  Typ  \\\n",
       "0     0     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "1     0     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "2     0     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "3     0     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "4     0     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=final_df.iloc[:1451,:]\n",
    "df_test=final_df.iloc[1451:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>FV</th>\n",
       "      <th>RH</th>\n",
       "      <th>RL</th>\n",
       "      <th>RM</th>\n",
       "      <th>Pave</th>\n",
       "      <th>IR2</th>\n",
       "      <th>IR3</th>\n",
       "      <th>Reg</th>\n",
       "      <th>HLS</th>\n",
       "      <th>Low</th>\n",
       "      <th>Lvl</th>\n",
       "      <th>NoSeWa</th>\n",
       "      <th>CulDSac</th>\n",
       "      <th>FR2</th>\n",
       "      <th>FR3</th>\n",
       "      <th>Inside</th>\n",
       "      <th>Mod</th>\n",
       "      <th>Sev</th>\n",
       "      <th>Blueste</th>\n",
       "      <th>BrDale</th>\n",
       "      <th>BrkSide</th>\n",
       "      <th>ClearCr</th>\n",
       "      <th>CollgCr</th>\n",
       "      <th>Crawfor</th>\n",
       "      <th>Edwards</th>\n",
       "      <th>Gilbert</th>\n",
       "      <th>IDOTRR</th>\n",
       "      <th>MeadowV</th>\n",
       "      <th>Mitchel</th>\n",
       "      <th>NAmes</th>\n",
       "      <th>NPkVill</th>\n",
       "      <th>NWAmes</th>\n",
       "      <th>NoRidge</th>\n",
       "      <th>NridgHt</th>\n",
       "      <th>OldTown</th>\n",
       "      <th>SWISU</th>\n",
       "      <th>Sawyer</th>\n",
       "      <th>SawyerW</th>\n",
       "      <th>Somerst</th>\n",
       "      <th>StoneBr</th>\n",
       "      <th>Timber</th>\n",
       "      <th>Veenker</th>\n",
       "      <th>Feedr</th>\n",
       "      <th>Norm</th>\n",
       "      <th>PosA</th>\n",
       "      <th>PosN</th>\n",
       "      <th>RRAe</th>\n",
       "      <th>RRAn</th>\n",
       "      <th>RRNn</th>\n",
       "      <th>2fmCon</th>\n",
       "      <th>Duplex</th>\n",
       "      <th>Twnhs</th>\n",
       "      <th>TwnhsE</th>\n",
       "      <th>RRNe</th>\n",
       "      <th>1.5Unf</th>\n",
       "      <th>1Story</th>\n",
       "      <th>2.5Fin</th>\n",
       "      <th>2.5Unf</th>\n",
       "      <th>2Story</th>\n",
       "      <th>SFoyer</th>\n",
       "      <th>SLvl</th>\n",
       "      <th>CWD</th>\n",
       "      <th>Con</th>\n",
       "      <th>ConLD</th>\n",
       "      <th>ConLI</th>\n",
       "      <th>ConLw</th>\n",
       "      <th>New</th>\n",
       "      <th>Oth</th>\n",
       "      <th>WD</th>\n",
       "      <th>AdjLand</th>\n",
       "      <th>Alloca</th>\n",
       "      <th>Family</th>\n",
       "      <th>Normal</th>\n",
       "      <th>Partial</th>\n",
       "      <th>Fa</th>\n",
       "      <th>Gd</th>\n",
       "      <th>Po</th>\n",
       "      <th>TA</th>\n",
       "      <th>CBlock</th>\n",
       "      <th>PConc</th>\n",
       "      <th>Slab</th>\n",
       "      <th>Stone</th>\n",
       "      <th>Wood</th>\n",
       "      <th>Mn</th>\n",
       "      <th>No</th>\n",
       "      <th>BLQ</th>\n",
       "      <th>GLQ</th>\n",
       "      <th>LwQ</th>\n",
       "      <th>Rec</th>\n",
       "      <th>Unf</th>\n",
       "      <th>Gable</th>\n",
       "      <th>Gambrel</th>\n",
       "      <th>Hip</th>\n",
       "      <th>Mansard</th>\n",
       "      <th>Shed</th>\n",
       "      <th>CompShg</th>\n",
       "      <th>Membran</th>\n",
       "      <th>Metal</th>\n",
       "      <th>Roll</th>\n",
       "      <th>Tar&amp;Grv</th>\n",
       "      <th>WdShake</th>\n",
       "      <th>WdShngl</th>\n",
       "      <th>AsphShn</th>\n",
       "      <th>BrkComm</th>\n",
       "      <th>BrkFace</th>\n",
       "      <th>CemntBd</th>\n",
       "      <th>HdBoard</th>\n",
       "      <th>ImStucc</th>\n",
       "      <th>MetalSd</th>\n",
       "      <th>Plywood</th>\n",
       "      <th>Stucco</th>\n",
       "      <th>VinylSd</th>\n",
       "      <th>Wd Sdng</th>\n",
       "      <th>WdShing</th>\n",
       "      <th>Brk Cmn</th>\n",
       "      <th>CmentBd</th>\n",
       "      <th>Other</th>\n",
       "      <th>Wd Shng</th>\n",
       "      <th>None</th>\n",
       "      <th>GasA</th>\n",
       "      <th>GasW</th>\n",
       "      <th>Grav</th>\n",
       "      <th>OthW</th>\n",
       "      <th>Wall</th>\n",
       "      <th>Y</th>\n",
       "      <th>FuseF</th>\n",
       "      <th>FuseP</th>\n",
       "      <th>Mix</th>\n",
       "      <th>SBrkr</th>\n",
       "      <th>Maj2</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          2003       196.0       706.0         0.0      150.0        856.0   \n",
       "1          1976         0.0       978.0         0.0      284.0       1262.0   \n",
       "2          2002       162.0       486.0         0.0      434.0        920.0   \n",
       "3          1970         0.0       216.0         0.0      540.0        756.0   \n",
       "4          2000       350.0       655.0         0.0      490.0       1145.0   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea  BsmtFullBath  BsmtHalfBath  \\\n",
       "0       856       854             0       1710           1.0           0.0   \n",
       "1      1262         0             0       1262           0.0           1.0   \n",
       "2       920       866             0       1786           1.0           0.0   \n",
       "3       961       756             0       1717           1.0           0.0   \n",
       "4      1145      1053             0       2198           1.0           0.0   \n",
       "\n",
       "   FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr  TotRmsAbvGrd  Fireplaces  \\\n",
       "0         2         1             3             1             8           0   \n",
       "1         2         0             3             1             6           1   \n",
       "2         2         1             3             1             6           1   \n",
       "3         1         0             3             1             7           1   \n",
       "4         2         1             4             1             9           1   \n",
       "\n",
       "   GarageYrBlt  GarageCars  GarageArea  WoodDeckSF  OpenPorchSF  \\\n",
       "0       2003.0         2.0       548.0           0           61   \n",
       "1       1976.0         2.0       460.0         298            0   \n",
       "2       2001.0         2.0       608.0           0           42   \n",
       "3       1998.0         3.0       642.0           0           35   \n",
       "4       2000.0         3.0       836.0         192           84   \n",
       "\n",
       "   EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  \\\n",
       "0              0          0            0         0        0       2    2008   \n",
       "1              0          0            0         0        0       5    2007   \n",
       "2              0          0            0         0        0       9    2008   \n",
       "3            272          0            0         0        0       2    2006   \n",
       "4              0          0            0         0        0      12    2008   \n",
       "\n",
       "   SalePrice  FV  RH  RL  RM  Pave  IR2  IR3  Reg  HLS  Low  Lvl  NoSeWa  \\\n",
       "0   208500.0   0   0   1   0     1    0    0    1    0    0    1       0   \n",
       "1   181500.0   0   0   1   0     1    0    0    1    0    0    1       0   \n",
       "2   223500.0   0   0   1   0     1    0    0    0    0    0    1       0   \n",
       "3   140000.0   0   0   1   0     1    0    0    0    0    0    1       0   \n",
       "4   250000.0   0   0   1   0     1    0    0    0    0    0    1       0   \n",
       "\n",
       "   CulDSac  FR2  FR3  Inside  Mod  Sev  Blueste  BrDale  BrkSide  ClearCr  \\\n",
       "0        0    0    0       1    0    0        0       0        0        0   \n",
       "1        0    1    0       0    0    0        0       0        0        0   \n",
       "2        0    0    0       1    0    0        0       0        0        0   \n",
       "3        0    0    0       0    0    0        0       0        0        0   \n",
       "4        0    1    0       0    0    0        0       0        0        0   \n",
       "\n",
       "   CollgCr  Crawfor  Edwards  Gilbert  IDOTRR  MeadowV  Mitchel  NAmes  \\\n",
       "0        1        0        0        0       0        0        0      0   \n",
       "1        0        0        0        0       0        0        0      0   \n",
       "2        1        0        0        0       0        0        0      0   \n",
       "3        0        1        0        0       0        0        0      0   \n",
       "4        0        0        0        0       0        0        0      0   \n",
       "\n",
       "   NPkVill  NWAmes  NoRidge  NridgHt  OldTown  SWISU  Sawyer  SawyerW  \\\n",
       "0        0       0        0        0        0      0       0        0   \n",
       "1        0       0        0        0        0      0       0        0   \n",
       "2        0       0        0        0        0      0       0        0   \n",
       "3        0       0        0        0        0      0       0        0   \n",
       "4        0       0        1        0        0      0       0        0   \n",
       "\n",
       "   Somerst  StoneBr  Timber  Veenker  Feedr  Norm  PosA  PosN  RRAe  RRAn  \\\n",
       "0        0        0       0        0      0     1     0     0     0     0   \n",
       "1        0        0       0        1      0     1     0     0     0     0   \n",
       "2        0        0       0        0      0     1     0     0     0     0   \n",
       "3        0        0       0        0      0     1     0     0     0     0   \n",
       "4        0        0       0        0      0     1     0     0     0     0   \n",
       "\n",
       "   RRNn  2fmCon  Duplex  Twnhs  TwnhsE  RRNe  1.5Unf  1Story  2.5Fin  2.5Unf  \\\n",
       "0     0       0       0      0       0     0       0       0       0       0   \n",
       "1     0       0       0      0       0     0       0       1       0       0   \n",
       "2     0       0       0      0       0     0       0       0       0       0   \n",
       "3     0       0       0      0       0     0       0       0       0       0   \n",
       "4     0       0       0      0       0     0       0       0       0       0   \n",
       "\n",
       "   2Story  SFoyer  SLvl  CWD  Con  ConLD  ConLI  ConLw  New  Oth  WD  AdjLand  \\\n",
       "0       1       0     0    0    0      0      0      0    0    0   1        0   \n",
       "1       0       0     0    0    0      0      0      0    0    0   1        0   \n",
       "2       1       0     0    0    0      0      0      0    0    0   1        0   \n",
       "3       1       0     0    0    0      0      0      0    0    0   1        0   \n",
       "4       1       0     0    0    0      0      0      0    0    0   1        0   \n",
       "\n",
       "   Alloca  Family  Normal  Partial  Fa  Gd  Po  TA  CBlock  PConc  Slab  \\\n",
       "0       0       0       1        0   0   0   0   1       0      1     0   \n",
       "1       0       0       1        0   0   0   0   1       1      0     0   \n",
       "2       0       0       1        0   0   0   0   1       0      1     0   \n",
       "3       0       0       0        0   0   0   0   1       0      0     0   \n",
       "4       0       0       1        0   0   0   0   1       0      1     0   \n",
       "\n",
       "   Stone  Wood  Mn  No  BLQ  GLQ  LwQ  Rec  Unf  Gable  Gambrel  Hip  Mansard  \\\n",
       "0      0     0   0   1    0    1    0    0    0      1        0    0        0   \n",
       "1      0     0   0   0    0    0    0    0    0      1        0    0        0   \n",
       "2      0     0   1   0    0    1    0    0    0      1        0    0        0   \n",
       "3      0     0   0   1    0    0    0    0    0      1        0    0        0   \n",
       "4      0     0   0   0    0    1    0    0    0      1        0    0        0   \n",
       "\n",
       "   Shed  CompShg  Membran  Metal  Roll  Tar&Grv  WdShake  WdShngl  AsphShn  \\\n",
       "0     0        1        0      0     0        0        0        0        0   \n",
       "1     0        1        0      0     0        0        0        0        0   \n",
       "2     0        1        0      0     0        0        0        0        0   \n",
       "3     0        1        0      0     0        0        0        0        0   \n",
       "4     0        1        0      0     0        0        0        0        0   \n",
       "\n",
       "   BrkComm  BrkFace  CemntBd  HdBoard  ImStucc  MetalSd  Plywood  Stucco  \\\n",
       "0        0        0        0        0        0        0        0       0   \n",
       "1        0        0        0        0        0        1        0       0   \n",
       "2        0        0        0        0        0        0        0       0   \n",
       "3        0        0        0        0        0        0        0       0   \n",
       "4        0        0        0        0        0        0        0       0   \n",
       "\n",
       "   VinylSd  Wd Sdng  WdShing  Brk Cmn  CmentBd  Other  Wd Shng  None  GasA  \\\n",
       "0        1        0        0        0        0      0        0     0     1   \n",
       "1        0        0        0        0        0      0        0     1     1   \n",
       "2        1        0        0        0        0      0        0     0     1   \n",
       "3        0        1        0        0        0      0        1     1     1   \n",
       "4        1        0        0        0        0      0        0     0     1   \n",
       "\n",
       "   GasW  Grav  OthW  Wall  Y  FuseF  FuseP  Mix  SBrkr  Maj2  Min1  Min2  Typ  \\\n",
       "0     0     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "1     0     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "2     0     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "3     0     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "4     0     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 177)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>FV</th>\n",
       "      <th>RH</th>\n",
       "      <th>RL</th>\n",
       "      <th>RM</th>\n",
       "      <th>Pave</th>\n",
       "      <th>IR2</th>\n",
       "      <th>IR3</th>\n",
       "      <th>Reg</th>\n",
       "      <th>HLS</th>\n",
       "      <th>Low</th>\n",
       "      <th>Lvl</th>\n",
       "      <th>NoSeWa</th>\n",
       "      <th>CulDSac</th>\n",
       "      <th>FR2</th>\n",
       "      <th>FR3</th>\n",
       "      <th>Inside</th>\n",
       "      <th>Mod</th>\n",
       "      <th>Sev</th>\n",
       "      <th>Blueste</th>\n",
       "      <th>BrDale</th>\n",
       "      <th>BrkSide</th>\n",
       "      <th>ClearCr</th>\n",
       "      <th>CollgCr</th>\n",
       "      <th>Crawfor</th>\n",
       "      <th>Edwards</th>\n",
       "      <th>Gilbert</th>\n",
       "      <th>IDOTRR</th>\n",
       "      <th>MeadowV</th>\n",
       "      <th>Mitchel</th>\n",
       "      <th>NAmes</th>\n",
       "      <th>NPkVill</th>\n",
       "      <th>NWAmes</th>\n",
       "      <th>NoRidge</th>\n",
       "      <th>NridgHt</th>\n",
       "      <th>OldTown</th>\n",
       "      <th>SWISU</th>\n",
       "      <th>Sawyer</th>\n",
       "      <th>SawyerW</th>\n",
       "      <th>Somerst</th>\n",
       "      <th>StoneBr</th>\n",
       "      <th>Timber</th>\n",
       "      <th>Veenker</th>\n",
       "      <th>Feedr</th>\n",
       "      <th>Norm</th>\n",
       "      <th>PosA</th>\n",
       "      <th>PosN</th>\n",
       "      <th>RRAe</th>\n",
       "      <th>RRAn</th>\n",
       "      <th>RRNn</th>\n",
       "      <th>2fmCon</th>\n",
       "      <th>Duplex</th>\n",
       "      <th>Twnhs</th>\n",
       "      <th>TwnhsE</th>\n",
       "      <th>RRNe</th>\n",
       "      <th>1.5Unf</th>\n",
       "      <th>1Story</th>\n",
       "      <th>2.5Fin</th>\n",
       "      <th>2.5Unf</th>\n",
       "      <th>2Story</th>\n",
       "      <th>SFoyer</th>\n",
       "      <th>SLvl</th>\n",
       "      <th>CWD</th>\n",
       "      <th>Con</th>\n",
       "      <th>ConLD</th>\n",
       "      <th>ConLI</th>\n",
       "      <th>ConLw</th>\n",
       "      <th>New</th>\n",
       "      <th>Oth</th>\n",
       "      <th>WD</th>\n",
       "      <th>AdjLand</th>\n",
       "      <th>Alloca</th>\n",
       "      <th>Family</th>\n",
       "      <th>Normal</th>\n",
       "      <th>Partial</th>\n",
       "      <th>Fa</th>\n",
       "      <th>Gd</th>\n",
       "      <th>Po</th>\n",
       "      <th>TA</th>\n",
       "      <th>CBlock</th>\n",
       "      <th>PConc</th>\n",
       "      <th>Slab</th>\n",
       "      <th>Stone</th>\n",
       "      <th>Wood</th>\n",
       "      <th>Mn</th>\n",
       "      <th>No</th>\n",
       "      <th>BLQ</th>\n",
       "      <th>GLQ</th>\n",
       "      <th>LwQ</th>\n",
       "      <th>Rec</th>\n",
       "      <th>Unf</th>\n",
       "      <th>Gable</th>\n",
       "      <th>Gambrel</th>\n",
       "      <th>Hip</th>\n",
       "      <th>Mansard</th>\n",
       "      <th>Shed</th>\n",
       "      <th>CompShg</th>\n",
       "      <th>Membran</th>\n",
       "      <th>Metal</th>\n",
       "      <th>Roll</th>\n",
       "      <th>Tar&amp;Grv</th>\n",
       "      <th>WdShake</th>\n",
       "      <th>WdShngl</th>\n",
       "      <th>AsphShn</th>\n",
       "      <th>BrkComm</th>\n",
       "      <th>BrkFace</th>\n",
       "      <th>CemntBd</th>\n",
       "      <th>HdBoard</th>\n",
       "      <th>ImStucc</th>\n",
       "      <th>MetalSd</th>\n",
       "      <th>Plywood</th>\n",
       "      <th>Stucco</th>\n",
       "      <th>VinylSd</th>\n",
       "      <th>Wd Sdng</th>\n",
       "      <th>WdShing</th>\n",
       "      <th>Brk Cmn</th>\n",
       "      <th>CmentBd</th>\n",
       "      <th>Other</th>\n",
       "      <th>Wd Shng</th>\n",
       "      <th>None</th>\n",
       "      <th>GasA</th>\n",
       "      <th>GasW</th>\n",
       "      <th>Grav</th>\n",
       "      <th>OthW</th>\n",
       "      <th>Wall</th>\n",
       "      <th>Y</th>\n",
       "      <th>FuseF</th>\n",
       "      <th>FuseP</th>\n",
       "      <th>Mix</th>\n",
       "      <th>SBrkr</th>\n",
       "      <th>Maj2</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1961.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1958.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>393</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>1629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>212</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>1604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>360</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1992.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>160</td>\n",
       "      <td>2915.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>1092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1977.721217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>160</td>\n",
       "      <td>2916.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>1092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>2917.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1960</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1224</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>85</td>\n",
       "      <td>2918.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1977.721217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>60</td>\n",
       "      <td>2919.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>94.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>996</td>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>190</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows Ã— 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0             20       1461.0    11622            5            6       1961   \n",
       "1             20       1462.0    14267            6            6       1958   \n",
       "2             60       1463.0    13830            5            5       1997   \n",
       "3             60       1464.0     9978            6            6       1998   \n",
       "4            120       1465.0     5005            8            5       1992   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1454         160       2915.0     1936            4            7       1970   \n",
       "1455         160       2916.0     1894            4            5       1970   \n",
       "1456          20       2917.0    20000            5            7       1960   \n",
       "1457          85       2918.0    10441            5            5       1992   \n",
       "1458          60       2919.0     9627            7            5       1993   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  \\\n",
       "0             1961         0.0       468.0       144.0      270.0   \n",
       "1             1958       108.0       923.0         0.0      406.0   \n",
       "2             1998         0.0       791.0         0.0      137.0   \n",
       "3             1998        20.0       602.0         0.0      324.0   \n",
       "4             1992         0.0       263.0         0.0     1017.0   \n",
       "...            ...         ...         ...         ...        ...   \n",
       "1454          1970         0.0         0.0         0.0      546.0   \n",
       "1455          1970         0.0       252.0         0.0      294.0   \n",
       "1456          1996         0.0      1224.0         0.0        0.0   \n",
       "1457          1992         0.0       337.0         0.0      575.0   \n",
       "1458          1994        94.0       758.0         0.0      238.0   \n",
       "\n",
       "      TotalBsmtSF  1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea  BsmtFullBath  \\\n",
       "0           882.0       896         0             0        896           0.0   \n",
       "1          1329.0      1329         0             0       1329           0.0   \n",
       "2           928.0       928       701             0       1629           0.0   \n",
       "3           926.0       926       678             0       1604           0.0   \n",
       "4          1280.0      1280         0             0       1280           0.0   \n",
       "...           ...       ...       ...           ...        ...           ...   \n",
       "1454        546.0       546       546             0       1092           0.0   \n",
       "1455        546.0       546       546             0       1092           0.0   \n",
       "1456       1224.0      1224         0             0       1224           1.0   \n",
       "1457        912.0       970         0             0        970           0.0   \n",
       "1458        996.0       996      1004             0       2000           0.0   \n",
       "\n",
       "      BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr  \\\n",
       "0              0.0         1         0             2             1   \n",
       "1              0.0         1         1             3             1   \n",
       "2              0.0         2         1             3             1   \n",
       "3              0.0         2         1             3             1   \n",
       "4              0.0         2         0             2             1   \n",
       "...            ...       ...       ...           ...           ...   \n",
       "1454           0.0         1         1             3             1   \n",
       "1455           0.0         1         1             3             1   \n",
       "1456           0.0         1         0             4             1   \n",
       "1457           1.0         1         0             3             1   \n",
       "1458           0.0         2         1             3             1   \n",
       "\n",
       "      TotRmsAbvGrd  Fireplaces  GarageYrBlt  GarageCars  GarageArea  \\\n",
       "0                5           0  1961.000000         1.0       730.0   \n",
       "1                6           0  1958.000000         1.0       312.0   \n",
       "2                6           1  1997.000000         2.0       482.0   \n",
       "3                7           1  1998.000000         2.0       470.0   \n",
       "4                5           0  1992.000000         2.0       506.0   \n",
       "...            ...         ...          ...         ...         ...   \n",
       "1454             5           0  1977.721217         0.0         0.0   \n",
       "1455             6           0  1970.000000         1.0       286.0   \n",
       "1456             7           1  1960.000000         2.0       576.0   \n",
       "1457             6           0  1977.721217         0.0         0.0   \n",
       "1458             9           1  1993.000000         3.0       650.0   \n",
       "\n",
       "      WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  \\\n",
       "0            140            0              0          0          120   \n",
       "1            393           36              0          0            0   \n",
       "2            212           34              0          0            0   \n",
       "3            360           36              0          0            0   \n",
       "4              0           82              0          0          144   \n",
       "...          ...          ...            ...        ...          ...   \n",
       "1454           0            0              0          0            0   \n",
       "1455           0           24              0          0            0   \n",
       "1456         474            0              0          0            0   \n",
       "1457          80           32              0          0            0   \n",
       "1458         190           48              0          0            0   \n",
       "\n",
       "      PoolArea  MiscVal  MoSold  YrSold  SalePrice  FV  RH  RL  RM  Pave  IR2  \\\n",
       "0            0        0       6    2010        NaN   0   1   0   0     1    0   \n",
       "1            0    12500       6    2010        NaN   0   0   1   0     1    0   \n",
       "2            0        0       3    2010        NaN   0   0   1   0     1    0   \n",
       "3            0        0       6    2010        NaN   0   0   1   0     1    0   \n",
       "4            0        0       1    2010        NaN   0   0   1   0     1    0   \n",
       "...        ...      ...     ...     ...        ...  ..  ..  ..  ..   ...  ...   \n",
       "1454         0        0       6    2006        NaN   0   0   0   1     1    0   \n",
       "1455         0        0       4    2006        NaN   0   0   0   1     1    0   \n",
       "1456         0        0       9    2006        NaN   0   0   1   0     1    0   \n",
       "1457         0      700       7    2006        NaN   0   0   1   0     1    0   \n",
       "1458         0        0      11    2006        NaN   0   0   1   0     1    0   \n",
       "\n",
       "      IR3  Reg  HLS  Low  Lvl  NoSeWa  CulDSac  FR2  FR3  Inside  Mod  Sev  \\\n",
       "0       0    1    0    0    1       0        0    0    0       1    0    0   \n",
       "1       0    0    0    0    1       0        0    0    0       0    0    0   \n",
       "2       0    0    0    0    1       0        0    0    0       1    0    0   \n",
       "3       0    0    0    0    1       0        0    0    0       1    0    0   \n",
       "4       0    0    1    0    0       0        0    0    0       1    0    0   \n",
       "...   ...  ...  ...  ...  ...     ...      ...  ...  ...     ...  ...  ...   \n",
       "1454    0    1    0    0    1       0        0    0    0       1    0    0   \n",
       "1455    0    1    0    0    1       0        0    0    0       1    0    0   \n",
       "1456    0    1    0    0    1       0        0    0    0       1    0    0   \n",
       "1457    0    1    0    0    1       0        0    0    0       1    0    0   \n",
       "1458    0    1    0    0    1       0        0    0    0       1    1    0   \n",
       "\n",
       "      Blueste  BrDale  BrkSide  ClearCr  CollgCr  Crawfor  Edwards  Gilbert  \\\n",
       "0           0       0        0        0        0        0        0        0   \n",
       "1           0       0        0        0        0        0        0        0   \n",
       "2           0       0        0        0        0        0        0        1   \n",
       "3           0       0        0        0        0        0        0        1   \n",
       "4           0       0        0        0        0        0        0        0   \n",
       "...       ...     ...      ...      ...      ...      ...      ...      ...   \n",
       "1454        0       0        0        0        0        0        0        0   \n",
       "1455        0       0        0        0        0        0        0        0   \n",
       "1456        0       0        0        0        0        0        0        0   \n",
       "1457        0       0        0        0        0        0        0        0   \n",
       "1458        0       0        0        0        0        0        0        0   \n",
       "\n",
       "      IDOTRR  MeadowV  Mitchel  NAmes  NPkVill  NWAmes  NoRidge  NridgHt  \\\n",
       "0          0        0        0      1        0       0        0        0   \n",
       "1          0        0        0      1        0       0        0        0   \n",
       "2          0        0        0      0        0       0        0        0   \n",
       "3          0        0        0      0        0       0        0        0   \n",
       "4          0        0        0      0        0       0        0        0   \n",
       "...      ...      ...      ...    ...      ...     ...      ...      ...   \n",
       "1454       0        1        0      0        0       0        0        0   \n",
       "1455       0        1        0      0        0       0        0        0   \n",
       "1456       0        0        1      0        0       0        0        0   \n",
       "1457       0        0        1      0        0       0        0        0   \n",
       "1458       0        0        1      0        0       0        0        0   \n",
       "\n",
       "      OldTown  SWISU  Sawyer  SawyerW  Somerst  StoneBr  Timber  Veenker  \\\n",
       "0           0      0       0        0        0        0       0        0   \n",
       "1           0      0       0        0        0        0       0        0   \n",
       "2           0      0       0        0        0        0       0        0   \n",
       "3           0      0       0        0        0        0       0        0   \n",
       "4           0      0       0        0        0        1       0        0   \n",
       "...       ...    ...     ...      ...      ...      ...     ...      ...   \n",
       "1454        0      0       0        0        0        0       0        0   \n",
       "1455        0      0       0        0        0        0       0        0   \n",
       "1456        0      0       0        0        0        0       0        0   \n",
       "1457        0      0       0        0        0        0       0        0   \n",
       "1458        0      0       0        0        0        0       0        0   \n",
       "\n",
       "      Feedr  Norm  PosA  PosN  RRAe  RRAn  RRNn  2fmCon  Duplex  Twnhs  \\\n",
       "0         0     1     0     0     0     0     0       0       0      0   \n",
       "1         0     1     0     0     0     0     0       0       0      0   \n",
       "2         0     1     0     0     0     0     0       0       0      0   \n",
       "3         0     1     0     0     0     0     0       0       0      0   \n",
       "4         0     1     0     0     0     0     0       0       0      0   \n",
       "...     ...   ...   ...   ...   ...   ...   ...     ...     ...    ...   \n",
       "1454      0     1     0     0     0     0     0       0       0      1   \n",
       "1455      0     1     0     0     0     0     0       0       0      0   \n",
       "1456      0     1     0     0     0     0     0       0       0      0   \n",
       "1457      0     1     0     0     0     0     0       0       0      0   \n",
       "1458      0     1     0     0     0     0     0       0       0      0   \n",
       "\n",
       "      TwnhsE  RRNe  1.5Unf  1Story  2.5Fin  2.5Unf  2Story  SFoyer  SLvl  CWD  \\\n",
       "0          0     0       0       1       0       0       0       0     0    0   \n",
       "1          0     0       0       1       0       0       0       0     0    0   \n",
       "2          0     0       0       0       0       0       1       0     0    0   \n",
       "3          0     0       0       0       0       0       1       0     0    0   \n",
       "4          1     0       0       1       0       0       0       0     0    0   \n",
       "...      ...   ...     ...     ...     ...     ...     ...     ...   ...  ...   \n",
       "1454       0     0       0       0       0       0       1       0     0    0   \n",
       "1455       1     0       0       0       0       0       1       0     0    0   \n",
       "1456       0     0       0       1       0       0       0       0     0    0   \n",
       "1457       0     0       0       0       0       0       0       1     0    0   \n",
       "1458       0     0       0       0       0       0       1       0     0    0   \n",
       "\n",
       "      Con  ConLD  ConLI  ConLw  New  Oth  WD  AdjLand  Alloca  Family  Normal  \\\n",
       "0       0      0      0      0    0    0   1        0       0       0       1   \n",
       "1       0      0      0      0    0    0   1        0       0       0       1   \n",
       "2       0      0      0      0    0    0   1        0       0       0       1   \n",
       "3       0      0      0      0    0    0   1        0       0       0       1   \n",
       "4       0      0      0      0    0    0   1        0       0       0       1   \n",
       "...   ...    ...    ...    ...  ...  ...  ..      ...     ...     ...     ...   \n",
       "1454    0      0      0      0    0    0   1        0       0       0       1   \n",
       "1455    0      0      0      0    0    0   1        0       0       0       0   \n",
       "1456    0      0      0      0    0    0   1        0       0       0       0   \n",
       "1457    0      0      0      0    0    0   1        0       0       0       1   \n",
       "1458    0      0      0      0    0    0   1        0       0       0       1   \n",
       "\n",
       "      Partial  Fa  Gd  Po  TA  CBlock  PConc  Slab  Stone  Wood  Mn  No  BLQ  \\\n",
       "0           0   0   0   0   1       1      0     0      0     0   0   1    0   \n",
       "1           0   0   0   0   1       1      0     0      0     0   0   1    0   \n",
       "2           0   0   0   0   1       0      1     0      0     0   0   1    0   \n",
       "3           0   0   0   0   1       0      1     0      0     0   0   1    0   \n",
       "4           0   0   0   0   1       0      1     0      0     0   0   1    0   \n",
       "...       ...  ..  ..  ..  ..     ...    ...   ...    ...   ...  ..  ..  ...   \n",
       "1454        0   0   0   0   1       1      0     0      0     0   0   1    0   \n",
       "1455        0   0   0   0   1       1      0     0      0     0   0   1    0   \n",
       "1456        0   0   0   0   1       1      0     0      0     0   0   1    0   \n",
       "1457        0   0   0   0   1       0      1     0      0     0   0   0    0   \n",
       "1458        0   0   0   0   1       0      1     0      0     0   0   0    0   \n",
       "\n",
       "      GLQ  LwQ  Rec  Unf  Gable  Gambrel  Hip  Mansard  Shed  CompShg  \\\n",
       "0       0    0    1    0      1        0    0        0     0        1   \n",
       "1       0    0    0    0      0        0    1        0     0        1   \n",
       "2       1    0    0    0      1        0    0        0     0        1   \n",
       "3       1    0    0    0      1        0    0        0     0        1   \n",
       "4       0    0    0    0      1        0    0        0     0        1   \n",
       "...   ...  ...  ...  ...    ...      ...  ...      ...   ...      ...   \n",
       "1454    0    0    0    1      1        0    0        0     0        1   \n",
       "1455    0    0    1    0      1        0    0        0     0        1   \n",
       "1456    0    0    0    0      1        0    0        0     0        1   \n",
       "1457    1    0    0    0      1        0    0        0     0        1   \n",
       "1458    0    1    0    0      1        0    0        0     0        1   \n",
       "\n",
       "      Membran  Metal  Roll  Tar&Grv  WdShake  WdShngl  AsphShn  BrkComm  \\\n",
       "0           0      0     0        0        0        0        0        0   \n",
       "1           0      0     0        0        0        0        0        0   \n",
       "2           0      0     0        0        0        0        0        0   \n",
       "3           0      0     0        0        0        0        0        0   \n",
       "4           0      0     0        0        0        0        0        0   \n",
       "...       ...    ...   ...      ...      ...      ...      ...      ...   \n",
       "1454        0      0     0        0        0        0        0        0   \n",
       "1455        0      0     0        0        0        0        0        0   \n",
       "1456        0      0     0        0        0        0        0        0   \n",
       "1457        0      0     0        0        0        0        0        0   \n",
       "1458        0      0     0        0        0        0        0        0   \n",
       "\n",
       "      BrkFace  CemntBd  HdBoard  ImStucc  MetalSd  Plywood  Stucco  VinylSd  \\\n",
       "0           0        0        0        0        0        0       0        1   \n",
       "1           0        0        0        0        0        0       0        0   \n",
       "2           0        0        0        0        0        0       0        1   \n",
       "3           0        0        0        0        0        0       0        1   \n",
       "4           0        0        1        0        0        0       0        0   \n",
       "...       ...      ...      ...      ...      ...      ...     ...      ...   \n",
       "1454        0        1        0        0        0        0       0        0   \n",
       "1455        0        1        0        0        0        0       0        0   \n",
       "1456        0        0        0        0        0        0       0        1   \n",
       "1457        0        0        1        0        0        0       0        0   \n",
       "1458        0        0        1        0        0        0       0        0   \n",
       "\n",
       "      Wd Sdng  WdShing  Brk Cmn  CmentBd  Other  Wd Shng  None  GasA  GasW  \\\n",
       "0           0        0        0        0      0        0     1     1     0   \n",
       "1           1        0        0        0      0        0     0     1     0   \n",
       "2           0        0        0        0      0        0     1     1     0   \n",
       "3           0        0        0        0      0        0     0     1     0   \n",
       "4           0        0        0        0      0        0     1     1     0   \n",
       "...       ...      ...      ...      ...    ...      ...   ...   ...   ...   \n",
       "1454        0        0        0        1      0        0     1     1     0   \n",
       "1455        0        0        0        1      0        0     1     1     0   \n",
       "1456        0        0        0        0      0        0     1     1     0   \n",
       "1457        0        0        0        0      0        1     1     1     0   \n",
       "1458        0        0        0        0      0        0     0     1     0   \n",
       "\n",
       "      Grav  OthW  Wall  Y  FuseF  FuseP  Mix  SBrkr  Maj2  Min1  Min2  Typ  \\\n",
       "0        0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "1        0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "2        0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "3        0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "4        0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "...    ...   ...   ... ..    ...    ...  ...    ...   ...   ...   ...  ...   \n",
       "1454     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "1455     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "1456     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "1457     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "1458     0     0     0  1      0      0    0      1     0     0     0    1   \n",
       "\n",
       "      Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0          1        0        0        0       0    0  0  \n",
       "1          1        0        0        0       0    0  0  \n",
       "2          1        0        0        0       0    0  0  \n",
       "3          1        0        0        0       0    0  0  \n",
       "4          1        0        0        0       0    1  0  \n",
       "...      ...      ...      ...      ...     ...  ... ..  \n",
       "1454       1        0        0        0       0    0  0  \n",
       "1455       0        0        0        1       0    0  0  \n",
       "1456       0        0        0        0       1    0  0  \n",
       "1457       1        0        0        0       0    0  0  \n",
       "1458       1        0        0        0       0    0  0  \n",
       "\n",
       "[1459 rows x 177 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 177)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_train['SalePrice']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "df_test_new = scaler.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "# # Remove non-numeric columns, columns that have null values\n",
    "# df = df.select_dtypes([np.number]).dropna(axis=1)\n",
    "\n",
    "# all_X = X_train\n",
    "# all_y = y_train\n",
    "\n",
    "# clf = RandomForestClassifier(random_state=1)\n",
    "# selector = RFECV(clf,cv=10)\n",
    "# selector.fit(all_X,all_y)\n",
    "\n",
    "# best_columns = list(all_X.columns[selector.support_])\n",
    "# print(\"Best Columns \\n\"+\"-\"*12+\"\\n{}\\n\".format(best_columns))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_columns=['1stFlrSF', '2ndFlrSF', 'BedroomAbvGr', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtUnfSF', 'EnclosedPorch', 'Fireplaces', 'FullBath', 'GarageArea', 'GarageCars', 'GarageYrBlt', 'GrLivArea', 'HalfBath', 'LotArea', 'LotFrontage', 'MSSubClass', 'MasVnrArea', 'MoSold', 'OpenPorchSF', 'OverallCond', 'OverallQual', 'ScreenPorch', 'TotRmsAbvGrd', 'TotalBsmtSF', 'WoodDeckSF', 'YearBuilt', 'YearRemodAdd', 'YrSold', 'RL', 'Reg', 'Lvl', 'Inside', 'Normal', 'CBlock', 'No', 'GLQ', 'Gable', 'MetalSd', 'VinylSd', 'None', 'Attchd', 'Detchd', 'RFn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_new_train=X_train.copy()\n",
    "# # df_test_new = df_test.copy()\n",
    "# # df_test_new = df_test_new[best_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_new_train=X_new_train[best_columns]\n",
    "# X_new_train = scaler.fit_transform(X_new_train)\n",
    "# df_test_new = scaler.transform(df_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1_space = np.linspace(0, 1, 30)\n",
    "# param_grid = {'l1_ratio': l1_space}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the ElasticNet regressor: elastic_net\n",
    "# elastic_net = ElasticNet()\n",
    "\n",
    "# gm_cv = GridSearchCV(elastic_net, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit it to the training data\n",
    "# gm_cv.fit(X_train,y_train)\n",
    "\n",
    "# # Predict on the test set and compute metrics\n",
    "\n",
    "\n",
    "\n",
    "# # mse = mean_squared_error(df_test, y_pred)\n",
    "# # rmse = math.sqrt(mse)\n",
    "# print(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_params_))\n",
    "# print(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_score_))\n",
    "# # print(\"Tuned ElasticNet R squared: {}\".format(r2))\n",
    "# # print(\"Tuned ElasticNet RMSE: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = gm_cv.predict(df_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xgboost\n",
    "regressor=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Set up the random search with 5-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv.fit(X_new_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor=xgboost.XGBRegressor(base_score=0.75, booster='gbtree', colsample_bylevel=1,\n",
    "#              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "#              importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
    "#              max_depth=5, min_child_weight=2, missing=None, n_estimators=1100,\n",
    "#              n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "#              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "#              silent=None, subsample=1, verbosity=1)\n",
    "\n",
    "regressor = xgboost.XGBRegressor(base_score=0.25, max_depth=2, n_estimators=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_new_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalie_model3.pkl'\n",
    "pickle.dump(regressor, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.drop(['SalePrice'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=regressor.predict(df_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(y_pred)\n",
    "\n",
    "\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new =df_train.copy()\n",
    "df_test_new = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_new.drop(['SalePrice'], axis=1)\n",
    "y_train = df_new['SalePrice']\n",
    "\n",
    "\n",
    "# X_train=df_new[best_columns]\n",
    "# y_train = df_new['SalePrice']\n",
    "# df_test_new = df_test_new[best_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1451, 176)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from numpy.random import seed\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "model = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(50, kernel_initializer = 'he_uniform',activation='relu',input_dim = X_train.shape[1]))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense( 25, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "model.add(Dense( 50, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "model.add(Dense( 1 ,kernel_initializer = 'he_uniform'))\n",
    "\n",
    "# # Compiling the ANN\n",
    "# model.compile(loss='root_mean_squared_error', optimizer='Adamax')\n",
    "\n",
    "# # Fitting the ANN to the Training set\n",
    "# model_history=model.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 50)                8850      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                1300      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 11,476\n",
      "Trainable params: 11,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "optimizer = RMSprop(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "# model.compile(loss='root_mean_squared_error', optimizer='Adamax')\n",
    "model.compile(loss='mean_squared_error', optimizer='Adamax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# seed_value = random.randint(2,200)\n",
    "# seed(seed_value)\n",
    "# np.random.seed(seed_value)\n",
    "# tensorflow.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 33421678592.0000 - val_loss: 25800910848.0000\n",
      "Epoch 2/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 15635783680.0000 - val_loss: 7864817152.0000\n",
      "Epoch 3/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 7460596736.0000 - val_loss: 5521504256.0000\n",
      "Epoch 4/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 6386487296.0000 - val_loss: 5175711744.0000\n",
      "Epoch 5/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 6033845248.0000 - val_loss: 5049955328.0000\n",
      "Epoch 6/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 5765929472.0000 - val_loss: 4951523328.0000\n",
      "Epoch 7/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 5538486784.0000 - val_loss: 4865812480.0000\n",
      "Epoch 8/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 5339909632.0000 - val_loss: 4788939264.0000\n",
      "Epoch 9/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 5146120192.0000 - val_loss: 4712193536.0000\n",
      "Epoch 10/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 4969032192.0000 - val_loss: 4630315008.0000\n",
      "Epoch 11/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 4776418304.0000 - val_loss: 4560017920.0000\n",
      "Epoch 12/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 4603900928.0000 - val_loss: 4472300032.0000\n",
      "Epoch 13/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 4419390464.0000 - val_loss: 4393641472.0000\n",
      "Epoch 14/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 4265427712.0000 - val_loss: 4311944704.0000\n",
      "Epoch 15/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 4105408256.0000 - val_loss: 4241279488.0000\n",
      "Epoch 16/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 3959218176.0000 - val_loss: 4166909952.0000\n",
      "Epoch 17/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 3816239872.0000 - val_loss: 4091287296.0000\n",
      "Epoch 18/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 3680047872.0000 - val_loss: 4022876672.0000\n",
      "Epoch 19/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 3564302848.0000 - val_loss: 3955735296.0000\n",
      "Epoch 20/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 3437709056.0000 - val_loss: 3916798976.0000\n",
      "Epoch 21/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 3336673280.0000 - val_loss: 3850031872.0000\n",
      "Epoch 22/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 3225608960.0000 - val_loss: 3785541888.0000\n",
      "Epoch 23/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 3091258880.0000 - val_loss: 3743529216.0000\n",
      "Epoch 24/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2960271360.0000 - val_loss: 3648442624.0000\n",
      "Epoch 25/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2843246848.0000 - val_loss: 3539207168.0000\n",
      "Epoch 26/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2707397120.0000 - val_loss: 3460120064.0000\n",
      "Epoch 27/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2587356928.0000 - val_loss: 3378130944.0000\n",
      "Epoch 28/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2463465728.0000 - val_loss: 3322397184.0000\n",
      "Epoch 29/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2342858752.0000 - val_loss: 3285899008.0000\n",
      "Epoch 30/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2231601664.0000 - val_loss: 3176585472.0000\n",
      "Epoch 31/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2119028352.0000 - val_loss: 3198801920.0000\n",
      "Epoch 32/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2018172288.0000 - val_loss: 3092692224.0000\n",
      "Epoch 33/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1925486080.0000 - val_loss: 3092796416.0000\n",
      "Epoch 34/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1842566400.0000 - val_loss: 3184571904.0000\n",
      "Epoch 35/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1777719552.0000 - val_loss: 3108716544.0000\n",
      "Epoch 36/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1722683392.0000 - val_loss: 3116968192.0000\n",
      "Epoch 37/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1680011008.0000 - val_loss: 3226972416.0000\n",
      "Epoch 38/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1668798592.0000 - val_loss: 3202770688.0000\n",
      "Epoch 39/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1620283392.0000 - val_loss: 3196421120.0000\n",
      "Epoch 40/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1615447552.0000 - val_loss: 3229375232.0000\n",
      "Epoch 41/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1595922432.0000 - val_loss: 3187224320.0000\n",
      "Epoch 42/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1585087360.0000 - val_loss: 3272904960.0000\n",
      "Epoch 43/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1580222080.0000 - val_loss: 3261315840.0000\n",
      "Epoch 44/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1573475968.0000 - val_loss: 3345390848.0000\n",
      "Epoch 45/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1554635648.0000 - val_loss: 3378068224.0000\n",
      "Epoch 46/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1587452544.0000 - val_loss: 3383991552.0000\n",
      "Epoch 47/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1565051008.0000 - val_loss: 3276168192.0000\n",
      "Epoch 48/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1555377920.0000 - val_loss: 3278341376.0000\n",
      "Epoch 49/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1557853568.0000 - val_loss: 3302323968.0000\n",
      "Epoch 50/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1545195648.0000 - val_loss: 3328108800.0000\n",
      "Epoch 51/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1550634240.0000 - val_loss: 3320562688.0000\n",
      "Epoch 52/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1536986368.0000 - val_loss: 3364672512.0000\n",
      "Epoch 53/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1549157632.0000 - val_loss: 3271267840.0000\n",
      "Epoch 54/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1541001472.0000 - val_loss: 3287869184.0000\n",
      "Epoch 55/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1536607232.0000 - val_loss: 3394615552.0000\n",
      "Epoch 56/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1544141312.0000 - val_loss: 3300041984.0000\n",
      "Epoch 57/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1530082816.0000 - val_loss: 3307476736.0000\n",
      "Epoch 58/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1523297664.0000 - val_loss: 3280323072.0000\n",
      "Epoch 59/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1525260032.0000 - val_loss: 3305917696.0000\n",
      "Epoch 60/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1530533632.0000 - val_loss: 3351172864.0000\n",
      "Epoch 61/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1532658816.0000 - val_loss: 3312749312.0000\n",
      "Epoch 62/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1516931712.0000 - val_loss: 3336586496.0000\n",
      "Epoch 63/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1515831424.0000 - val_loss: 3368060672.0000\n",
      "Epoch 64/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1521273344.0000 - val_loss: 3303300864.0000\n",
      "Epoch 65/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1511415424.0000 - val_loss: 3337178112.0000\n",
      "Epoch 66/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1509416064.0000 - val_loss: 3368740864.0000\n",
      "Epoch 67/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1506973824.0000 - val_loss: 3346915072.0000\n",
      "Epoch 68/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1507011072.0000 - val_loss: 3438492672.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1524036608.0000 - val_loss: 3360658688.0000\n",
      "Epoch 70/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1504151680.0000 - val_loss: 3431832832.0000\n",
      "Epoch 71/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1495535488.0000 - val_loss: 3299591936.0000\n",
      "Epoch 72/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1505379072.0000 - val_loss: 3380787712.0000\n",
      "Epoch 73/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1506292608.0000 - val_loss: 3537355520.0000\n",
      "Epoch 74/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1501708672.0000 - val_loss: 3329007872.0000\n",
      "Epoch 75/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1502801152.0000 - val_loss: 3330233344.0000\n",
      "Epoch 76/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1494685824.0000 - val_loss: 3336644352.0000\n",
      "Epoch 77/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1493927168.0000 - val_loss: 3345552128.0000\n",
      "Epoch 78/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1490225536.0000 - val_loss: 3293392128.0000\n",
      "Epoch 79/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1498517888.0000 - val_loss: 3333728000.0000\n",
      "Epoch 80/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1492026496.0000 - val_loss: 3337971712.0000\n",
      "Epoch 81/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1491308800.0000 - val_loss: 3350345728.0000\n",
      "Epoch 82/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1487187968.0000 - val_loss: 3340206592.0000\n",
      "Epoch 83/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1486497664.0000 - val_loss: 3290489088.0000\n",
      "Epoch 84/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1487723008.0000 - val_loss: 3380005888.0000\n",
      "Epoch 85/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1481625600.0000 - val_loss: 3308176384.0000\n",
      "Epoch 86/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1476699136.0000 - val_loss: 3466478848.0000\n",
      "Epoch 87/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1476398464.0000 - val_loss: 3451808768.0000\n",
      "Epoch 88/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1485301120.0000 - val_loss: 3292172032.0000\n",
      "Epoch 89/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1484347904.0000 - val_loss: 3307922688.0000\n",
      "Epoch 90/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1480703616.0000 - val_loss: 3327539200.0000\n",
      "Epoch 91/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1467757952.0000 - val_loss: 3380831488.0000\n",
      "Epoch 92/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1464070144.0000 - val_loss: 3351456768.0000\n",
      "Epoch 93/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1469617664.0000 - val_loss: 3304451840.0000\n",
      "Epoch 94/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1466508416.0000 - val_loss: 3298904832.0000\n",
      "Epoch 95/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1472612352.0000 - val_loss: 3281456128.0000\n",
      "Epoch 96/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1470305408.0000 - val_loss: 3344635392.0000\n",
      "Epoch 97/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1456786048.0000 - val_loss: 3326814208.0000\n",
      "Epoch 98/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1462551424.0000 - val_loss: 3306836992.0000\n",
      "Epoch 99/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1457408384.0000 - val_loss: 3292368384.0000\n",
      "Epoch 100/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1456232448.0000 - val_loss: 3309278976.0000\n",
      "Epoch 101/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1451119232.0000 - val_loss: 3278142720.0000\n",
      "Epoch 102/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1447593472.0000 - val_loss: 3442266112.0000\n",
      "Epoch 103/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1467082368.0000 - val_loss: 3267280896.0000\n",
      "Epoch 104/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1448833920.0000 - val_loss: 3283360256.0000\n",
      "Epoch 105/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1445305472.0000 - val_loss: 3333377024.0000\n",
      "Epoch 106/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1437923712.0000 - val_loss: 3232254720.0000\n",
      "Epoch 107/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1448573312.0000 - val_loss: 3265638912.0000\n",
      "Epoch 108/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1443975040.0000 - val_loss: 3314238464.0000\n",
      "Epoch 109/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1441785728.0000 - val_loss: 3311615744.0000\n",
      "Epoch 110/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1438981504.0000 - val_loss: 3460633344.0000\n",
      "Epoch 111/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1452964992.0000 - val_loss: 3241291520.0000\n",
      "Epoch 112/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1438537088.0000 - val_loss: 3388878592.0000\n",
      "Epoch 113/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1436059520.0000 - val_loss: 3291430400.0000\n",
      "Epoch 114/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1425558528.0000 - val_loss: 3526119424.0000\n",
      "Epoch 115/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1428116608.0000 - val_loss: 3327392256.0000\n",
      "Epoch 116/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1436903040.0000 - val_loss: 3377904128.0000\n",
      "Epoch 117/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1428465280.0000 - val_loss: 3280359424.0000\n",
      "Epoch 118/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1434156288.0000 - val_loss: 3270628096.0000\n",
      "Epoch 119/1000\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 1421878016.0000 - val_loss: 3253243648.0000\n",
      "Epoch 120/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1420138496.0000 - val_loss: 3325268224.0000\n",
      "Epoch 121/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1420057472.0000 - val_loss: 3249112832.0000\n",
      "Epoch 122/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1412763008.0000 - val_loss: 3247840512.0000\n",
      "Epoch 123/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1406250496.0000 - val_loss: 3285405952.0000\n",
      "Epoch 124/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1393434240.0000 - val_loss: 3321538304.0000\n",
      "Epoch 125/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1408819072.0000 - val_loss: 3251238400.0000\n",
      "Epoch 126/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1404801408.0000 - val_loss: 3381575168.0000\n",
      "Epoch 127/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1400945152.0000 - val_loss: 3343628288.0000\n",
      "Epoch 128/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1406434688.0000 - val_loss: 3281828608.0000\n",
      "Epoch 129/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1405970432.0000 - val_loss: 3261703680.0000\n",
      "Epoch 130/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1403123584.0000 - val_loss: 3378657792.0000\n",
      "Epoch 131/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1399655296.0000 - val_loss: 3397337344.0000\n",
      "Epoch 132/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1401098880.0000 - val_loss: 3318466048.0000\n",
      "Epoch 133/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1397029888.0000 - val_loss: 3255498240.0000\n",
      "Epoch 134/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1393017344.0000 - val_loss: 3255878912.0000\n",
      "Epoch 135/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1391066496.0000 - val_loss: 3279572992.0000\n",
      "Epoch 136/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 1398833920.0000 - val_loss: 3348250112.0000\n",
      "Epoch 137/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1387634560.0000 - val_loss: 3334404608.0000\n",
      "Epoch 138/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1405335680.0000 - val_loss: 3273329920.0000\n",
      "Epoch 139/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1376536832.0000 - val_loss: 3332025600.0000\n",
      "Epoch 140/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1388538752.0000 - val_loss: 3365408256.0000\n",
      "Epoch 141/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1379691392.0000 - val_loss: 3260133888.0000\n",
      "Epoch 142/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1384354304.0000 - val_loss: 3289916928.0000\n",
      "Epoch 143/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1378765184.0000 - val_loss: 3318106368.0000\n",
      "Epoch 144/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1403277952.0000 - val_loss: 3382451456.0000\n",
      "Epoch 145/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1378688896.0000 - val_loss: 3302541056.0000\n",
      "Epoch 146/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1374369408.0000 - val_loss: 3283084800.0000\n",
      "Epoch 147/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1377064960.0000 - val_loss: 3275433216.0000\n",
      "Epoch 148/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1378541568.0000 - val_loss: 3305342976.0000\n",
      "Epoch 149/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1383952640.0000 - val_loss: 3259006208.0000\n",
      "Epoch 150/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1364156800.0000 - val_loss: 3334454528.0000\n",
      "Epoch 151/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1364642688.0000 - val_loss: 3305935360.0000\n",
      "Epoch 152/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1368405632.0000 - val_loss: 3333236224.0000\n",
      "Epoch 153/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1365583744.0000 - val_loss: 3301462272.0000\n",
      "Epoch 154/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1364562304.0000 - val_loss: 3287144960.0000\n",
      "Epoch 155/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1359138048.0000 - val_loss: 3282144000.0000\n",
      "Epoch 156/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1348837120.0000 - val_loss: 3338215936.0000\n",
      "Epoch 157/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1356232704.0000 - val_loss: 3306680320.0000\n",
      "Epoch 158/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1354542720.0000 - val_loss: 3264717568.0000\n",
      "Epoch 159/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1349125504.0000 - val_loss: 3239962112.0000\n",
      "Epoch 160/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1345714944.0000 - val_loss: 3251854592.0000\n",
      "Epoch 161/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1383177856.0000 - val_loss: 3251901696.0000\n",
      "Epoch 162/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1346090624.0000 - val_loss: 3256006912.0000\n",
      "Epoch 163/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1358311168.0000 - val_loss: 3259797248.0000\n",
      "Epoch 164/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1350883968.0000 - val_loss: 3205692416.0000\n",
      "Epoch 165/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1354052096.0000 - val_loss: 3227464960.0000\n",
      "Epoch 166/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1335098240.0000 - val_loss: 3327565824.0000\n",
      "Epoch 167/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1333587072.0000 - val_loss: 3273899776.0000\n",
      "Epoch 168/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1338402176.0000 - val_loss: 3202051840.0000\n",
      "Epoch 169/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1349243392.0000 - val_loss: 3253281280.0000\n",
      "Epoch 170/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1335976576.0000 - val_loss: 3271297280.0000\n",
      "Epoch 171/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1336013184.0000 - val_loss: 3262710784.0000\n",
      "Epoch 172/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1333303424.0000 - val_loss: 3346019584.0000\n",
      "Epoch 173/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1324113664.0000 - val_loss: 3177880832.0000\n",
      "Epoch 174/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1342383744.0000 - val_loss: 3182611968.0000\n",
      "Epoch 175/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1320280064.0000 - val_loss: 3296105472.0000\n",
      "Epoch 176/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1330319744.0000 - val_loss: 3235395328.0000\n",
      "Epoch 177/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1320968320.0000 - val_loss: 3264569600.0000\n",
      "Epoch 178/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1328610176.0000 - val_loss: 3278326528.0000\n",
      "Epoch 179/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1315162496.0000 - val_loss: 3255819264.0000\n",
      "Epoch 180/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1320388608.0000 - val_loss: 3295072768.0000\n",
      "Epoch 181/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1323272960.0000 - val_loss: 3212730368.0000\n",
      "Epoch 182/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1313111552.0000 - val_loss: 3163974144.0000\n",
      "Epoch 183/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1325303296.0000 - val_loss: 3316544256.0000\n",
      "Epoch 184/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1317742848.0000 - val_loss: 3226033408.0000\n",
      "Epoch 185/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1320591232.0000 - val_loss: 3206934016.0000\n",
      "Epoch 186/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1311379968.0000 - val_loss: 3194625280.0000\n",
      "Epoch 187/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1293895168.0000 - val_loss: 3244454656.0000\n",
      "Epoch 188/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1307529216.0000 - val_loss: 3147970048.0000\n",
      "Epoch 189/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1314673408.0000 - val_loss: 3154096384.0000\n",
      "Epoch 190/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1301855744.0000 - val_loss: 3210902528.0000\n",
      "Epoch 191/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1304463360.0000 - val_loss: 3223911168.0000\n",
      "Epoch 192/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1307205632.0000 - val_loss: 3279666944.0000\n",
      "Epoch 193/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1301786752.0000 - val_loss: 3192711168.0000\n",
      "Epoch 194/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1301359360.0000 - val_loss: 3262710272.0000\n",
      "Epoch 195/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1298197504.0000 - val_loss: 3194293504.0000\n",
      "Epoch 196/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1300599552.0000 - val_loss: 3216636672.0000\n",
      "Epoch 197/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1280834560.0000 - val_loss: 3124484608.0000\n",
      "Epoch 198/1000\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 1289960064.0000 - val_loss: 3188635136.0000\n",
      "Epoch 199/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1282065664.0000 - val_loss: 3313743360.0000\n",
      "Epoch 200/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1284944000.0000 - val_loss: 3194719744.0000\n",
      "Epoch 201/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1296254976.0000 - val_loss: 3244083200.0000\n",
      "Epoch 202/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1289863552.0000 - val_loss: 3194976768.0000\n",
      "Epoch 203/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 1282410624.0000 - val_loss: 3208434944.0000\n",
      "Epoch 204/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1283730944.0000 - val_loss: 3219111168.0000\n",
      "Epoch 205/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1278747392.0000 - val_loss: 3250772224.0000\n",
      "Epoch 206/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1278624896.0000 - val_loss: 3156236544.0000\n",
      "Epoch 207/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1278125952.0000 - val_loss: 3122805504.0000\n",
      "Epoch 208/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1273366016.0000 - val_loss: 3171645952.0000\n",
      "Epoch 209/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1272611712.0000 - val_loss: 3122475008.0000\n",
      "Epoch 210/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1273046784.0000 - val_loss: 3205207808.0000\n",
      "Epoch 211/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1274465536.0000 - val_loss: 3186082304.0000\n",
      "Epoch 212/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1271477888.0000 - val_loss: 3210761216.0000\n",
      "Epoch 213/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1270952448.0000 - val_loss: 3163527680.0000\n",
      "Epoch 214/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1272860544.0000 - val_loss: 3157957888.0000\n",
      "Epoch 215/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1275098752.0000 - val_loss: 3134204416.0000\n",
      "Epoch 216/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1267694336.0000 - val_loss: 3139109120.0000\n",
      "Epoch 217/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1271861120.0000 - val_loss: 3107648512.0000\n",
      "Epoch 218/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1262629504.0000 - val_loss: 3186640640.0000\n",
      "Epoch 219/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1272409088.0000 - val_loss: 3096876544.0000\n",
      "Epoch 220/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1265725184.0000 - val_loss: 3095601664.0000\n",
      "Epoch 221/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1266735232.0000 - val_loss: 3106396928.0000\n",
      "Epoch 222/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1265075584.0000 - val_loss: 3214489344.0000\n",
      "Epoch 223/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1258733440.0000 - val_loss: 3108986112.0000\n",
      "Epoch 224/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1258729728.0000 - val_loss: 3140260608.0000\n",
      "Epoch 225/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1269105792.0000 - val_loss: 3134902016.0000\n",
      "Epoch 226/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1259533568.0000 - val_loss: 3237612288.0000\n",
      "Epoch 227/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1250756608.0000 - val_loss: 3154106624.0000\n",
      "Epoch 228/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1254636160.0000 - val_loss: 3114520832.0000\n",
      "Epoch 229/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1254256256.0000 - val_loss: 3071962624.0000\n",
      "Epoch 230/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1260152832.0000 - val_loss: 3144017408.0000\n",
      "Epoch 231/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1262481280.0000 - val_loss: 3061731584.0000\n",
      "Epoch 232/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1245299456.0000 - val_loss: 3161906944.0000\n",
      "Epoch 233/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1249819264.0000 - val_loss: 3255241216.0000\n",
      "Epoch 234/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1243144960.0000 - val_loss: 3197143040.0000\n",
      "Epoch 235/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1255902976.0000 - val_loss: 3141472256.0000\n",
      "Epoch 236/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1242297984.0000 - val_loss: 3151116032.0000\n",
      "Epoch 237/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1248974080.0000 - val_loss: 3074528512.0000\n",
      "Epoch 238/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1240628352.0000 - val_loss: 3136178432.0000\n",
      "Epoch 239/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1235964672.0000 - val_loss: 3132896000.0000\n",
      "Epoch 240/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1238953088.0000 - val_loss: 3068843264.0000\n",
      "Epoch 241/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1236468864.0000 - val_loss: 3119138304.0000\n",
      "Epoch 242/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1231801344.0000 - val_loss: 3083803136.0000\n",
      "Epoch 243/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1241965312.0000 - val_loss: 3072165120.0000\n",
      "Epoch 244/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1229181568.0000 - val_loss: 3068562944.0000\n",
      "Epoch 245/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1240610176.0000 - val_loss: 3101752320.0000\n",
      "Epoch 246/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1233985024.0000 - val_loss: 3240484864.0000\n",
      "Epoch 247/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1227947776.0000 - val_loss: 3127254528.0000\n",
      "Epoch 248/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1235943680.0000 - val_loss: 3083145216.0000\n",
      "Epoch 249/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1232175360.0000 - val_loss: 3109347072.0000\n",
      "Epoch 250/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1223506944.0000 - val_loss: 3094164480.0000\n",
      "Epoch 251/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1220655744.0000 - val_loss: 3162966272.0000\n",
      "Epoch 252/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1233526912.0000 - val_loss: 3153395200.0000\n",
      "Epoch 253/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1228569984.0000 - val_loss: 3122988544.0000\n",
      "Epoch 254/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1217670144.0000 - val_loss: 3112663040.0000\n",
      "Epoch 255/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1227979136.0000 - val_loss: 3120469504.0000\n",
      "Epoch 256/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1208254976.0000 - val_loss: 3058622464.0000\n",
      "Epoch 257/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1221039488.0000 - val_loss: 3270202368.0000\n",
      "Epoch 258/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1213456384.0000 - val_loss: 3093436160.0000\n",
      "Epoch 259/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1231536896.0000 - val_loss: 3073224960.0000\n",
      "Epoch 260/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1215318912.0000 - val_loss: 3073892096.0000\n",
      "Epoch 261/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1207271168.0000 - val_loss: 3114821120.0000\n",
      "Epoch 262/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1212655744.0000 - val_loss: 3018278144.0000\n",
      "Epoch 263/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1219279360.0000 - val_loss: 2999480576.0000\n",
      "Epoch 264/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1238543744.0000 - val_loss: 3004995840.0000\n",
      "Epoch 265/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1220654592.0000 - val_loss: 3017207808.0000\n",
      "Epoch 266/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1209424896.0000 - val_loss: 3080333824.0000\n",
      "Epoch 267/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1212247168.0000 - val_loss: 3077172480.0000\n",
      "Epoch 268/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1206124544.0000 - val_loss: 3066440704.0000\n",
      "Epoch 269/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1201495040.0000 - val_loss: 3180793344.0000\n",
      "Epoch 270/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 1ms/step - loss: 1206100864.0000 - val_loss: 3001380352.0000\n",
      "Epoch 271/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1219421696.0000 - val_loss: 3029374208.0000\n",
      "Epoch 272/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1205394432.0000 - val_loss: 3026717440.0000\n",
      "Epoch 273/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1208913152.0000 - val_loss: 3032922624.0000\n",
      "Epoch 274/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1205603328.0000 - val_loss: 3063968256.0000\n",
      "Epoch 275/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1199106816.0000 - val_loss: 3118829312.0000\n",
      "Epoch 276/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1205327744.0000 - val_loss: 3025534720.0000\n",
      "Epoch 277/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1202721024.0000 - val_loss: 3044290560.0000\n",
      "Epoch 278/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1204825984.0000 - val_loss: 3086909696.0000\n",
      "Epoch 279/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1205325056.0000 - val_loss: 3003309056.0000\n",
      "Epoch 280/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1194261888.0000 - val_loss: 3018731520.0000\n",
      "Epoch 281/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1202029952.0000 - val_loss: 3075076608.0000\n",
      "Epoch 282/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1190396416.0000 - val_loss: 3007329280.0000\n",
      "Epoch 283/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1206926720.0000 - val_loss: 3029521408.0000\n",
      "Epoch 284/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1196712704.0000 - val_loss: 3124983296.0000\n",
      "Epoch 285/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1201437056.0000 - val_loss: 3007231232.0000\n",
      "Epoch 286/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1199634304.0000 - val_loss: 3114308352.0000\n",
      "Epoch 287/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1206442112.0000 - val_loss: 3040959744.0000\n",
      "Epoch 288/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1181411584.0000 - val_loss: 3073008128.0000\n",
      "Epoch 289/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1191017088.0000 - val_loss: 3054552320.0000\n",
      "Epoch 290/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1204169600.0000 - val_loss: 3005812736.0000\n",
      "Epoch 291/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1180154624.0000 - val_loss: 3118555392.0000\n",
      "Epoch 292/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1189169280.0000 - val_loss: 3124739072.0000\n",
      "Epoch 293/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1191118848.0000 - val_loss: 3016956160.0000\n",
      "Epoch 294/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1186452480.0000 - val_loss: 3101355776.0000\n",
      "Epoch 295/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1185343104.0000 - val_loss: 3020722176.0000\n",
      "Epoch 296/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1177294592.0000 - val_loss: 3119220736.0000\n",
      "Epoch 297/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1183920896.0000 - val_loss: 3025919744.0000\n",
      "Epoch 298/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1182979968.0000 - val_loss: 2992700672.0000\n",
      "Epoch 299/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1171467776.0000 - val_loss: 2990861824.0000\n",
      "Epoch 300/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1190946176.0000 - val_loss: 3047331328.0000\n",
      "Epoch 301/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1180891520.0000 - val_loss: 3051372288.0000\n",
      "Epoch 302/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1182886784.0000 - val_loss: 3152495616.0000\n",
      "Epoch 303/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1171002368.0000 - val_loss: 3116196864.0000\n",
      "Epoch 304/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1178567680.0000 - val_loss: 3008631552.0000\n",
      "Epoch 305/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1208864512.0000 - val_loss: 3040950016.0000\n",
      "Epoch 306/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1168991872.0000 - val_loss: 3055739392.0000\n",
      "Epoch 307/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1169083648.0000 - val_loss: 3058461952.0000\n",
      "Epoch 308/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1162904704.0000 - val_loss: 3011097344.0000\n",
      "Epoch 309/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1169197696.0000 - val_loss: 3011271168.0000\n",
      "Epoch 310/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1187461248.0000 - val_loss: 2972780032.0000\n",
      "Epoch 311/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1164762240.0000 - val_loss: 3097460736.0000\n",
      "Epoch 312/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1170932864.0000 - val_loss: 3027083008.0000\n",
      "Epoch 313/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1179444736.0000 - val_loss: 3104799488.0000\n",
      "Epoch 314/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1187499264.0000 - val_loss: 3001106432.0000\n",
      "Epoch 315/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1167638656.0000 - val_loss: 2985822464.0000\n",
      "Epoch 316/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1172545792.0000 - val_loss: 3036707072.0000\n",
      "Epoch 317/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1175342848.0000 - val_loss: 2961737472.0000\n",
      "Epoch 318/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1166688256.0000 - val_loss: 3029028096.0000\n",
      "Epoch 319/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1159260672.0000 - val_loss: 2975034624.0000\n",
      "Epoch 320/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1160928640.0000 - val_loss: 3143346176.0000\n",
      "Epoch 321/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1168268800.0000 - val_loss: 2965195776.0000\n",
      "Epoch 322/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1170571904.0000 - val_loss: 3048710912.0000\n",
      "Epoch 323/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1158577920.0000 - val_loss: 2958260224.0000\n",
      "Epoch 324/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1155408256.0000 - val_loss: 2981190400.0000\n",
      "Epoch 325/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1176363520.0000 - val_loss: 2935863296.0000\n",
      "Epoch 326/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1150599936.0000 - val_loss: 3086910976.0000\n",
      "Epoch 327/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1164630272.0000 - val_loss: 2948290816.0000\n",
      "Epoch 328/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1152032640.0000 - val_loss: 3027621376.0000\n",
      "Epoch 329/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1154568192.0000 - val_loss: 3017980160.0000\n",
      "Epoch 330/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1163784960.0000 - val_loss: 3080554752.0000\n",
      "Epoch 331/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1160094720.0000 - val_loss: 2932195584.0000\n",
      "Epoch 332/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1147332992.0000 - val_loss: 3041342976.0000\n",
      "Epoch 333/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1165777664.0000 - val_loss: 2940832768.0000\n",
      "Epoch 334/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1152559360.0000 - val_loss: 2940427776.0000\n",
      "Epoch 335/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1160600192.0000 - val_loss: 3188935680.0000\n",
      "Epoch 336/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1159212544.0000 - val_loss: 2948126720.0000\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 1154277376.0000 - val_loss: 2968935424.0000\n",
      "Epoch 338/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1144396800.0000 - val_loss: 2935248896.0000\n",
      "Epoch 339/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1143239424.0000 - val_loss: 2924206848.0000\n",
      "Epoch 340/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1160998528.0000 - val_loss: 2944375040.0000\n",
      "Epoch 341/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1147776128.0000 - val_loss: 2928063744.0000\n",
      "Epoch 342/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1140320128.0000 - val_loss: 2952763392.0000\n",
      "Epoch 343/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1145482368.0000 - val_loss: 2951418112.0000\n",
      "Epoch 344/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1134529024.0000 - val_loss: 2903239424.0000\n",
      "Epoch 345/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1144062080.0000 - val_loss: 2973627392.0000\n",
      "Epoch 346/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1138212352.0000 - val_loss: 2933989632.0000\n",
      "Epoch 347/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1134710784.0000 - val_loss: 2965776384.0000\n",
      "Epoch 348/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1135545216.0000 - val_loss: 2972037888.0000\n",
      "Epoch 349/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1155507968.0000 - val_loss: 2967072256.0000\n",
      "Epoch 350/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1155779840.0000 - val_loss: 2926048768.0000\n",
      "Epoch 351/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1141145088.0000 - val_loss: 2918337280.0000\n",
      "Epoch 352/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1150918656.0000 - val_loss: 2960023040.0000\n",
      "Epoch 353/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1135093632.0000 - val_loss: 2917358080.0000\n",
      "Epoch 354/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1132036864.0000 - val_loss: 3001756160.0000\n",
      "Epoch 355/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1157876736.0000 - val_loss: 2976489472.0000\n",
      "Epoch 356/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1145314176.0000 - val_loss: 2884036608.0000\n",
      "Epoch 357/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1129794304.0000 - val_loss: 2986892032.0000\n",
      "Epoch 358/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1127921920.0000 - val_loss: 3087402752.0000\n",
      "Epoch 359/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1140814720.0000 - val_loss: 2942021632.0000\n",
      "Epoch 360/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1161319296.0000 - val_loss: 2941498112.0000\n",
      "Epoch 361/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1151012992.0000 - val_loss: 2926480128.0000\n",
      "Epoch 362/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1125515392.0000 - val_loss: 2910924032.0000\n",
      "Epoch 363/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1137849856.0000 - val_loss: 2966528768.0000\n",
      "Epoch 364/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1139199488.0000 - val_loss: 2864102656.0000\n",
      "Epoch 365/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1136711168.0000 - val_loss: 3052849920.0000\n",
      "Epoch 366/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1125685248.0000 - val_loss: 2962708736.0000\n",
      "Epoch 367/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1124525312.0000 - val_loss: 2884928768.0000\n",
      "Epoch 368/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1122161152.0000 - val_loss: 2936531712.0000\n",
      "Epoch 369/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1119129600.0000 - val_loss: 2907660288.0000\n",
      "Epoch 370/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1120175488.0000 - val_loss: 2883867136.0000\n",
      "Epoch 371/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1122256256.0000 - val_loss: 2904480256.0000\n",
      "Epoch 372/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1113704832.0000 - val_loss: 2848744704.0000\n",
      "Epoch 373/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1109500672.0000 - val_loss: 2966503680.0000\n",
      "Epoch 374/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1119442432.0000 - val_loss: 2946333696.0000\n",
      "Epoch 375/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1116810112.0000 - val_loss: 3013239552.0000\n",
      "Epoch 376/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1131438592.0000 - val_loss: 2846332160.0000\n",
      "Epoch 377/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1112809856.0000 - val_loss: 2845469696.0000\n",
      "Epoch 378/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1109233920.0000 - val_loss: 2872277248.0000\n",
      "Epoch 379/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1128156288.0000 - val_loss: 3053303552.0000\n",
      "Epoch 380/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1118010496.0000 - val_loss: 3021514496.0000\n",
      "Epoch 381/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1114452992.0000 - val_loss: 3004110080.0000\n",
      "Epoch 382/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1119153024.0000 - val_loss: 2869001472.0000\n",
      "Epoch 383/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1113004416.0000 - val_loss: 3032125184.0000\n",
      "Epoch 384/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1109556224.0000 - val_loss: 2946956544.0000\n",
      "Epoch 385/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1112050048.0000 - val_loss: 2861755392.0000\n",
      "Epoch 386/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1135134080.0000 - val_loss: 2851400448.0000\n",
      "Epoch 387/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1106496000.0000 - val_loss: 2889218560.0000\n",
      "Epoch 388/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1101311744.0000 - val_loss: 2920559360.0000\n",
      "Epoch 389/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1113443968.0000 - val_loss: 2864768000.0000\n",
      "Epoch 390/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1108540032.0000 - val_loss: 2883220224.0000\n",
      "Epoch 391/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1095310080.0000 - val_loss: 2844708352.0000\n",
      "Epoch 392/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1107548288.0000 - val_loss: 2870377984.0000\n",
      "Epoch 393/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1103766528.0000 - val_loss: 2812905216.0000\n",
      "Epoch 394/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1123408000.0000 - val_loss: 2894752768.0000\n",
      "Epoch 395/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1098267776.0000 - val_loss: 2832225536.0000\n",
      "Epoch 396/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1097265536.0000 - val_loss: 2913162496.0000\n",
      "Epoch 397/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1105609216.0000 - val_loss: 3039498496.0000\n",
      "Epoch 398/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1105367296.0000 - val_loss: 2907453952.0000\n",
      "Epoch 399/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1105556224.0000 - val_loss: 2778166016.0000\n",
      "Epoch 400/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1097196160.0000 - val_loss: 2772128768.0000\n",
      "Epoch 401/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1102889344.0000 - val_loss: 2818229248.0000\n",
      "Epoch 402/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1109840512.0000 - val_loss: 2929792000.0000\n",
      "Epoch 403/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1084953984.0000 - val_loss: 3150278144.0000\n",
      "Epoch 404/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 1100073600.0000 - val_loss: 2826818048.0000\n",
      "Epoch 405/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1108764928.0000 - val_loss: 2789162240.0000\n",
      "Epoch 406/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1098084096.0000 - val_loss: 2838730752.0000\n",
      "Epoch 407/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1082038272.0000 - val_loss: 2850834432.0000\n",
      "Epoch 408/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1097360768.0000 - val_loss: 3004549376.0000\n",
      "Epoch 409/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1087158144.0000 - val_loss: 2812503040.0000\n",
      "Epoch 410/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1090865280.0000 - val_loss: 2846748416.0000\n",
      "Epoch 411/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1097135872.0000 - val_loss: 2782883584.0000\n",
      "Epoch 412/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1091825920.0000 - val_loss: 2844645632.0000\n",
      "Epoch 413/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1089236864.0000 - val_loss: 2783634688.0000\n",
      "Epoch 414/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1104742272.0000 - val_loss: 3009629440.0000\n",
      "Epoch 415/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1090935424.0000 - val_loss: 2768147712.0000\n",
      "Epoch 416/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1078764544.0000 - val_loss: 2901861888.0000\n",
      "Epoch 417/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1079837824.0000 - val_loss: 2748224000.0000\n",
      "Epoch 418/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1069395072.0000 - val_loss: 2782490112.0000\n",
      "Epoch 419/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1079072384.0000 - val_loss: 2849409024.0000\n",
      "Epoch 420/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1080462208.0000 - val_loss: 2819164928.0000\n",
      "Epoch 421/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1081386880.0000 - val_loss: 2791730688.0000\n",
      "Epoch 422/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1082072704.0000 - val_loss: 2788492800.0000\n",
      "Epoch 423/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1073147264.0000 - val_loss: 2797967872.0000\n",
      "Epoch 424/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1073043392.0000 - val_loss: 2807434240.0000\n",
      "Epoch 425/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1081936256.0000 - val_loss: 2772437760.0000\n",
      "Epoch 426/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1064939456.0000 - val_loss: 2745633024.0000\n",
      "Epoch 427/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1069364672.0000 - val_loss: 2796103680.0000\n",
      "Epoch 428/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1064525568.0000 - val_loss: 2772011008.0000\n",
      "Epoch 429/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1074669568.0000 - val_loss: 2709586944.0000\n",
      "Epoch 430/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1077830656.0000 - val_loss: 2795866624.0000\n",
      "Epoch 431/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1060973120.0000 - val_loss: 2781814528.0000\n",
      "Epoch 432/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1066673984.0000 - val_loss: 2777911040.0000\n",
      "Epoch 433/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1058742464.0000 - val_loss: 2820294656.0000\n",
      "Epoch 434/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1063858304.0000 - val_loss: 2780311552.0000\n",
      "Epoch 435/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1067559872.0000 - val_loss: 2702622464.0000\n",
      "Epoch 436/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1057746432.0000 - val_loss: 2809047296.0000\n",
      "Epoch 437/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1082656512.0000 - val_loss: 2743410176.0000\n",
      "Epoch 438/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1056931072.0000 - val_loss: 2810469632.0000\n",
      "Epoch 439/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1061272384.0000 - val_loss: 2710231808.0000\n",
      "Epoch 440/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1072613696.0000 - val_loss: 2800098816.0000\n",
      "Epoch 441/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1053898624.0000 - val_loss: 2779878656.0000\n",
      "Epoch 442/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1057660672.0000 - val_loss: 3036977408.0000\n",
      "Epoch 443/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1071407360.0000 - val_loss: 2892069120.0000\n",
      "Epoch 444/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1050470464.0000 - val_loss: 2783842048.0000\n",
      "Epoch 445/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1065727360.0000 - val_loss: 2783644416.0000\n",
      "Epoch 446/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1055550016.0000 - val_loss: 2750226944.0000\n",
      "Epoch 447/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1049396096.0000 - val_loss: 2734344448.0000\n",
      "Epoch 448/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1045761024.0000 - val_loss: 2753184000.0000\n",
      "Epoch 449/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1053926784.0000 - val_loss: 2856987904.0000\n",
      "Epoch 450/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1057093760.0000 - val_loss: 2913131008.0000\n",
      "Epoch 451/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1048064128.0000 - val_loss: 2783322112.0000\n",
      "Epoch 452/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1045351296.0000 - val_loss: 2727443456.0000\n",
      "Epoch 453/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1056928128.0000 - val_loss: 2692875776.0000\n",
      "Epoch 454/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1044977088.0000 - val_loss: 2805499648.0000\n",
      "Epoch 455/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1040692160.0000 - val_loss: 2712795648.0000\n",
      "Epoch 456/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1039198144.0000 - val_loss: 2699651840.0000\n",
      "Epoch 457/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1058438400.0000 - val_loss: 2653048832.0000\n",
      "Epoch 458/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1043778880.0000 - val_loss: 2700899584.0000\n",
      "Epoch 459/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1042324864.0000 - val_loss: 2783543296.0000\n",
      "Epoch 460/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1034583488.0000 - val_loss: 2802325248.0000\n",
      "Epoch 461/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1037718400.0000 - val_loss: 2794126336.0000\n",
      "Epoch 462/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1043617856.0000 - val_loss: 2825986304.0000\n",
      "Epoch 463/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1033469376.0000 - val_loss: 2645467648.0000\n",
      "Epoch 464/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1031671104.0000 - val_loss: 2845403648.0000\n",
      "Epoch 465/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1035681024.0000 - val_loss: 2662632704.0000\n",
      "Epoch 466/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1031777088.0000 - val_loss: 2702284032.0000\n",
      "Epoch 467/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1054889152.0000 - val_loss: 2666135296.0000\n",
      "Epoch 468/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1030135872.0000 - val_loss: 2643341312.0000\n",
      "Epoch 469/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1034853312.0000 - val_loss: 2744203008.0000\n",
      "Epoch 470/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1016831168.0000 - val_loss: 2670589184.0000\n",
      "Epoch 471/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 1033052992.0000 - val_loss: 2650202880.0000\n",
      "Epoch 472/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1024865728.0000 - val_loss: 2673170432.0000\n",
      "Epoch 473/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1016037504.0000 - val_loss: 2687726592.0000\n",
      "Epoch 474/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1034160896.0000 - val_loss: 2715517440.0000\n",
      "Epoch 475/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1017953856.0000 - val_loss: 2692593408.0000\n",
      "Epoch 476/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1025402560.0000 - val_loss: 2619516928.0000\n",
      "Epoch 477/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1035229696.0000 - val_loss: 2681648896.0000\n",
      "Epoch 478/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1025653440.0000 - val_loss: 2739697664.0000\n",
      "Epoch 479/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1013155136.0000 - val_loss: 2668819456.0000\n",
      "Epoch 480/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1023068480.0000 - val_loss: 2689528576.0000\n",
      "Epoch 481/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1018782656.0000 - val_loss: 2651191808.0000\n",
      "Epoch 482/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1028470144.0000 - val_loss: 2704044288.0000\n",
      "Epoch 483/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 998745152.0000 - val_loss: 2640999680.0000\n",
      "Epoch 484/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1025092864.0000 - val_loss: 2620156416.0000\n",
      "Epoch 485/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1028330432.0000 - val_loss: 2654481408.0000\n",
      "Epoch 486/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1003659328.0000 - val_loss: 2674795008.0000\n",
      "Epoch 487/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1007759168.0000 - val_loss: 2668596224.0000\n",
      "Epoch 488/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1006986624.0000 - val_loss: 2712139776.0000\n",
      "Epoch 489/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1007108864.0000 - val_loss: 2665957120.0000\n",
      "Epoch 490/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1001167616.0000 - val_loss: 2758117632.0000\n",
      "Epoch 491/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1006681856.0000 - val_loss: 2660795392.0000\n",
      "Epoch 492/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1001401152.0000 - val_loss: 2643386624.0000\n",
      "Epoch 493/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1004261120.0000 - val_loss: 2674470912.0000\n",
      "Epoch 494/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1011768128.0000 - val_loss: 2609586432.0000\n",
      "Epoch 495/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1007984256.0000 - val_loss: 2622070016.0000\n",
      "Epoch 496/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 990328640.0000 - val_loss: 2588957440.0000\n",
      "Epoch 497/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 995802432.0000 - val_loss: 2580640512.0000\n",
      "Epoch 498/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 990714368.0000 - val_loss: 2729076480.0000\n",
      "Epoch 499/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 980325120.0000 - val_loss: 2716823040.0000\n",
      "Epoch 500/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 994137280.0000 - val_loss: 2545122304.0000\n",
      "Epoch 501/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1004080640.0000 - val_loss: 2552341248.0000\n",
      "Epoch 502/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 989778880.0000 - val_loss: 2620334592.0000\n",
      "Epoch 503/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 986798912.0000 - val_loss: 2565785344.0000\n",
      "Epoch 504/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 987961664.0000 - val_loss: 2584628480.0000\n",
      "Epoch 505/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 998027392.0000 - val_loss: 2586249472.0000\n",
      "Epoch 506/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 996731392.0000 - val_loss: 2606036480.0000\n",
      "Epoch 507/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 993315136.0000 - val_loss: 2556977920.0000\n",
      "Epoch 508/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 996384384.0000 - val_loss: 2596054528.0000\n",
      "Epoch 509/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 985394304.0000 - val_loss: 2604513280.0000\n",
      "Epoch 510/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 998517888.0000 - val_loss: 2588143104.0000\n",
      "Epoch 511/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 998091840.0000 - val_loss: 2624303872.0000\n",
      "Epoch 512/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 979646272.0000 - val_loss: 2505151232.0000\n",
      "Epoch 513/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 991440384.0000 - val_loss: 2601828864.0000\n",
      "Epoch 514/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 984173184.0000 - val_loss: 2615564288.0000\n",
      "Epoch 515/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 973081344.0000 - val_loss: 2486566656.0000\n",
      "Epoch 516/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 993102848.0000 - val_loss: 2638297344.0000\n",
      "Epoch 517/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1021130176.0000 - val_loss: 2514210304.0000\n",
      "Epoch 518/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 973152896.0000 - val_loss: 2587998976.0000\n",
      "Epoch 519/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 968161536.0000 - val_loss: 2624203520.0000\n",
      "Epoch 520/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 981498688.0000 - val_loss: 2572298496.0000\n",
      "Epoch 521/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 971863168.0000 - val_loss: 2551661056.0000\n",
      "Epoch 522/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 954509696.0000 - val_loss: 2540274176.0000\n",
      "Epoch 523/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 970841408.0000 - val_loss: 2575648768.0000\n",
      "Epoch 524/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 964544704.0000 - val_loss: 2534631680.0000\n",
      "Epoch 525/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 970268608.0000 - val_loss: 2472090368.0000\n",
      "Epoch 526/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 986596480.0000 - val_loss: 2695425792.0000\n",
      "Epoch 527/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 968218112.0000 - val_loss: 2665673984.0000\n",
      "Epoch 528/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 962455680.0000 - val_loss: 2517098240.0000\n",
      "Epoch 529/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 951651648.0000 - val_loss: 2504687104.0000\n",
      "Epoch 530/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 961940032.0000 - val_loss: 2567096064.0000\n",
      "Epoch 531/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 943569216.0000 - val_loss: 2473406208.0000\n",
      "Epoch 532/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 967771904.0000 - val_loss: 2488981248.0000\n",
      "Epoch 533/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 970128960.0000 - val_loss: 2616313344.0000\n",
      "Epoch 534/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 967013184.0000 - val_loss: 2468208128.0000\n",
      "Epoch 535/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 945262784.0000 - val_loss: 2499289856.0000\n",
      "Epoch 536/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 948407744.0000 - val_loss: 2464316160.0000\n",
      "Epoch 537/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 957961088.0000 - val_loss: 2509583872.0000\n",
      "Epoch 538/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 957940160.0000 - val_loss: 2680164352.0000\n",
      "Epoch 539/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 958929216.0000 - val_loss: 2618960128.0000\n",
      "Epoch 540/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 948428736.0000 - val_loss: 2479407616.0000\n",
      "Epoch 541/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 946863936.0000 - val_loss: 2547409664.0000\n",
      "Epoch 542/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 944813248.0000 - val_loss: 2552070400.0000\n",
      "Epoch 543/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 941002432.0000 - val_loss: 2645455104.0000\n",
      "Epoch 544/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 949913024.0000 - val_loss: 2516611840.0000\n",
      "Epoch 545/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 938590272.0000 - val_loss: 2609626624.0000\n",
      "Epoch 546/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 939394880.0000 - val_loss: 2433867264.0000\n",
      "Epoch 547/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 943086848.0000 - val_loss: 2446973184.0000\n",
      "Epoch 548/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 946015360.0000 - val_loss: 2449681920.0000\n",
      "Epoch 549/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 944196352.0000 - val_loss: 2454697984.0000\n",
      "Epoch 550/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 942450624.0000 - val_loss: 2485374464.0000\n",
      "Epoch 551/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 944367552.0000 - val_loss: 2407702272.0000\n",
      "Epoch 552/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 940722304.0000 - val_loss: 2548760320.0000\n",
      "Epoch 553/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 937531328.0000 - val_loss: 2438178816.0000\n",
      "Epoch 554/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 944247168.0000 - val_loss: 2475296256.0000\n",
      "Epoch 555/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 920899904.0000 - val_loss: 2462296320.0000\n",
      "Epoch 556/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 931915648.0000 - val_loss: 2420646400.0000\n",
      "Epoch 557/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 935954496.0000 - val_loss: 2435469824.0000\n",
      "Epoch 558/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 932084608.0000 - val_loss: 2452086784.0000\n",
      "Epoch 559/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 920923392.0000 - val_loss: 2445781504.0000\n",
      "Epoch 560/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 918057984.0000 - val_loss: 2531262976.0000\n",
      "Epoch 561/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 918278656.0000 - val_loss: 2473507328.0000\n",
      "Epoch 562/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 919877184.0000 - val_loss: 2504685824.0000\n",
      "Epoch 563/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 917030336.0000 - val_loss: 2368518144.0000\n",
      "Epoch 564/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 912844992.0000 - val_loss: 2379849728.0000\n",
      "Epoch 565/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 918074240.0000 - val_loss: 2378368768.0000\n",
      "Epoch 566/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 915402752.0000 - val_loss: 2497435392.0000\n",
      "Epoch 567/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 922089088.0000 - val_loss: 2474683904.0000\n",
      "Epoch 568/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 914898752.0000 - val_loss: 2429849344.0000\n",
      "Epoch 569/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 912829120.0000 - val_loss: 2409180160.0000\n",
      "Epoch 570/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 900759232.0000 - val_loss: 2475378944.0000\n",
      "Epoch 571/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 914575872.0000 - val_loss: 2360686848.0000\n",
      "Epoch 572/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 918351680.0000 - val_loss: 2408330752.0000\n",
      "Epoch 573/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 896286208.0000 - val_loss: 2437067520.0000\n",
      "Epoch 574/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 895994496.0000 - val_loss: 2449920000.0000\n",
      "Epoch 575/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 898299584.0000 - val_loss: 2379470848.0000\n",
      "Epoch 576/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 928593216.0000 - val_loss: 2354140672.0000\n",
      "Epoch 577/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 890552832.0000 - val_loss: 2409284096.0000\n",
      "Epoch 578/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 895511808.0000 - val_loss: 2433364224.0000\n",
      "Epoch 579/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 911936128.0000 - val_loss: 2321502976.0000\n",
      "Epoch 580/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 892691520.0000 - val_loss: 2473423360.0000\n",
      "Epoch 581/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 891015616.0000 - val_loss: 2399760128.0000\n",
      "Epoch 582/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 909674752.0000 - val_loss: 2372510976.0000\n",
      "Epoch 583/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 907975040.0000 - val_loss: 2369601536.0000\n",
      "Epoch 584/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 893383296.0000 - val_loss: 2490406656.0000\n",
      "Epoch 585/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 884048320.0000 - val_loss: 2341073152.0000\n",
      "Epoch 586/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 877932032.0000 - val_loss: 2340813824.0000\n",
      "Epoch 587/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 878403136.0000 - val_loss: 2445656832.0000\n",
      "Epoch 588/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 885624384.0000 - val_loss: 2403318784.0000\n",
      "Epoch 589/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 885698112.0000 - val_loss: 2415812864.0000\n",
      "Epoch 590/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 881782080.0000 - val_loss: 2549499648.0000\n",
      "Epoch 591/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 891240704.0000 - val_loss: 2323780608.0000\n",
      "Epoch 592/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 892749632.0000 - val_loss: 2333709824.0000\n",
      "Epoch 593/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 877531776.0000 - val_loss: 2277291520.0000\n",
      "Epoch 594/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 879635776.0000 - val_loss: 2361705728.0000\n",
      "Epoch 595/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 890274944.0000 - val_loss: 2327838464.0000\n",
      "Epoch 596/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 891651328.0000 - val_loss: 2365968896.0000\n",
      "Epoch 597/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 868786240.0000 - val_loss: 2376918784.0000\n",
      "Epoch 598/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 868932864.0000 - val_loss: 2368311040.0000\n",
      "Epoch 599/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 867253312.0000 - val_loss: 2312205312.0000\n",
      "Epoch 600/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 870146944.0000 - val_loss: 2296624640.0000\n",
      "Epoch 601/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 870352512.0000 - val_loss: 2301187328.0000\n",
      "Epoch 602/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 868990848.0000 - val_loss: 2281732608.0000\n",
      "Epoch 603/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 874689216.0000 - val_loss: 2248650240.0000\n",
      "Epoch 604/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 871754240.0000 - val_loss: 2390717696.0000\n",
      "Epoch 605/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 870664448.0000 - val_loss: 2268510208.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 852605504.0000 - val_loss: 2277395456.0000\n",
      "Epoch 607/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 875660352.0000 - val_loss: 2253128704.0000\n",
      "Epoch 608/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 855387328.0000 - val_loss: 2318455040.0000\n",
      "Epoch 609/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 860277312.0000 - val_loss: 2320116224.0000\n",
      "Epoch 610/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 853350464.0000 - val_loss: 2339848192.0000\n",
      "Epoch 611/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 856039424.0000 - val_loss: 2216041728.0000\n",
      "Epoch 612/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 852032064.0000 - val_loss: 2309596416.0000\n",
      "Epoch 613/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 872896448.0000 - val_loss: 2239128320.0000\n",
      "Epoch 614/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 862572288.0000 - val_loss: 2287335936.0000\n",
      "Epoch 615/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 857762368.0000 - val_loss: 2280938752.0000\n",
      "Epoch 616/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 866000640.0000 - val_loss: 2280351488.0000\n",
      "Epoch 617/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 838179264.0000 - val_loss: 2420596480.0000\n",
      "Epoch 618/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 839129216.0000 - val_loss: 2503031808.0000\n",
      "Epoch 619/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 853077888.0000 - val_loss: 2229159424.0000\n",
      "Epoch 620/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 835623168.0000 - val_loss: 2218469376.0000\n",
      "Epoch 621/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 838664640.0000 - val_loss: 2232620288.0000\n",
      "Epoch 622/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 826340864.0000 - val_loss: 2253472256.0000\n",
      "Epoch 623/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 833305152.0000 - val_loss: 2175066880.0000\n",
      "Epoch 624/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 844448192.0000 - val_loss: 2304289536.0000\n",
      "Epoch 625/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 828447808.0000 - val_loss: 2172632576.0000\n",
      "Epoch 626/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 854442944.0000 - val_loss: 2142494976.0000\n",
      "Epoch 627/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 828780160.0000 - val_loss: 2162060800.0000\n",
      "Epoch 628/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 836118336.0000 - val_loss: 2223529984.0000\n",
      "Epoch 629/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 831906496.0000 - val_loss: 2216655104.0000\n",
      "Epoch 630/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 827616128.0000 - val_loss: 2229730304.0000\n",
      "Epoch 631/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 837523456.0000 - val_loss: 2258259712.0000\n",
      "Epoch 632/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 837579840.0000 - val_loss: 2244806656.0000\n",
      "Epoch 633/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 851317312.0000 - val_loss: 2419813632.0000\n",
      "Epoch 634/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 844457216.0000 - val_loss: 2278543616.0000\n",
      "Epoch 635/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 811913088.0000 - val_loss: 2189995008.0000\n",
      "Epoch 636/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 830094208.0000 - val_loss: 2130686592.0000\n",
      "Epoch 637/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 810955456.0000 - val_loss: 2256970752.0000\n",
      "Epoch 638/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 818882688.0000 - val_loss: 2202497536.0000\n",
      "Epoch 639/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 835576832.0000 - val_loss: 2323198208.0000\n",
      "Epoch 640/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 826765120.0000 - val_loss: 2200130304.0000\n",
      "Epoch 641/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 821349952.0000 - val_loss: 2138718720.0000\n",
      "Epoch 642/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 818609664.0000 - val_loss: 2241117696.0000\n",
      "Epoch 643/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 826893312.0000 - val_loss: 2191617280.0000\n",
      "Epoch 644/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 816401920.0000 - val_loss: 2111001088.0000\n",
      "Epoch 645/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 816822464.0000 - val_loss: 2228996352.0000\n",
      "Epoch 646/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 815048512.0000 - val_loss: 2269467136.0000\n",
      "Epoch 647/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 809737984.0000 - val_loss: 2179623680.0000\n",
      "Epoch 648/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 808305920.0000 - val_loss: 2344965120.0000\n",
      "Epoch 649/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 808204352.0000 - val_loss: 2164164352.0000\n",
      "Epoch 650/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 820116480.0000 - val_loss: 2090324992.0000\n",
      "Epoch 651/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 804647168.0000 - val_loss: 2138741888.0000\n",
      "Epoch 652/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 802671744.0000 - val_loss: 2113856512.0000\n",
      "Epoch 653/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 826878528.0000 - val_loss: 2275040000.0000\n",
      "Epoch 654/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 802201280.0000 - val_loss: 2108982528.0000\n",
      "Epoch 655/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 793023552.0000 - val_loss: 2179556864.0000\n",
      "Epoch 656/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 800895040.0000 - val_loss: 2106787584.0000\n",
      "Epoch 657/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 790051328.0000 - val_loss: 2145819776.0000\n",
      "Epoch 658/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 800629952.0000 - val_loss: 2125711488.0000\n",
      "Epoch 659/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 789488832.0000 - val_loss: 2169610752.0000\n",
      "Epoch 660/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 790405696.0000 - val_loss: 2043454592.0000\n",
      "Epoch 661/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 798984704.0000 - val_loss: 2051513216.0000\n",
      "Epoch 662/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 801208320.0000 - val_loss: 2082569728.0000\n",
      "Epoch 663/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 797029056.0000 - val_loss: 2141960576.0000\n",
      "Epoch 664/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 817757504.0000 - val_loss: 2206574848.0000\n",
      "Epoch 665/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 791411328.0000 - val_loss: 2083031808.0000\n",
      "Epoch 666/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 782297536.0000 - val_loss: 2137725568.0000\n",
      "Epoch 667/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 788624832.0000 - val_loss: 2063497600.0000\n",
      "Epoch 668/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 768365376.0000 - val_loss: 2300305152.0000\n",
      "Epoch 669/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 800471040.0000 - val_loss: 2374957824.0000\n",
      "Epoch 670/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 783902848.0000 - val_loss: 2088041344.0000\n",
      "Epoch 671/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 786966848.0000 - val_loss: 2087020544.0000\n",
      "Epoch 672/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 765895552.0000 - val_loss: 2033945344.0000\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 1ms/step - loss: 764749888.0000 - val_loss: 2155789056.0000\n",
      "Epoch 674/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 770672768.0000 - val_loss: 2127366528.0000\n",
      "Epoch 675/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 770411520.0000 - val_loss: 2078779648.0000\n",
      "Epoch 676/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 768492864.0000 - val_loss: 2100869248.0000\n",
      "Epoch 677/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 784461440.0000 - val_loss: 2012935040.0000\n",
      "Epoch 678/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 783475392.0000 - val_loss: 2034389888.0000\n",
      "Epoch 679/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 776202496.0000 - val_loss: 2105219712.0000\n",
      "Epoch 680/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 765230912.0000 - val_loss: 2056685440.0000\n",
      "Epoch 681/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 765050624.0000 - val_loss: 2017867392.0000\n",
      "Epoch 682/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 761368448.0000 - val_loss: 1980509184.0000\n",
      "Epoch 683/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 779847296.0000 - val_loss: 2087822464.0000\n",
      "Epoch 684/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 769535360.0000 - val_loss: 2000627328.0000\n",
      "Epoch 685/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 760115072.0000 - val_loss: 2074636416.0000\n",
      "Epoch 686/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 760452672.0000 - val_loss: 2097733760.0000\n",
      "Epoch 687/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 766734336.0000 - val_loss: 2005659264.0000\n",
      "Epoch 688/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 783120960.0000 - val_loss: 2213142784.0000\n",
      "Epoch 689/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 764068096.0000 - val_loss: 2020175744.0000\n",
      "Epoch 690/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 762118656.0000 - val_loss: 1986419328.0000\n",
      "Epoch 691/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 752288000.0000 - val_loss: 1930601088.0000\n",
      "Epoch 692/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 758150208.0000 - val_loss: 1981939456.0000\n",
      "Epoch 693/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 759606272.0000 - val_loss: 1912474752.0000\n",
      "Epoch 694/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 749616192.0000 - val_loss: 2010631680.0000\n",
      "Epoch 695/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 761888512.0000 - val_loss: 1974029056.0000\n",
      "Epoch 696/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 761521792.0000 - val_loss: 1998888064.0000\n",
      "Epoch 697/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 740309248.0000 - val_loss: 1939042944.0000\n",
      "Epoch 698/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 752479360.0000 - val_loss: 2038519552.0000\n",
      "Epoch 699/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 754661056.0000 - val_loss: 1935392512.0000\n",
      "Epoch 700/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 760028672.0000 - val_loss: 1971309312.0000\n",
      "Epoch 701/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 769136256.0000 - val_loss: 1974084352.0000\n",
      "Epoch 702/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 746404224.0000 - val_loss: 2110477696.0000\n",
      "Epoch 703/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 754135168.0000 - val_loss: 2029196800.0000\n",
      "Epoch 704/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 731471232.0000 - val_loss: 1947761920.0000\n",
      "Epoch 705/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 744269952.0000 - val_loss: 2055236864.0000\n",
      "Epoch 706/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 739142400.0000 - val_loss: 1947441408.0000\n",
      "Epoch 707/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 729295040.0000 - val_loss: 1933329536.0000\n",
      "Epoch 708/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 744200192.0000 - val_loss: 1969445760.0000\n",
      "Epoch 709/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 742031360.0000 - val_loss: 1986125056.0000\n",
      "Epoch 710/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 734996032.0000 - val_loss: 2014470144.0000\n",
      "Epoch 711/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 748081472.0000 - val_loss: 1988464000.0000\n",
      "Epoch 712/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 738381760.0000 - val_loss: 1975970944.0000\n",
      "Epoch 713/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 730092800.0000 - val_loss: 2064933504.0000\n",
      "Epoch 714/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 727952448.0000 - val_loss: 1841466240.0000\n",
      "Epoch 715/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 741397568.0000 - val_loss: 2042476928.0000\n",
      "Epoch 716/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 741495232.0000 - val_loss: 1987918976.0000\n",
      "Epoch 717/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 717700096.0000 - val_loss: 1850534400.0000\n",
      "Epoch 718/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 740120704.0000 - val_loss: 1916254336.0000\n",
      "Epoch 719/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 737678528.0000 - val_loss: 1863460096.0000\n",
      "Epoch 720/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 744659584.0000 - val_loss: 1809726592.0000\n",
      "Epoch 721/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 726873408.0000 - val_loss: 1896749440.0000\n",
      "Epoch 722/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 709898816.0000 - val_loss: 1893248768.0000\n",
      "Epoch 723/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 739916736.0000 - val_loss: 1979530624.0000\n",
      "Epoch 724/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 719013312.0000 - val_loss: 1854440320.0000\n",
      "Epoch 725/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 720882112.0000 - val_loss: 1808940672.0000\n",
      "Epoch 726/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 722865216.0000 - val_loss: 1914512384.0000\n",
      "Epoch 727/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 715660160.0000 - val_loss: 1856381440.0000\n",
      "Epoch 728/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 724134976.0000 - val_loss: 1969864704.0000\n",
      "Epoch 729/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 725590720.0000 - val_loss: 1859895936.0000\n",
      "Epoch 730/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 736850688.0000 - val_loss: 1776086144.0000\n",
      "Epoch 731/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 719077760.0000 - val_loss: 1853220864.0000\n",
      "Epoch 732/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 711956416.0000 - val_loss: 1877729792.0000\n",
      "Epoch 733/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 737794432.0000 - val_loss: 1893868800.0000\n",
      "Epoch 734/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 702595648.0000 - val_loss: 1872497024.0000\n",
      "Epoch 735/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 720831360.0000 - val_loss: 1828828800.0000\n",
      "Epoch 736/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 712535104.0000 - val_loss: 1898258816.0000\n",
      "Epoch 737/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 704296384.0000 - val_loss: 1918458112.0000\n",
      "Epoch 738/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 713432064.0000 - val_loss: 1856956032.0000\n",
      "Epoch 739/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 712237120.0000 - val_loss: 1832307456.0000\n",
      "Epoch 740/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 723904064.0000 - val_loss: 1877769984.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 695660352.0000 - val_loss: 1797515776.0000\n",
      "Epoch 742/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 692477952.0000 - val_loss: 1789827328.0000\n",
      "Epoch 743/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 705288256.0000 - val_loss: 1809478912.0000\n",
      "Epoch 744/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 691529344.0000 - val_loss: 1846999040.0000\n",
      "Epoch 745/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 700625856.0000 - val_loss: 1818037248.0000\n",
      "Epoch 746/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 688405760.0000 - val_loss: 1851128064.0000\n",
      "Epoch 747/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 704846144.0000 - val_loss: 1814425088.0000\n",
      "Epoch 748/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 684507776.0000 - val_loss: 1859667840.0000\n",
      "Epoch 749/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 716257664.0000 - val_loss: 1889964288.0000\n",
      "Epoch 750/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 704985856.0000 - val_loss: 1824541568.0000\n",
      "Epoch 751/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 681390464.0000 - val_loss: 1911427072.0000\n",
      "Epoch 752/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 686027520.0000 - val_loss: 1808774656.0000\n",
      "Epoch 753/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 686236160.0000 - val_loss: 1857102336.0000\n",
      "Epoch 754/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 682920640.0000 - val_loss: 1866753152.0000\n",
      "Epoch 755/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 684467520.0000 - val_loss: 1827007360.0000\n",
      "Epoch 756/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 675834944.0000 - val_loss: 1744334080.0000\n",
      "Epoch 757/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 690509184.0000 - val_loss: 1824354176.0000\n",
      "Epoch 758/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 676675968.0000 - val_loss: 1825063168.0000\n",
      "Epoch 759/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 663868544.0000 - val_loss: 1885149440.0000\n",
      "Epoch 760/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 669079040.0000 - val_loss: 1851204480.0000\n",
      "Epoch 761/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 678873536.0000 - val_loss: 1911472768.0000\n",
      "Epoch 762/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 681590400.0000 - val_loss: 1739836416.0000\n",
      "Epoch 763/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 673390848.0000 - val_loss: 1758928640.0000\n",
      "Epoch 764/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 664703040.0000 - val_loss: 1874401280.0000\n",
      "Epoch 765/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 663902784.0000 - val_loss: 1767373440.0000\n",
      "Epoch 766/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 674940288.0000 - val_loss: 1757075200.0000\n",
      "Epoch 767/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 693181056.0000 - val_loss: 1846283904.0000\n",
      "Epoch 768/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 662951680.0000 - val_loss: 1814990848.0000\n",
      "Epoch 769/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 674070528.0000 - val_loss: 1801218048.0000\n",
      "Epoch 770/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 676191360.0000 - val_loss: 1762298752.0000\n",
      "Epoch 771/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 689137728.0000 - val_loss: 1822630784.0000\n",
      "Epoch 772/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 662833728.0000 - val_loss: 1780847232.0000\n",
      "Epoch 773/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 691702080.0000 - val_loss: 1736204544.0000\n",
      "Epoch 774/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 673885952.0000 - val_loss: 1736448896.0000\n",
      "Epoch 775/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 663198592.0000 - val_loss: 1826253952.0000\n",
      "Epoch 776/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 662121088.0000 - val_loss: 1689967488.0000\n",
      "Epoch 777/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 668347904.0000 - val_loss: 1806723840.0000\n",
      "Epoch 778/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 693584128.0000 - val_loss: 2030884992.0000\n",
      "Epoch 779/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 659294528.0000 - val_loss: 1839814656.0000\n",
      "Epoch 780/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 666991168.0000 - val_loss: 1685216128.0000\n",
      "Epoch 781/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 680055872.0000 - val_loss: 1777739520.0000\n",
      "Epoch 782/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 650972544.0000 - val_loss: 1791494784.0000\n",
      "Epoch 783/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 653828032.0000 - val_loss: 1777740416.0000\n",
      "Epoch 784/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 654429376.0000 - val_loss: 1708212480.0000\n",
      "Epoch 785/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 656802368.0000 - val_loss: 1729647488.0000\n",
      "Epoch 786/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 654990656.0000 - val_loss: 1749292800.0000\n",
      "Epoch 787/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 665761088.0000 - val_loss: 1778625152.0000\n",
      "Epoch 788/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 651797440.0000 - val_loss: 1805417856.0000\n",
      "Epoch 789/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 647947520.0000 - val_loss: 1692849920.0000\n",
      "Epoch 790/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 647698432.0000 - val_loss: 1653421568.0000\n",
      "Epoch 791/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 647065792.0000 - val_loss: 1749968768.0000\n",
      "Epoch 792/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 673659840.0000 - val_loss: 1918134912.0000\n",
      "Epoch 793/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 696675712.0000 - val_loss: 1762683392.0000\n",
      "Epoch 794/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 663923840.0000 - val_loss: 1737907840.0000\n",
      "Epoch 795/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 665817408.0000 - val_loss: 1727629440.0000\n",
      "Epoch 796/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 660859456.0000 - val_loss: 1708171776.0000\n",
      "Epoch 797/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 665838784.0000 - val_loss: 1665307264.0000\n",
      "Epoch 798/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 638350784.0000 - val_loss: 1763044096.0000\n",
      "Epoch 799/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 663800384.0000 - val_loss: 1677435008.0000\n",
      "Epoch 800/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 650053568.0000 - val_loss: 1697837824.0000\n",
      "Epoch 801/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 638841216.0000 - val_loss: 1705052544.0000\n",
      "Epoch 802/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 635398272.0000 - val_loss: 1635852160.0000\n",
      "Epoch 803/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 646412928.0000 - val_loss: 1650603520.0000\n",
      "Epoch 804/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 642893120.0000 - val_loss: 1760133248.0000\n",
      "Epoch 805/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 640699072.0000 - val_loss: 1715968384.0000\n",
      "Epoch 806/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 654192704.0000 - val_loss: 1771426176.0000\n",
      "Epoch 807/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 677056896.0000 - val_loss: 1694563712.0000\n",
      "Epoch 808/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 1ms/step - loss: 644459968.0000 - val_loss: 1701442432.0000\n",
      "Epoch 809/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 640799936.0000 - val_loss: 1661316608.0000\n",
      "Epoch 810/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 631519360.0000 - val_loss: 1671026560.0000\n",
      "Epoch 811/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 638288320.0000 - val_loss: 1672671232.0000\n",
      "Epoch 812/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 664177728.0000 - val_loss: 1693584128.0000\n",
      "Epoch 813/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 628183808.0000 - val_loss: 1658058752.0000\n",
      "Epoch 814/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 629614080.0000 - val_loss: 1660213248.0000\n",
      "Epoch 815/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 648075008.0000 - val_loss: 1667563264.0000\n",
      "Epoch 816/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 626184960.0000 - val_loss: 1824977408.0000\n",
      "Epoch 817/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 644042752.0000 - val_loss: 1695234560.0000\n",
      "Epoch 818/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 637215424.0000 - val_loss: 1700224896.0000\n",
      "Epoch 819/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 639550720.0000 - val_loss: 1635345536.0000\n",
      "Epoch 820/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 652716288.0000 - val_loss: 1732978944.0000\n",
      "Epoch 821/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 628229952.0000 - val_loss: 1687589504.0000\n",
      "Epoch 822/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 635769024.0000 - val_loss: 1793168384.0000\n",
      "Epoch 823/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 632718272.0000 - val_loss: 1561879296.0000\n",
      "Epoch 824/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 634360320.0000 - val_loss: 1595979904.0000\n",
      "Epoch 825/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 626913024.0000 - val_loss: 1585935488.0000\n",
      "Epoch 826/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 612513664.0000 - val_loss: 1754681472.0000\n",
      "Epoch 827/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 634042240.0000 - val_loss: 1665517696.0000\n",
      "Epoch 828/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 631568768.0000 - val_loss: 1734303232.0000\n",
      "Epoch 829/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 640692992.0000 - val_loss: 1676651008.0000\n",
      "Epoch 830/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 637214016.0000 - val_loss: 1670529408.0000\n",
      "Epoch 831/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 616519552.0000 - val_loss: 1560451840.0000\n",
      "Epoch 832/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 629328960.0000 - val_loss: 1574426880.0000\n",
      "Epoch 833/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 618858176.0000 - val_loss: 1726365696.0000\n",
      "Epoch 834/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 648482368.0000 - val_loss: 1727362432.0000\n",
      "Epoch 835/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 625299520.0000 - val_loss: 1571753216.0000\n",
      "Epoch 836/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 661446656.0000 - val_loss: 1597432832.0000\n",
      "Epoch 837/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 614149632.0000 - val_loss: 1639200128.0000\n",
      "Epoch 838/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 608945152.0000 - val_loss: 1682319744.0000\n",
      "Epoch 839/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 603449280.0000 - val_loss: 1526915840.0000\n",
      "Epoch 840/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 621203776.0000 - val_loss: 1623722368.0000\n",
      "Epoch 841/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 612430848.0000 - val_loss: 1574390528.0000\n",
      "Epoch 842/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 624508800.0000 - val_loss: 1608787712.0000\n",
      "Epoch 843/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 627518464.0000 - val_loss: 1651259520.0000\n",
      "Epoch 844/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 618706816.0000 - val_loss: 1641828736.0000\n",
      "Epoch 845/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 607783808.0000 - val_loss: 1634708864.0000\n",
      "Epoch 846/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 621976448.0000 - val_loss: 1549450624.0000\n",
      "Epoch 847/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 627607168.0000 - val_loss: 1597462400.0000\n",
      "Epoch 848/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 635188544.0000 - val_loss: 1562873088.0000\n",
      "Epoch 849/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 621574400.0000 - val_loss: 1577606144.0000\n",
      "Epoch 850/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 629079488.0000 - val_loss: 1589047168.0000\n",
      "Epoch 851/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 594865664.0000 - val_loss: 1633719808.0000\n",
      "Epoch 852/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 604012608.0000 - val_loss: 1549645952.0000\n",
      "Epoch 853/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 597772096.0000 - val_loss: 1638326016.0000\n",
      "Epoch 854/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 612999168.0000 - val_loss: 1681061760.0000\n",
      "Epoch 855/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 593875584.0000 - val_loss: 1579094144.0000\n",
      "Epoch 856/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 611259520.0000 - val_loss: 1549940864.0000\n",
      "Epoch 857/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 596435968.0000 - val_loss: 1607781760.0000\n",
      "Epoch 858/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 619283712.0000 - val_loss: 1505777280.0000\n",
      "Epoch 859/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 598567040.0000 - val_loss: 1536600704.0000\n",
      "Epoch 860/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 602601024.0000 - val_loss: 1556182272.0000\n",
      "Epoch 861/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 619271680.0000 - val_loss: 1584753152.0000\n",
      "Epoch 862/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 599457152.0000 - val_loss: 1591522816.0000\n",
      "Epoch 863/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 631651840.0000 - val_loss: 1612943488.0000\n",
      "Epoch 864/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 614076096.0000 - val_loss: 1497743232.0000\n",
      "Epoch 865/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 591160576.0000 - val_loss: 1610022144.0000\n",
      "Epoch 866/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 597654720.0000 - val_loss: 1575058688.0000\n",
      "Epoch 867/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 597676544.0000 - val_loss: 1506710528.0000\n",
      "Epoch 868/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 581201408.0000 - val_loss: 1574188288.0000\n",
      "Epoch 869/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 613285248.0000 - val_loss: 1532742400.0000\n",
      "Epoch 870/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 597615616.0000 - val_loss: 1573256960.0000\n",
      "Epoch 871/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 606204736.0000 - val_loss: 1491464448.0000\n",
      "Epoch 872/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 621526336.0000 - val_loss: 1551911424.0000\n",
      "Epoch 873/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 579514688.0000 - val_loss: 1463430272.0000\n",
      "Epoch 874/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 587529856.0000 - val_loss: 1584525184.0000\n",
      "Epoch 875/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 594119808.0000 - val_loss: 1543160832.0000\n",
      "Epoch 876/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 593330176.0000 - val_loss: 1514873600.0000\n",
      "Epoch 877/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 581102784.0000 - val_loss: 1525052928.0000\n",
      "Epoch 878/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 599716928.0000 - val_loss: 1527445760.0000\n",
      "Epoch 879/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 586626240.0000 - val_loss: 1483486208.0000\n",
      "Epoch 880/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 589030912.0000 - val_loss: 1555798912.0000\n",
      "Epoch 881/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 600019328.0000 - val_loss: 1559644032.0000\n",
      "Epoch 882/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 593648256.0000 - val_loss: 1547091840.0000\n",
      "Epoch 883/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 598966272.0000 - val_loss: 1426260864.0000\n",
      "Epoch 884/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 565990400.0000 - val_loss: 1560412160.0000\n",
      "Epoch 885/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 607961728.0000 - val_loss: 1476448000.0000\n",
      "Epoch 886/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 609154560.0000 - val_loss: 1553745792.0000\n",
      "Epoch 887/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 588200192.0000 - val_loss: 1500195968.0000\n",
      "Epoch 888/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 591627456.0000 - val_loss: 1477906944.0000\n",
      "Epoch 889/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 588658432.0000 - val_loss: 1578886272.0000\n",
      "Epoch 890/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 584349184.0000 - val_loss: 1480405632.0000\n",
      "Epoch 891/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 595105536.0000 - val_loss: 1529385472.0000\n",
      "Epoch 892/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 592083328.0000 - val_loss: 1511337344.0000\n",
      "Epoch 893/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 568972928.0000 - val_loss: 1494392576.0000\n",
      "Epoch 894/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 580049728.0000 - val_loss: 1465558016.0000\n",
      "Epoch 895/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 566444288.0000 - val_loss: 1492732032.0000\n",
      "Epoch 896/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 586859968.0000 - val_loss: 1431365376.0000\n",
      "Epoch 897/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 588762816.0000 - val_loss: 1543411712.0000\n",
      "Epoch 898/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 576535936.0000 - val_loss: 1490606464.0000\n",
      "Epoch 899/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 568903616.0000 - val_loss: 1497533824.0000\n",
      "Epoch 900/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 579200832.0000 - val_loss: 1502160256.0000\n",
      "Epoch 901/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 585602880.0000 - val_loss: 1450769792.0000\n",
      "Epoch 902/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 563992704.0000 - val_loss: 1459601408.0000\n",
      "Epoch 903/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 563618304.0000 - val_loss: 1436956288.0000\n",
      "Epoch 904/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 560238016.0000 - val_loss: 1478921344.0000\n",
      "Epoch 905/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 615755200.0000 - val_loss: 1494387968.0000\n",
      "Epoch 906/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 568490368.0000 - val_loss: 1433963136.0000\n",
      "Epoch 907/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 564145280.0000 - val_loss: 1469924736.0000\n",
      "Epoch 908/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 566536256.0000 - val_loss: 1398604288.0000\n",
      "Epoch 909/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 587357760.0000 - val_loss: 1412285696.0000\n",
      "Epoch 910/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 571943040.0000 - val_loss: 1542718848.0000\n",
      "Epoch 911/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 567307712.0000 - val_loss: 1417147136.0000\n",
      "Epoch 912/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 562794368.0000 - val_loss: 1519567360.0000\n",
      "Epoch 913/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 587738560.0000 - val_loss: 1455454336.0000\n",
      "Epoch 914/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 554956736.0000 - val_loss: 1420814336.0000\n",
      "Epoch 915/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 564874304.0000 - val_loss: 1464605568.0000\n",
      "Epoch 916/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 598312384.0000 - val_loss: 1420235136.0000\n",
      "Epoch 917/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 591851392.0000 - val_loss: 1469299328.0000\n",
      "Epoch 918/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 563087680.0000 - val_loss: 1434391808.0000\n",
      "Epoch 919/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 556486272.0000 - val_loss: 1455964928.0000\n",
      "Epoch 920/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 579516800.0000 - val_loss: 1397756416.0000\n",
      "Epoch 921/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 559154816.0000 - val_loss: 1397805056.0000\n",
      "Epoch 922/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 561410240.0000 - val_loss: 1381693184.0000\n",
      "Epoch 923/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 586771456.0000 - val_loss: 1539442944.0000\n",
      "Epoch 924/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 596401216.0000 - val_loss: 1438528128.0000\n",
      "Epoch 925/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 564453952.0000 - val_loss: 1430120832.0000\n",
      "Epoch 926/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 554764864.0000 - val_loss: 1356447744.0000\n",
      "Epoch 927/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 562003584.0000 - val_loss: 1392104192.0000\n",
      "Epoch 928/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 558743296.0000 - val_loss: 1490114432.0000\n",
      "Epoch 929/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 574158656.0000 - val_loss: 1427500672.0000\n",
      "Epoch 930/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 563198336.0000 - val_loss: 1429960704.0000\n",
      "Epoch 931/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 564379392.0000 - val_loss: 1541804544.0000\n",
      "Epoch 932/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 553019712.0000 - val_loss: 1477461632.0000\n",
      "Epoch 933/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 563480192.0000 - val_loss: 1539605248.0000\n",
      "Epoch 934/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 552362560.0000 - val_loss: 1509657344.0000\n",
      "Epoch 935/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 565397824.0000 - val_loss: 1427367680.0000\n",
      "Epoch 936/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 560979648.0000 - val_loss: 1372173056.0000\n",
      "Epoch 937/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 560195456.0000 - val_loss: 1692826752.0000\n",
      "Epoch 938/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 552821504.0000 - val_loss: 1421670016.0000\n",
      "Epoch 939/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 558963904.0000 - val_loss: 1357337344.0000\n",
      "Epoch 940/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 569374784.0000 - val_loss: 1417368960.0000\n",
      "Epoch 941/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 560136832.0000 - val_loss: 1494270976.0000\n",
      "Epoch 942/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 548588608.0000 - val_loss: 1351715072.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 943/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 560866048.0000 - val_loss: 1363263104.0000\n",
      "Epoch 944/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 546880128.0000 - val_loss: 1421887872.0000\n",
      "Epoch 945/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 561743104.0000 - val_loss: 1379652864.0000\n",
      "Epoch 946/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 555042688.0000 - val_loss: 1396957184.0000\n",
      "Epoch 947/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 583322368.0000 - val_loss: 1523799040.0000\n",
      "Epoch 948/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 586722368.0000 - val_loss: 1385421696.0000\n",
      "Epoch 949/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 544275968.0000 - val_loss: 1391715200.0000\n",
      "Epoch 950/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 543853952.0000 - val_loss: 1348320768.0000\n",
      "Epoch 951/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 584201984.0000 - val_loss: 1395742208.0000\n",
      "Epoch 952/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 531352832.0000 - val_loss: 1364913152.0000\n",
      "Epoch 953/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 545910272.0000 - val_loss: 1411059200.0000\n",
      "Epoch 954/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 551203456.0000 - val_loss: 1424372736.0000\n",
      "Epoch 955/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 572695616.0000 - val_loss: 1360846976.0000\n",
      "Epoch 956/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 536981824.0000 - val_loss: 1414770048.0000\n",
      "Epoch 957/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 545152512.0000 - val_loss: 1331914752.0000\n",
      "Epoch 958/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 572556480.0000 - val_loss: 1410943872.0000\n",
      "Epoch 959/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 556467648.0000 - val_loss: 1424756608.0000\n",
      "Epoch 960/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 552951296.0000 - val_loss: 1318817152.0000\n",
      "Epoch 961/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 554100352.0000 - val_loss: 1304308864.0000\n",
      "Epoch 962/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 537123776.0000 - val_loss: 1389208320.0000\n",
      "Epoch 963/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 537948288.0000 - val_loss: 1307129856.0000\n",
      "Epoch 964/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 552718400.0000 - val_loss: 1306699008.0000\n",
      "Epoch 965/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 558479616.0000 - val_loss: 1352808832.0000\n",
      "Epoch 966/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 557484800.0000 - val_loss: 1316190336.0000\n",
      "Epoch 967/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 549461376.0000 - val_loss: 1393734016.0000\n",
      "Epoch 968/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 551409536.0000 - val_loss: 1307126016.0000\n",
      "Epoch 969/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 532725696.0000 - val_loss: 1500587648.0000\n",
      "Epoch 970/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 546772160.0000 - val_loss: 1406145536.0000\n",
      "Epoch 971/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 532406880.0000 - val_loss: 1359745152.0000\n",
      "Epoch 972/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 532009088.0000 - val_loss: 1358411648.0000\n",
      "Epoch 973/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 534196768.0000 - val_loss: 1578515072.0000\n",
      "Epoch 974/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 567134784.0000 - val_loss: 1375242624.0000\n",
      "Epoch 975/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 536440288.0000 - val_loss: 1298584576.0000\n",
      "Epoch 976/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 541809600.0000 - val_loss: 1451068800.0000\n",
      "Epoch 977/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 544711296.0000 - val_loss: 1366598016.0000\n",
      "Epoch 978/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 517160352.0000 - val_loss: 1297527424.0000\n",
      "Epoch 979/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 536177376.0000 - val_loss: 1476796032.0000\n",
      "Epoch 980/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 534424736.0000 - val_loss: 1361581056.0000\n",
      "Epoch 981/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 548308800.0000 - val_loss: 1384528000.0000\n",
      "Epoch 982/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 541763328.0000 - val_loss: 1385382912.0000\n",
      "Epoch 983/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 576177792.0000 - val_loss: 1337144064.0000\n",
      "Epoch 984/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 515168672.0000 - val_loss: 1613008256.0000\n",
      "Epoch 985/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 535970304.0000 - val_loss: 1289837440.0000\n",
      "Epoch 986/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 535182400.0000 - val_loss: 1329662208.0000\n",
      "Epoch 987/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 525185632.0000 - val_loss: 1351544320.0000\n",
      "Epoch 988/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 530899232.0000 - val_loss: 1327200896.0000\n",
      "Epoch 989/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 555753344.0000 - val_loss: 1317558784.0000\n",
      "Epoch 990/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 550529984.0000 - val_loss: 1378439552.0000\n",
      "Epoch 991/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 548321664.0000 - val_loss: 1322315648.0000\n",
      "Epoch 992/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 529402912.0000 - val_loss: 1370169088.0000\n",
      "Epoch 993/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 533598912.0000 - val_loss: 1314871936.0000\n",
      "Epoch 994/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 527177568.0000 - val_loss: 1308928128.0000\n",
      "Epoch 995/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 530697024.0000 - val_loss: 1308977024.0000\n",
      "Epoch 996/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 531358432.0000 - val_loss: 1502194816.0000\n",
      "Epoch 997/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 552248960.0000 - val_loss: 1286754944.0000\n",
      "Epoch 998/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 537312064.0000 - val_loss: 1370986880.0000\n",
      "Epoch 999/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 508487712.0000 - val_loss: 1269028736.0000\n",
      "Epoch 1000/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 517417696.0000 - val_loss: 1327214848.0000\n"
     ]
    }
   ],
   "source": [
    "# # Fitting the ANN to the Training set\n",
    "model_history=model.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(df_test_new.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[236895.83],\n",
       "       [239712.55],\n",
       "       [327136.28],\n",
       "       ...,\n",
       "       [397965.2 ],\n",
       "       [305083.38],\n",
       "       [417704.62]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed_value = random.randint(2,200)\n",
    "seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tensorflow.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 36431536128.0000 - val_loss: 32946671616.0000\n",
      "Epoch 2/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 23531980800.0000 - val_loss: 12568774656.0000\n",
      "Epoch 3/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 8153317376.0000 - val_loss: 5248078336.0000\n",
      "Epoch 4/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 5453564928.0000 - val_loss: 4869242880.0000\n",
      "Epoch 5/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 5122925568.0000 - val_loss: 4758738944.0000\n",
      "Epoch 6/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 4905174528.0000 - val_loss: 4658757632.0000\n",
      "Epoch 7/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 4694886912.0000 - val_loss: 4563057152.0000\n",
      "Epoch 8/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 4499362816.0000 - val_loss: 4474946048.0000\n",
      "Epoch 9/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 4306061824.0000 - val_loss: 4388808192.0000\n",
      "Epoch 10/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 4143927552.0000 - val_loss: 4290614784.0000\n",
      "Epoch 11/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 3980386304.0000 - val_loss: 4215525376.0000\n",
      "Epoch 12/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 3826264576.0000 - val_loss: 4132853760.0000\n",
      "Epoch 13/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 3681393664.0000 - val_loss: 4052722944.0000\n",
      "Epoch 14/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 3553818624.0000 - val_loss: 3976730368.0000\n",
      "Epoch 15/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 3418415616.0000 - val_loss: 3911056384.0000\n",
      "Epoch 16/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 3303261952.0000 - val_loss: 3825159424.0000\n",
      "Epoch 17/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 3186433792.0000 - val_loss: 3772624384.0000\n",
      "Epoch 18/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 3059827456.0000 - val_loss: 3698891776.0000\n",
      "Epoch 19/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2922202880.0000 - val_loss: 3624805632.0000\n",
      "Epoch 20/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2799990016.0000 - val_loss: 3486779904.0000\n",
      "Epoch 21/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2662130176.0000 - val_loss: 3403040768.0000\n",
      "Epoch 22/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2520524032.0000 - val_loss: 3331393280.0000\n",
      "Epoch 23/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2402853632.0000 - val_loss: 3286202624.0000\n",
      "Epoch 24/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2263786496.0000 - val_loss: 3198232064.0000\n",
      "Epoch 25/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2139865600.0000 - val_loss: 3148267264.0000\n",
      "Epoch 26/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2027768192.0000 - val_loss: 3095477760.0000\n",
      "Epoch 27/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1929359744.0000 - val_loss: 3089176832.0000\n",
      "Epoch 28/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1839154560.0000 - val_loss: 3095168768.0000\n",
      "Epoch 29/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1774934784.0000 - val_loss: 3045178880.0000\n",
      "Epoch 30/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1728156288.0000 - val_loss: 3115100160.0000\n",
      "Epoch 31/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1674368000.0000 - val_loss: 3037245696.0000\n",
      "Epoch 32/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1662666112.0000 - val_loss: 3074506240.0000\n",
      "Epoch 33/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1612315776.0000 - val_loss: 3360013824.0000\n",
      "Epoch 34/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1621607552.0000 - val_loss: 3125741824.0000\n",
      "Epoch 35/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1597061376.0000 - val_loss: 3203304192.0000\n",
      "Epoch 36/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1590744320.0000 - val_loss: 3168020480.0000\n",
      "Epoch 37/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1594117376.0000 - val_loss: 3230565888.0000\n",
      "Epoch 38/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1573894912.0000 - val_loss: 3209666560.0000\n",
      "Epoch 39/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1571248000.0000 - val_loss: 3203379456.0000\n",
      "Epoch 40/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1563246336.0000 - val_loss: 3313533184.0000\n",
      "Epoch 41/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1559511168.0000 - val_loss: 3179759360.0000\n",
      "Epoch 42/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1557639424.0000 - val_loss: 3221293824.0000\n",
      "Epoch 43/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1562967040.0000 - val_loss: 3203459072.0000\n",
      "Epoch 44/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1541888256.0000 - val_loss: 3162472448.0000\n",
      "Epoch 45/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1556760576.0000 - val_loss: 3175334656.0000\n",
      "Epoch 46/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1549644800.0000 - val_loss: 3295714304.0000\n",
      "Epoch 47/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1547330176.0000 - val_loss: 3218818304.0000\n",
      "Epoch 48/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1555015680.0000 - val_loss: 3214322688.0000\n",
      "Epoch 49/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1539147392.0000 - val_loss: 3242261504.0000\n",
      "Epoch 50/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1545317376.0000 - val_loss: 3285693952.0000\n",
      "Epoch 51/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1533525760.0000 - val_loss: 3203142656.0000\n",
      "Epoch 52/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1529140352.0000 - val_loss: 3310943488.0000\n",
      "Epoch 53/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1542797440.0000 - val_loss: 3236264192.0000\n",
      "Epoch 54/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1530414336.0000 - val_loss: 3235497216.0000\n",
      "Epoch 55/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1528786432.0000 - val_loss: 3174693632.0000\n",
      "Epoch 56/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1519831552.0000 - val_loss: 3163360256.0000\n",
      "Epoch 57/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1529688320.0000 - val_loss: 3242223104.0000\n",
      "Epoch 58/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1534275456.0000 - val_loss: 3247794944.0000\n",
      "Epoch 59/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1531962752.0000 - val_loss: 3190380544.0000\n",
      "Epoch 60/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1513711616.0000 - val_loss: 3210542336.0000\n",
      "Epoch 61/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1517191552.0000 - val_loss: 3251589120.0000\n",
      "Epoch 62/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1527674880.0000 - val_loss: 3233914624.0000\n",
      "Epoch 63/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1511476736.0000 - val_loss: 3222547968.0000\n",
      "Epoch 64/1000\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 1503026560.0000 - val_loss: 3186898688.0000\n",
      "Epoch 65/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1512008576.0000 - val_loss: 3215547136.0000\n",
      "Epoch 66/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1503518848.0000 - val_loss: 3241067776.0000\n",
      "Epoch 67/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1495751808.0000 - val_loss: 3253429504.0000\n",
      "Epoch 68/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1509152896.0000 - val_loss: 3222467840.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1494848640.0000 - val_loss: 3146216704.0000\n",
      "Epoch 70/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1502049536.0000 - val_loss: 3182426368.0000\n",
      "Epoch 71/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1492711936.0000 - val_loss: 3230511872.0000\n",
      "Epoch 72/1000\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 1500993024.0000 - val_loss: 3181466624.0000\n",
      "Epoch 73/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1483144576.0000 - val_loss: 3150591744.0000\n",
      "Epoch 74/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1496405248.0000 - val_loss: 3228037632.0000\n",
      "Epoch 75/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1488683904.0000 - val_loss: 3216710400.0000\n",
      "Epoch 76/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1477805312.0000 - val_loss: 3316195840.0000\n",
      "Epoch 77/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1489336320.0000 - val_loss: 3148467712.0000\n",
      "Epoch 78/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1477583488.0000 - val_loss: 3134339584.0000\n",
      "Epoch 79/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1466414720.0000 - val_loss: 3308922880.0000\n",
      "Epoch 80/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1472979328.0000 - val_loss: 3204820736.0000\n",
      "Epoch 81/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1471842176.0000 - val_loss: 3279261952.0000\n",
      "Epoch 82/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1479091712.0000 - val_loss: 3172967168.0000\n",
      "Epoch 83/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1464581888.0000 - val_loss: 3173556480.0000\n",
      "Epoch 84/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1471556096.0000 - val_loss: 3225715968.0000\n",
      "Epoch 85/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1462840704.0000 - val_loss: 3244931840.0000\n",
      "Epoch 86/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1456462976.0000 - val_loss: 3261678848.0000\n",
      "Epoch 87/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1460249856.0000 - val_loss: 3161137408.0000\n",
      "Epoch 88/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1462740480.0000 - val_loss: 3189739264.0000\n",
      "Epoch 89/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1448608768.0000 - val_loss: 3301560832.0000\n",
      "Epoch 90/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1459836288.0000 - val_loss: 3178464256.0000\n",
      "Epoch 91/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1437656192.0000 - val_loss: 3284006912.0000\n",
      "Epoch 92/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1453562880.0000 - val_loss: 3127760128.0000\n",
      "Epoch 93/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1442914432.0000 - val_loss: 3112342784.0000\n",
      "Epoch 94/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1442757248.0000 - val_loss: 3224381696.0000\n",
      "Epoch 95/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1441910912.0000 - val_loss: 3151599104.0000\n",
      "Epoch 96/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1451032192.0000 - val_loss: 3124000256.0000\n",
      "Epoch 97/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1448299008.0000 - val_loss: 3246369792.0000\n",
      "Epoch 98/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1445696896.0000 - val_loss: 3184750848.0000\n",
      "Epoch 99/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1438041344.0000 - val_loss: 3139492096.0000\n",
      "Epoch 100/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1434179456.0000 - val_loss: 3140993792.0000\n",
      "Epoch 101/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1428011648.0000 - val_loss: 3263755008.0000\n",
      "Epoch 102/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1429628800.0000 - val_loss: 3140251904.0000\n",
      "Epoch 103/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1416540672.0000 - val_loss: 3113491712.0000\n",
      "Epoch 104/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1430588160.0000 - val_loss: 3109157120.0000\n",
      "Epoch 105/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1426313600.0000 - val_loss: 3106747904.0000\n",
      "Epoch 106/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1412979968.0000 - val_loss: 3234208000.0000\n",
      "Epoch 107/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1423410688.0000 - val_loss: 3192387328.0000\n",
      "Epoch 108/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1414738944.0000 - val_loss: 3147535616.0000\n",
      "Epoch 109/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1411943936.0000 - val_loss: 3151418880.0000\n",
      "Epoch 110/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1413948160.0000 - val_loss: 3209587712.0000\n",
      "Epoch 111/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1413501056.0000 - val_loss: 3197629440.0000\n",
      "Epoch 112/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1400365056.0000 - val_loss: 3115038720.0000\n",
      "Epoch 113/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1401980288.0000 - val_loss: 3179675136.0000\n",
      "Epoch 114/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1397654400.0000 - val_loss: 3113266944.0000\n",
      "Epoch 115/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1394288512.0000 - val_loss: 3153807616.0000\n",
      "Epoch 116/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1390529536.0000 - val_loss: 3218524928.0000\n",
      "Epoch 117/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1387799296.0000 - val_loss: 3207105536.0000\n",
      "Epoch 118/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1394486144.0000 - val_loss: 3175569920.0000\n",
      "Epoch 119/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1390913664.0000 - val_loss: 3133847040.0000\n",
      "Epoch 120/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1389079936.0000 - val_loss: 3113789184.0000\n",
      "Epoch 121/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1379168896.0000 - val_loss: 3186510592.0000\n",
      "Epoch 122/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1378368000.0000 - val_loss: 3237352192.0000\n",
      "Epoch 123/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1387191936.0000 - val_loss: 3108603136.0000\n",
      "Epoch 124/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1384497664.0000 - val_loss: 3233448448.0000\n",
      "Epoch 125/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1388344064.0000 - val_loss: 3110695424.0000\n",
      "Epoch 126/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1374309632.0000 - val_loss: 3125289216.0000\n",
      "Epoch 127/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1378926848.0000 - val_loss: 3176255744.0000\n",
      "Epoch 128/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1370056576.0000 - val_loss: 3083708416.0000\n",
      "Epoch 129/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1380067456.0000 - val_loss: 3239113216.0000\n",
      "Epoch 130/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1355407872.0000 - val_loss: 3301689600.0000\n",
      "Epoch 131/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1374503808.0000 - val_loss: 3104784896.0000\n",
      "Epoch 132/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1360016128.0000 - val_loss: 3201067520.0000\n",
      "Epoch 133/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1357622656.0000 - val_loss: 3212120576.0000\n",
      "Epoch 134/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1363605376.0000 - val_loss: 3194920192.0000\n",
      "Epoch 135/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1354392448.0000 - val_loss: 3235430912.0000\n",
      "Epoch 136/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 1365340672.0000 - val_loss: 3115324160.0000\n",
      "Epoch 137/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1352244224.0000 - val_loss: 3130953728.0000\n",
      "Epoch 138/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1348920576.0000 - val_loss: 3100126208.0000\n",
      "Epoch 139/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1351819136.0000 - val_loss: 3087862016.0000\n",
      "Epoch 140/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1348389248.0000 - val_loss: 3206830848.0000\n",
      "Epoch 141/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1348248448.0000 - val_loss: 3148914944.0000\n",
      "Epoch 142/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1342057728.0000 - val_loss: 3107885312.0000\n",
      "Epoch 143/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1346080512.0000 - val_loss: 3147205632.0000\n",
      "Epoch 144/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1346309376.0000 - val_loss: 3215192576.0000\n",
      "Epoch 145/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1339742336.0000 - val_loss: 3254484992.0000\n",
      "Epoch 146/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1348143360.0000 - val_loss: 3137142016.0000\n",
      "Epoch 147/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1339442432.0000 - val_loss: 3152048640.0000\n",
      "Epoch 148/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1332704256.0000 - val_loss: 3095421184.0000\n",
      "Epoch 149/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1331133184.0000 - val_loss: 3110220544.0000\n",
      "Epoch 150/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1334424704.0000 - val_loss: 3103690496.0000\n",
      "Epoch 151/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1327209344.0000 - val_loss: 3068299776.0000\n",
      "Epoch 152/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1334868096.0000 - val_loss: 3175794944.0000\n",
      "Epoch 153/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1327903744.0000 - val_loss: 3115635200.0000\n",
      "Epoch 154/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1345734528.0000 - val_loss: 3106536960.0000\n",
      "Epoch 155/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1319317888.0000 - val_loss: 3147588352.0000\n",
      "Epoch 156/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1326346880.0000 - val_loss: 3060382208.0000\n",
      "Epoch 157/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1316234752.0000 - val_loss: 3127689728.0000\n",
      "Epoch 158/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1315994240.0000 - val_loss: 3077960960.0000\n",
      "Epoch 159/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1323637760.0000 - val_loss: 3089622784.0000\n",
      "Epoch 160/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1325661440.0000 - val_loss: 3155333120.0000\n",
      "Epoch 161/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1314071808.0000 - val_loss: 3078300928.0000\n",
      "Epoch 162/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1316177024.0000 - val_loss: 3081155584.0000\n",
      "Epoch 163/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1311693952.0000 - val_loss: 3103700736.0000\n",
      "Epoch 164/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1310292608.0000 - val_loss: 3098751744.0000\n",
      "Epoch 165/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1308120576.0000 - val_loss: 3069364224.0000\n",
      "Epoch 166/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1311113856.0000 - val_loss: 3050668544.0000\n",
      "Epoch 167/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1308820480.0000 - val_loss: 3116333312.0000\n",
      "Epoch 168/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1314033152.0000 - val_loss: 3148526848.0000\n",
      "Epoch 169/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1308315904.0000 - val_loss: 3063446784.0000\n",
      "Epoch 170/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1307052672.0000 - val_loss: 3220554496.0000\n",
      "Epoch 171/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1308730880.0000 - val_loss: 3057629184.0000\n",
      "Epoch 172/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1301192704.0000 - val_loss: 3057738240.0000\n",
      "Epoch 173/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1309701888.0000 - val_loss: 3140881152.0000\n",
      "Epoch 174/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1302069888.0000 - val_loss: 3106105856.0000\n",
      "Epoch 175/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1301318784.0000 - val_loss: 3061894656.0000\n",
      "Epoch 176/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1298253440.0000 - val_loss: 3053882368.0000\n",
      "Epoch 177/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1290515968.0000 - val_loss: 3037785344.0000\n",
      "Epoch 178/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1299267584.0000 - val_loss: 3072495360.0000\n",
      "Epoch 179/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1297747200.0000 - val_loss: 3076931584.0000\n",
      "Epoch 180/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1287956992.0000 - val_loss: 3062179584.0000\n",
      "Epoch 181/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1295569792.0000 - val_loss: 3114055424.0000\n",
      "Epoch 182/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1288937728.0000 - val_loss: 3062690048.0000\n",
      "Epoch 183/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1291435264.0000 - val_loss: 3183613952.0000\n",
      "Epoch 184/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1288031744.0000 - val_loss: 3032179456.0000\n",
      "Epoch 185/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1282111616.0000 - val_loss: 2997465344.0000\n",
      "Epoch 186/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1280947584.0000 - val_loss: 3163872768.0000\n",
      "Epoch 187/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1281760000.0000 - val_loss: 3061819136.0000\n",
      "Epoch 188/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1280493184.0000 - val_loss: 3033084416.0000\n",
      "Epoch 189/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1282795008.0000 - val_loss: 3078141696.0000\n",
      "Epoch 190/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1279158272.0000 - val_loss: 3046250496.0000\n",
      "Epoch 191/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1281518848.0000 - val_loss: 3102873088.0000\n",
      "Epoch 192/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1283276288.0000 - val_loss: 3064837632.0000\n",
      "Epoch 193/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1283084928.0000 - val_loss: 3064957440.0000\n",
      "Epoch 194/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1265490816.0000 - val_loss: 3035483904.0000\n",
      "Epoch 195/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1283849728.0000 - val_loss: 3075608064.0000\n",
      "Epoch 196/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1276852224.0000 - val_loss: 3036044032.0000\n",
      "Epoch 197/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1271285248.0000 - val_loss: 3065655552.0000\n",
      "Epoch 198/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1270537984.0000 - val_loss: 3022102528.0000\n",
      "Epoch 199/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1265717376.0000 - val_loss: 3052050944.0000\n",
      "Epoch 200/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1270128256.0000 - val_loss: 3001700864.0000\n",
      "Epoch 201/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1271252224.0000 - val_loss: 3087905536.0000\n",
      "Epoch 202/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1272996736.0000 - val_loss: 2996177664.0000\n",
      "Epoch 203/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 1271752192.0000 - val_loss: 3022277120.0000\n",
      "Epoch 204/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1261870080.0000 - val_loss: 3055187200.0000\n",
      "Epoch 205/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1262090880.0000 - val_loss: 3016117504.0000\n",
      "Epoch 206/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1264356736.0000 - val_loss: 3019496192.0000\n",
      "Epoch 207/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1254284032.0000 - val_loss: 3004878592.0000\n",
      "Epoch 208/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1251961472.0000 - val_loss: 3089796864.0000\n",
      "Epoch 209/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1262176512.0000 - val_loss: 2966471424.0000\n",
      "Epoch 210/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1255596160.0000 - val_loss: 3082335232.0000\n",
      "Epoch 211/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1256371200.0000 - val_loss: 3098198784.0000\n",
      "Epoch 212/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1254199168.0000 - val_loss: 3049712384.0000\n",
      "Epoch 213/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1266824448.0000 - val_loss: 2975988992.0000\n",
      "Epoch 214/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1240838272.0000 - val_loss: 2995486208.0000\n",
      "Epoch 215/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1261638912.0000 - val_loss: 3019295488.0000\n",
      "Epoch 216/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1250716032.0000 - val_loss: 2993766400.0000\n",
      "Epoch 217/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1249920512.0000 - val_loss: 2988668928.0000\n",
      "Epoch 218/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1246239488.0000 - val_loss: 3050642944.0000\n",
      "Epoch 219/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1245191808.0000 - val_loss: 3107956736.0000\n",
      "Epoch 220/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1251240832.0000 - val_loss: 3052648192.0000\n",
      "Epoch 221/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1249243648.0000 - val_loss: 3077286912.0000\n",
      "Epoch 222/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1249482880.0000 - val_loss: 3058971392.0000\n",
      "Epoch 223/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1245437696.0000 - val_loss: 3083059712.0000\n",
      "Epoch 224/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1243610112.0000 - val_loss: 2963569408.0000\n",
      "Epoch 225/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1241146752.0000 - val_loss: 2972426496.0000\n",
      "Epoch 226/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1245654784.0000 - val_loss: 3000100352.0000\n",
      "Epoch 227/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1239151360.0000 - val_loss: 3068724992.0000\n",
      "Epoch 228/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1246712704.0000 - val_loss: 3080245248.0000\n",
      "Epoch 229/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1239683200.0000 - val_loss: 3065001728.0000\n",
      "Epoch 230/1000\n",
      "116/116 [==============================] - ETA: 0s - loss: 1284857216.00 - 0s 2ms/step - loss: 1238856448.0000 - val_loss: 2978323968.0000\n",
      "Epoch 231/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1231672832.0000 - val_loss: 3165776640.0000\n",
      "Epoch 232/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1234364160.0000 - val_loss: 2956276480.0000\n",
      "Epoch 233/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1233940352.0000 - val_loss: 3021161984.0000\n",
      "Epoch 234/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1230445440.0000 - val_loss: 3011664896.0000\n",
      "Epoch 235/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1243628416.0000 - val_loss: 2940476160.0000\n",
      "Epoch 236/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1239772288.0000 - val_loss: 2999621888.0000\n",
      "Epoch 237/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1233376768.0000 - val_loss: 3041799424.0000\n",
      "Epoch 238/1000\n",
      "116/116 [==============================] - ETA: 0s - loss: 1062884160.00 - 0s 2ms/step - loss: 1229435776.0000 - val_loss: 3015869696.0000\n",
      "Epoch 239/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1227900544.0000 - val_loss: 2975820288.0000\n",
      "Epoch 240/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1224087296.0000 - val_loss: 2913748736.0000\n",
      "Epoch 241/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1229806336.0000 - val_loss: 2943245056.0000\n",
      "Epoch 242/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1217015680.0000 - val_loss: 2908758016.0000\n",
      "Epoch 243/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1226732288.0000 - val_loss: 2948606464.0000\n",
      "Epoch 244/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1223966208.0000 - val_loss: 2990298112.0000\n",
      "Epoch 245/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1228700416.0000 - val_loss: 2938566912.0000\n",
      "Epoch 246/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1216290432.0000 - val_loss: 2970644224.0000\n",
      "Epoch 247/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1218215040.0000 - val_loss: 3017747456.0000\n",
      "Epoch 248/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1222205440.0000 - val_loss: 3079440640.0000\n",
      "Epoch 249/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1227774080.0000 - val_loss: 3084470528.0000\n",
      "Epoch 250/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1229769984.0000 - val_loss: 2918250496.0000\n",
      "Epoch 251/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1216618496.0000 - val_loss: 2943069696.0000\n",
      "Epoch 252/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1218156032.0000 - val_loss: 3032609536.0000\n",
      "Epoch 253/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1207866240.0000 - val_loss: 2920457216.0000\n",
      "Epoch 254/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1217509888.0000 - val_loss: 2973852416.0000\n",
      "Epoch 255/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1211997824.0000 - val_loss: 2977770240.0000\n",
      "Epoch 256/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1206891648.0000 - val_loss: 2926550272.0000\n",
      "Epoch 257/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1214328192.0000 - val_loss: 2926496512.0000\n",
      "Epoch 258/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1214825472.0000 - val_loss: 2916726016.0000\n",
      "Epoch 259/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1212668032.0000 - val_loss: 2928457216.0000\n",
      "Epoch 260/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1210573824.0000 - val_loss: 2889891072.0000\n",
      "Epoch 261/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1212227712.0000 - val_loss: 2866205696.0000\n",
      "Epoch 262/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1200724864.0000 - val_loss: 3035039488.0000\n",
      "Epoch 263/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1210015872.0000 - val_loss: 2963311104.0000\n",
      "Epoch 264/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1216094208.0000 - val_loss: 2924721920.0000\n",
      "Epoch 265/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1198346240.0000 - val_loss: 2935303680.0000\n",
      "Epoch 266/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1214508800.0000 - val_loss: 3114437376.0000\n",
      "Epoch 267/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1208364672.0000 - val_loss: 2931296512.0000\n",
      "Epoch 268/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1215449472.0000 - val_loss: 2868228608.0000\n",
      "Epoch 269/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1198301696.0000 - val_loss: 2944839936.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1193651456.0000 - val_loss: 2980911104.0000\n",
      "Epoch 271/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1216097536.0000 - val_loss: 2976327936.0000\n",
      "Epoch 272/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1204318976.0000 - val_loss: 2914985984.0000\n",
      "Epoch 273/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1195890560.0000 - val_loss: 2929909504.0000\n",
      "Epoch 274/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1196386816.0000 - val_loss: 2860482560.0000\n",
      "Epoch 275/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1196193408.0000 - val_loss: 2918679808.0000\n",
      "Epoch 276/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1191598336.0000 - val_loss: 2937715200.0000\n",
      "Epoch 277/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1205103744.0000 - val_loss: 2958178560.0000\n",
      "Epoch 278/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1189277440.0000 - val_loss: 2895737344.0000\n",
      "Epoch 279/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1189446400.0000 - val_loss: 2823138560.0000\n",
      "Epoch 280/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1203842560.0000 - val_loss: 2912844800.0000\n",
      "Epoch 281/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1195634432.0000 - val_loss: 2836144128.0000\n",
      "Epoch 282/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1195300480.0000 - val_loss: 2873507584.0000\n",
      "Epoch 283/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1177430656.0000 - val_loss: 2805759744.0000\n",
      "Epoch 284/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1188774016.0000 - val_loss: 2830029312.0000\n",
      "Epoch 285/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1182936832.0000 - val_loss: 2840376320.0000\n",
      "Epoch 286/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1186894208.0000 - val_loss: 2916729088.0000\n",
      "Epoch 287/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1180005120.0000 - val_loss: 2835716608.0000\n",
      "Epoch 288/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1187829632.0000 - val_loss: 2950960384.0000\n",
      "Epoch 289/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1190942080.0000 - val_loss: 2848545536.0000\n",
      "Epoch 290/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1186690560.0000 - val_loss: 2889644288.0000\n",
      "Epoch 291/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1183614080.0000 - val_loss: 2792077568.0000\n",
      "Epoch 292/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1184393216.0000 - val_loss: 2807548160.0000\n",
      "Epoch 293/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1178577792.0000 - val_loss: 2846609408.0000\n",
      "Epoch 294/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1185901440.0000 - val_loss: 2784677632.0000\n",
      "Epoch 295/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1176183936.0000 - val_loss: 2764305152.0000\n",
      "Epoch 296/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1169579008.0000 - val_loss: 2779150336.0000\n",
      "Epoch 297/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1184577536.0000 - val_loss: 2772532480.0000\n",
      "Epoch 298/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1185856768.0000 - val_loss: 2850036736.0000\n",
      "Epoch 299/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1179065344.0000 - val_loss: 2834874112.0000\n",
      "Epoch 300/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1175549440.0000 - val_loss: 2902573568.0000\n",
      "Epoch 301/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1172986368.0000 - val_loss: 2783615232.0000\n",
      "Epoch 302/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1170690304.0000 - val_loss: 2821592832.0000\n",
      "Epoch 303/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1176525312.0000 - val_loss: 2830557696.0000\n",
      "Epoch 304/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1174818816.0000 - val_loss: 2921073664.0000\n",
      "Epoch 305/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1172628864.0000 - val_loss: 2817318656.0000\n",
      "Epoch 306/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1183335424.0000 - val_loss: 2777210112.0000\n",
      "Epoch 307/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1166975616.0000 - val_loss: 2870569984.0000\n",
      "Epoch 308/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1171988224.0000 - val_loss: 2840837888.0000\n",
      "Epoch 309/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1163748864.0000 - val_loss: 2871319296.0000\n",
      "Epoch 310/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1166099072.0000 - val_loss: 2850862336.0000\n",
      "Epoch 311/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1168028032.0000 - val_loss: 2895367424.0000\n",
      "Epoch 312/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1151110912.0000 - val_loss: 2915651584.0000\n",
      "Epoch 313/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1165730048.0000 - val_loss: 2802334976.0000\n",
      "Epoch 314/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1161260416.0000 - val_loss: 2813858048.0000\n",
      "Epoch 315/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1164711296.0000 - val_loss: 2799099648.0000\n",
      "Epoch 316/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1163642496.0000 - val_loss: 2789856000.0000\n",
      "Epoch 317/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1164034560.0000 - val_loss: 2762496000.0000\n",
      "Epoch 318/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1157005696.0000 - val_loss: 2855119872.0000\n",
      "Epoch 319/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1155602816.0000 - val_loss: 2887366912.0000\n",
      "Epoch 320/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1168834048.0000 - val_loss: 2763154944.0000\n",
      "Epoch 321/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1159883008.0000 - val_loss: 2763839488.0000\n",
      "Epoch 322/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1151530240.0000 - val_loss: 2868910592.0000\n",
      "Epoch 323/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1160244096.0000 - val_loss: 2744144128.0000\n",
      "Epoch 324/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1159003648.0000 - val_loss: 2701082624.0000\n",
      "Epoch 325/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1154990464.0000 - val_loss: 2744512256.0000\n",
      "Epoch 326/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1155392896.0000 - val_loss: 2880851200.0000\n",
      "Epoch 327/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1156473216.0000 - val_loss: 2766387968.0000\n",
      "Epoch 328/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1140595840.0000 - val_loss: 2715138560.0000\n",
      "Epoch 329/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1155015552.0000 - val_loss: 2719983872.0000\n",
      "Epoch 330/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1153205504.0000 - val_loss: 2770396672.0000\n",
      "Epoch 331/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1149355392.0000 - val_loss: 2726389760.0000\n",
      "Epoch 332/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1160581120.0000 - val_loss: 2717409024.0000\n",
      "Epoch 333/1000\n",
      "116/116 [==============================] - ETA: 0s - loss: 1194671616.00 - 0s 2ms/step - loss: 1143544832.0000 - val_loss: 2765343232.0000\n",
      "Epoch 334/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1144346880.0000 - val_loss: 2725463808.0000\n",
      "Epoch 335/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1141470592.0000 - val_loss: 2851122176.0000\n",
      "Epoch 336/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1145342720.0000 - val_loss: 2773399552.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1147710848.0000 - val_loss: 2827401984.0000\n",
      "Epoch 338/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1147375232.0000 - val_loss: 2753278464.0000\n",
      "Epoch 339/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1144370304.0000 - val_loss: 2763460352.0000\n",
      "Epoch 340/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1139440768.0000 - val_loss: 2705264128.0000\n",
      "Epoch 341/1000\n",
      "116/116 [==============================] - ETA: 0s - loss: 1122881664.00 - 0s 2ms/step - loss: 1147790208.0000 - val_loss: 2712077312.0000\n",
      "Epoch 342/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1148785280.0000 - val_loss: 2752686592.0000\n",
      "Epoch 343/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1142865280.0000 - val_loss: 2777970176.0000\n",
      "Epoch 344/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1139591552.0000 - val_loss: 2759544832.0000\n",
      "Epoch 345/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1139057536.0000 - val_loss: 2737154816.0000\n",
      "Epoch 346/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1140398208.0000 - val_loss: 2696948224.0000\n",
      "Epoch 347/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1136641408.0000 - val_loss: 2755686912.0000\n",
      "Epoch 348/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1140132352.0000 - val_loss: 2765985536.0000\n",
      "Epoch 349/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1131842560.0000 - val_loss: 2735337728.0000\n",
      "Epoch 350/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1137201024.0000 - val_loss: 2674119680.0000\n",
      "Epoch 351/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1130774656.0000 - val_loss: 2723913984.0000\n",
      "Epoch 352/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1131488000.0000 - val_loss: 2713533696.0000\n",
      "Epoch 353/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1127392000.0000 - val_loss: 2680123136.0000\n",
      "Epoch 354/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1123092224.0000 - val_loss: 2681483264.0000\n",
      "Epoch 355/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1127467520.0000 - val_loss: 2662623488.0000\n",
      "Epoch 356/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1123910784.0000 - val_loss: 2697101568.0000\n",
      "Epoch 357/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1122302592.0000 - val_loss: 2675815936.0000\n",
      "Epoch 358/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1135114752.0000 - val_loss: 2671470080.0000\n",
      "Epoch 359/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1122372608.0000 - val_loss: 2707155456.0000\n",
      "Epoch 360/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1127649920.0000 - val_loss: 2711434496.0000\n",
      "Epoch 361/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1125021952.0000 - val_loss: 2684954880.0000\n",
      "Epoch 362/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1129300352.0000 - val_loss: 2650272512.0000\n",
      "Epoch 363/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1114887296.0000 - val_loss: 2788173824.0000\n",
      "Epoch 364/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1120561792.0000 - val_loss: 2628607488.0000\n",
      "Epoch 365/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1117154688.0000 - val_loss: 2699988736.0000\n",
      "Epoch 366/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1120860800.0000 - val_loss: 2617417984.0000\n",
      "Epoch 367/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1125140736.0000 - val_loss: 2621697792.0000\n",
      "Epoch 368/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1120377472.0000 - val_loss: 2622925312.0000\n",
      "Epoch 369/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1112809984.0000 - val_loss: 2674957824.0000\n",
      "Epoch 370/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1119643520.0000 - val_loss: 2684594944.0000\n",
      "Epoch 371/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1111088768.0000 - val_loss: 2620993536.0000\n",
      "Epoch 372/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1120679552.0000 - val_loss: 2640241920.0000\n",
      "Epoch 373/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1107817088.0000 - val_loss: 2641277440.0000\n",
      "Epoch 374/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1112137984.0000 - val_loss: 2747171584.0000\n",
      "Epoch 375/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1123475328.0000 - val_loss: 2647005184.0000\n",
      "Epoch 376/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1122210048.0000 - val_loss: 2627514624.0000\n",
      "Epoch 377/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1103799168.0000 - val_loss: 2593793280.0000\n",
      "Epoch 378/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1105238144.0000 - val_loss: 2623292672.0000\n",
      "Epoch 379/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1110791168.0000 - val_loss: 2732227328.0000\n",
      "Epoch 380/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1102364928.0000 - val_loss: 2582007296.0000\n",
      "Epoch 381/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1103572096.0000 - val_loss: 2656274176.0000\n",
      "Epoch 382/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1107629824.0000 - val_loss: 2685827328.0000\n",
      "Epoch 383/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1108881152.0000 - val_loss: 2599234304.0000\n",
      "Epoch 384/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1108490368.0000 - val_loss: 2617733632.0000\n",
      "Epoch 385/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1102976640.0000 - val_loss: 2639806208.0000\n",
      "Epoch 386/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1101228160.0000 - val_loss: 2632633088.0000\n",
      "Epoch 387/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1102276224.0000 - val_loss: 2549989888.0000\n",
      "Epoch 388/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1101096192.0000 - val_loss: 2602855168.0000\n",
      "Epoch 389/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1101707008.0000 - val_loss: 2620359936.0000\n",
      "Epoch 390/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1099994240.0000 - val_loss: 2594814720.0000\n",
      "Epoch 391/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1116859136.0000 - val_loss: 2639035392.0000\n",
      "Epoch 392/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1096561024.0000 - val_loss: 2583832576.0000\n",
      "Epoch 393/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1095750016.0000 - val_loss: 2565555456.0000\n",
      "Epoch 394/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1106360064.0000 - val_loss: 2585272576.0000\n",
      "Epoch 395/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1093007232.0000 - val_loss: 2541888256.0000\n",
      "Epoch 396/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1095577472.0000 - val_loss: 2676326912.0000\n",
      "Epoch 397/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1102840320.0000 - val_loss: 2580349696.0000\n",
      "Epoch 398/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1105492736.0000 - val_loss: 2585783296.0000\n",
      "Epoch 399/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1090190720.0000 - val_loss: 2550597632.0000\n",
      "Epoch 400/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1093042688.0000 - val_loss: 2587667456.0000\n",
      "Epoch 401/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1079711360.0000 - val_loss: 2766657536.0000\n",
      "Epoch 402/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1100493568.0000 - val_loss: 2571738624.0000\n",
      "Epoch 403/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1090807808.0000 - val_loss: 2564307200.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1089964800.0000 - val_loss: 2603799040.0000\n",
      "Epoch 405/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1089860096.0000 - val_loss: 2536332032.0000\n",
      "Epoch 406/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1089330176.0000 - val_loss: 2571705344.0000\n",
      "Epoch 407/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1089629440.0000 - val_loss: 2601589760.0000\n",
      "Epoch 408/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1106334464.0000 - val_loss: 2560729344.0000\n",
      "Epoch 409/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1087839104.0000 - val_loss: 2507896576.0000\n",
      "Epoch 410/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1083420288.0000 - val_loss: 2683291392.0000\n",
      "Epoch 411/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1095696640.0000 - val_loss: 2565366784.0000\n",
      "Epoch 412/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1091643776.0000 - val_loss: 2573368320.0000\n",
      "Epoch 413/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1080574464.0000 - val_loss: 2529533184.0000\n",
      "Epoch 414/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1074452480.0000 - val_loss: 2549997312.0000\n",
      "Epoch 415/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1083349504.0000 - val_loss: 2542851072.0000\n",
      "Epoch 416/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1085102464.0000 - val_loss: 2567795200.0000\n",
      "Epoch 417/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1089573632.0000 - val_loss: 2606212608.0000\n",
      "Epoch 418/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1086620672.0000 - val_loss: 2645204480.0000\n",
      "Epoch 419/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1077619840.0000 - val_loss: 2574868736.0000\n",
      "Epoch 420/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1088492800.0000 - val_loss: 2557903104.0000\n",
      "Epoch 421/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1076798080.0000 - val_loss: 2472050688.0000\n",
      "Epoch 422/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1069850688.0000 - val_loss: 2571755264.0000\n",
      "Epoch 423/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1084625152.0000 - val_loss: 2549081088.0000\n",
      "Epoch 424/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1073055936.0000 - val_loss: 2530676480.0000\n",
      "Epoch 425/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1074447232.0000 - val_loss: 2461235200.0000\n",
      "Epoch 426/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1073679552.0000 - val_loss: 2592758272.0000\n",
      "Epoch 427/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1071351360.0000 - val_loss: 2593915136.0000\n",
      "Epoch 428/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1069765952.0000 - val_loss: 2590880768.0000\n",
      "Epoch 429/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1069335104.0000 - val_loss: 2505781248.0000\n",
      "Epoch 430/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1073286912.0000 - val_loss: 2473383168.0000\n",
      "Epoch 431/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1067962112.0000 - val_loss: 2485221888.0000\n",
      "Epoch 432/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1060766016.0000 - val_loss: 2535864064.0000\n",
      "Epoch 433/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1056498496.0000 - val_loss: 2476578304.0000\n",
      "Epoch 434/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1065291776.0000 - val_loss: 2515880192.0000\n",
      "Epoch 435/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1060837760.0000 - val_loss: 2476598784.0000\n",
      "Epoch 436/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1074859264.0000 - val_loss: 2437891584.0000\n",
      "Epoch 437/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1061196096.0000 - val_loss: 2410778368.0000\n",
      "Epoch 438/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1064717312.0000 - val_loss: 2449025024.0000\n",
      "Epoch 439/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1061457664.0000 - val_loss: 2483324672.0000\n",
      "Epoch 440/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1064398976.0000 - val_loss: 2497175296.0000\n",
      "Epoch 441/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1057481536.0000 - val_loss: 2431489536.0000\n",
      "Epoch 442/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1052608064.0000 - val_loss: 2460765440.0000\n",
      "Epoch 443/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1054665408.0000 - val_loss: 2399221248.0000\n",
      "Epoch 444/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1063369408.0000 - val_loss: 2434479872.0000\n",
      "Epoch 445/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1056855104.0000 - val_loss: 2473857536.0000\n",
      "Epoch 446/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1060106624.0000 - val_loss: 2498370048.0000\n",
      "Epoch 447/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1062958912.0000 - val_loss: 2431084032.0000\n",
      "Epoch 448/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1048407744.0000 - val_loss: 2415255296.0000\n",
      "Epoch 449/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1060856064.0000 - val_loss: 2459443456.0000\n",
      "Epoch 450/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1053591104.0000 - val_loss: 2519430144.0000\n",
      "Epoch 451/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1043929024.0000 - val_loss: 2510470144.0000\n",
      "Epoch 452/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1044628224.0000 - val_loss: 2428054528.0000\n",
      "Epoch 453/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1046848128.0000 - val_loss: 2352208128.0000\n",
      "Epoch 454/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1042281600.0000 - val_loss: 2378107904.0000\n",
      "Epoch 455/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1063545984.0000 - val_loss: 2370202112.0000\n",
      "Epoch 456/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1057576832.0000 - val_loss: 2389053696.0000\n",
      "Epoch 457/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1041985344.0000 - val_loss: 2433130240.0000\n",
      "Epoch 458/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1049434944.0000 - val_loss: 2462371328.0000\n",
      "Epoch 459/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1042109504.0000 - val_loss: 2363639552.0000\n",
      "Epoch 460/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1045439424.0000 - val_loss: 2373626112.0000\n",
      "Epoch 461/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1039078720.0000 - val_loss: 2372781312.0000\n",
      "Epoch 462/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1036676224.0000 - val_loss: 2387193600.0000\n",
      "Epoch 463/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1039571264.0000 - val_loss: 2333293568.0000\n",
      "Epoch 464/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1044624960.0000 - val_loss: 2359896064.0000\n",
      "Epoch 465/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1040407744.0000 - val_loss: 2454729984.0000\n",
      "Epoch 466/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1047299392.0000 - val_loss: 2350379008.0000\n",
      "Epoch 467/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1038343552.0000 - val_loss: 2301395968.0000\n",
      "Epoch 468/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1041419904.0000 - val_loss: 2373195264.0000\n",
      "Epoch 469/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1031246144.0000 - val_loss: 2356858624.0000\n",
      "Epoch 470/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1029168960.0000 - val_loss: 2416476160.0000\n",
      "Epoch 471/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 1037736896.0000 - val_loss: 2333268224.0000\n",
      "Epoch 472/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1030533376.0000 - val_loss: 2407067136.0000\n",
      "Epoch 473/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1044486464.0000 - val_loss: 2383144448.0000\n",
      "Epoch 474/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1041508608.0000 - val_loss: 2348293376.0000\n",
      "Epoch 475/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1027506304.0000 - val_loss: 2348171008.0000\n",
      "Epoch 476/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1025557056.0000 - val_loss: 2341922304.0000\n",
      "Epoch 477/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1025685184.0000 - val_loss: 2315633152.0000\n",
      "Epoch 478/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1019511552.0000 - val_loss: 2340169728.0000\n",
      "Epoch 479/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1021387840.0000 - val_loss: 2278578176.0000\n",
      "Epoch 480/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1017156544.0000 - val_loss: 2331108096.0000\n",
      "Epoch 481/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1030840384.0000 - val_loss: 2312846080.0000\n",
      "Epoch 482/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1013831424.0000 - val_loss: 2353703168.0000\n",
      "Epoch 483/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1019061888.0000 - val_loss: 2299283968.0000\n",
      "Epoch 484/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1020857408.0000 - val_loss: 2279665152.0000\n",
      "Epoch 485/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1014371264.0000 - val_loss: 2288178944.0000\n",
      "Epoch 486/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1015489728.0000 - val_loss: 2279482624.0000\n",
      "Epoch 487/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1012851648.0000 - val_loss: 2309312256.0000\n",
      "Epoch 488/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1016256832.0000 - val_loss: 2388953344.0000\n",
      "Epoch 489/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1010818688.0000 - val_loss: 2292659968.0000\n",
      "Epoch 490/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1014482944.0000 - val_loss: 2369075456.0000\n",
      "Epoch 491/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1022217728.0000 - val_loss: 2323819520.0000\n",
      "Epoch 492/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1008128448.0000 - val_loss: 2284112384.0000\n",
      "Epoch 493/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1015049280.0000 - val_loss: 2289148672.0000\n",
      "Epoch 494/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1019208640.0000 - val_loss: 2279521280.0000\n",
      "Epoch 495/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1015911296.0000 - val_loss: 2274390528.0000\n",
      "Epoch 496/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1010631424.0000 - val_loss: 2256621056.0000\n",
      "Epoch 497/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1007958720.0000 - val_loss: 2237093632.0000\n",
      "Epoch 498/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1000461056.0000 - val_loss: 2373737216.0000\n",
      "Epoch 499/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1006565952.0000 - val_loss: 2262327296.0000\n",
      "Epoch 500/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1006051840.0000 - val_loss: 2256055552.0000\n",
      "Epoch 501/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1025285504.0000 - val_loss: 2354090496.0000\n",
      "Epoch 502/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 1013016640.0000 - val_loss: 2371773184.0000\n",
      "Epoch 503/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1005925632.0000 - val_loss: 2279184640.0000\n",
      "Epoch 504/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1003332992.0000 - val_loss: 2231576064.0000\n",
      "Epoch 505/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1003133888.0000 - val_loss: 2233266432.0000\n",
      "Epoch 506/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 997559936.0000 - val_loss: 2261515520.0000\n",
      "Epoch 507/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 997858240.0000 - val_loss: 2322218752.0000\n",
      "Epoch 508/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1002895808.0000 - val_loss: 2201076224.0000\n",
      "Epoch 509/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 998004032.0000 - val_loss: 2273359616.0000\n",
      "Epoch 510/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 992430272.0000 - val_loss: 2239080704.0000\n",
      "Epoch 511/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 998537600.0000 - val_loss: 2157536512.0000\n",
      "Epoch 512/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 994280576.0000 - val_loss: 2231861760.0000\n",
      "Epoch 513/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 992266560.0000 - val_loss: 2211757568.0000\n",
      "Epoch 514/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 983603840.0000 - val_loss: 2247252224.0000\n",
      "Epoch 515/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 986847616.0000 - val_loss: 2233546752.0000\n",
      "Epoch 516/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 989734720.0000 - val_loss: 2222523648.0000\n",
      "Epoch 517/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 987659392.0000 - val_loss: 2163967744.0000\n",
      "Epoch 518/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 993507712.0000 - val_loss: 2132650624.0000\n",
      "Epoch 519/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 984487424.0000 - val_loss: 2213555712.0000\n",
      "Epoch 520/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1010132672.0000 - val_loss: 2299650816.0000\n",
      "Epoch 521/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 995167104.0000 - val_loss: 2154762752.0000\n",
      "Epoch 522/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 987189248.0000 - val_loss: 2164629248.0000\n",
      "Epoch 523/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 980890752.0000 - val_loss: 2152806144.0000\n",
      "Epoch 524/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 982468160.0000 - val_loss: 2256166144.0000\n",
      "Epoch 525/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 983176704.0000 - val_loss: 2119446144.0000\n",
      "Epoch 526/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 980979008.0000 - val_loss: 2152736768.0000\n",
      "Epoch 527/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 975829824.0000 - val_loss: 2136389760.0000\n",
      "Epoch 528/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 981146112.0000 - val_loss: 2152932352.0000\n",
      "Epoch 529/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 979797632.0000 - val_loss: 2142847744.0000\n",
      "Epoch 530/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 976961408.0000 - val_loss: 2160067328.0000\n",
      "Epoch 531/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 992983872.0000 - val_loss: 2193881856.0000\n",
      "Epoch 532/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 981123072.0000 - val_loss: 2166068224.0000\n",
      "Epoch 533/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 968662848.0000 - val_loss: 2187721984.0000\n",
      "Epoch 534/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 971588608.0000 - val_loss: 2212859648.0000\n",
      "Epoch 535/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 972898752.0000 - val_loss: 2089270400.0000\n",
      "Epoch 536/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 962779072.0000 - val_loss: 2100903552.0000\n",
      "Epoch 537/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 969705088.0000 - val_loss: 2137569024.0000\n",
      "Epoch 538/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 966952704.0000 - val_loss: 2112685824.0000\n",
      "Epoch 539/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 972113088.0000 - val_loss: 2162074624.0000\n",
      "Epoch 540/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 961649024.0000 - val_loss: 2081522688.0000\n",
      "Epoch 541/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 969526016.0000 - val_loss: 2123030784.0000\n",
      "Epoch 542/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 956054976.0000 - val_loss: 2155682048.0000\n",
      "Epoch 543/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 965639424.0000 - val_loss: 2040051840.0000\n",
      "Epoch 544/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 958670080.0000 - val_loss: 2048794496.0000\n",
      "Epoch 545/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 974605824.0000 - val_loss: 2032148352.0000\n",
      "Epoch 546/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 966181312.0000 - val_loss: 2063432064.0000\n",
      "Epoch 547/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 958925696.0000 - val_loss: 2153702144.0000\n",
      "Epoch 548/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 948411136.0000 - val_loss: 2026187520.0000\n",
      "Epoch 549/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 950681280.0000 - val_loss: 2043984000.0000\n",
      "Epoch 550/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 955971968.0000 - val_loss: 1997962880.0000\n",
      "Epoch 551/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 964205056.0000 - val_loss: 2149868544.0000\n",
      "Epoch 552/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 951997312.0000 - val_loss: 2092177408.0000\n",
      "Epoch 553/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 953857920.0000 - val_loss: 2090636928.0000\n",
      "Epoch 554/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 958319040.0000 - val_loss: 2087773184.0000\n",
      "Epoch 555/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 964787072.0000 - val_loss: 2062941568.0000\n",
      "Epoch 556/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 958189056.0000 - val_loss: 1988069248.0000\n",
      "Epoch 557/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 947432960.0000 - val_loss: 2023589120.0000\n",
      "Epoch 558/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 955088128.0000 - val_loss: 1973782656.0000\n",
      "Epoch 559/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 941980544.0000 - val_loss: 2008781568.0000\n",
      "Epoch 560/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 946624320.0000 - val_loss: 2021798016.0000\n",
      "Epoch 561/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 944254912.0000 - val_loss: 2048999296.0000\n",
      "Epoch 562/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 952171072.0000 - val_loss: 2018386304.0000\n",
      "Epoch 563/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 941793536.0000 - val_loss: 1989834624.0000\n",
      "Epoch 564/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 940315392.0000 - val_loss: 1921285760.0000\n",
      "Epoch 565/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 938990400.0000 - val_loss: 2184411392.0000\n",
      "Epoch 566/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 933667776.0000 - val_loss: 1985467648.0000\n",
      "Epoch 567/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 935349184.0000 - val_loss: 1985673728.0000\n",
      "Epoch 568/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 940805504.0000 - val_loss: 1930881536.0000\n",
      "Epoch 569/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 944458304.0000 - val_loss: 1936896896.0000\n",
      "Epoch 570/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 940302400.0000 - val_loss: 1964025472.0000\n",
      "Epoch 571/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 925638208.0000 - val_loss: 1921476096.0000\n",
      "Epoch 572/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 935714752.0000 - val_loss: 1953779456.0000\n",
      "Epoch 573/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 930789888.0000 - val_loss: 1961012992.0000\n",
      "Epoch 574/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 940621696.0000 - val_loss: 2037797504.0000\n",
      "Epoch 575/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 931663168.0000 - val_loss: 1928822016.0000\n",
      "Epoch 576/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 941470784.0000 - val_loss: 1914876800.0000\n",
      "Epoch 577/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 929387200.0000 - val_loss: 1925235968.0000\n",
      "Epoch 578/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 930125504.0000 - val_loss: 1893730048.0000\n",
      "Epoch 579/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 923738752.0000 - val_loss: 1899480960.0000\n",
      "Epoch 580/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 923497024.0000 - val_loss: 1923392384.0000\n",
      "Epoch 581/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 930406336.0000 - val_loss: 1943535872.0000\n",
      "Epoch 582/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 930738688.0000 - val_loss: 1854222336.0000\n",
      "Epoch 583/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 916108864.0000 - val_loss: 1936322176.0000\n",
      "Epoch 584/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 923677760.0000 - val_loss: 1927085184.0000\n",
      "Epoch 585/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 926966464.0000 - val_loss: 1955617664.0000\n",
      "Epoch 586/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 918649408.0000 - val_loss: 1895430144.0000\n",
      "Epoch 587/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 918184320.0000 - val_loss: 1878818944.0000\n",
      "Epoch 588/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 919809536.0000 - val_loss: 1877549184.0000\n",
      "Epoch 589/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 923019840.0000 - val_loss: 1862895232.0000\n",
      "Epoch 590/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 918203328.0000 - val_loss: 1826215296.0000\n",
      "Epoch 591/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 921109760.0000 - val_loss: 1868781440.0000\n",
      "Epoch 592/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 917647104.0000 - val_loss: 1940460544.0000\n",
      "Epoch 593/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 907532544.0000 - val_loss: 1846657920.0000\n",
      "Epoch 594/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 905119808.0000 - val_loss: 1985448448.0000\n",
      "Epoch 595/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 913833088.0000 - val_loss: 1856205056.0000\n",
      "Epoch 596/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 911384000.0000 - val_loss: 1942512512.0000\n",
      "Epoch 597/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 906515648.0000 - val_loss: 1828651008.0000\n",
      "Epoch 598/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 907954432.0000 - val_loss: 1792330624.0000\n",
      "Epoch 599/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 907608000.0000 - val_loss: 1763192064.0000\n",
      "Epoch 600/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 907187456.0000 - val_loss: 1888986112.0000\n",
      "Epoch 601/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 905366720.0000 - val_loss: 1849617792.0000\n",
      "Epoch 602/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 898828352.0000 - val_loss: 1825665792.0000\n",
      "Epoch 603/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 892584320.0000 - val_loss: 1816608384.0000\n",
      "Epoch 604/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 892579520.0000 - val_loss: 1781992064.0000\n",
      "Epoch 605/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 897015168.0000 - val_loss: 1758481024.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 887613568.0000 - val_loss: 1821758720.0000\n",
      "Epoch 607/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 888059968.0000 - val_loss: 1834561536.0000\n",
      "Epoch 608/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 888191744.0000 - val_loss: 1849017984.0000\n",
      "Epoch 609/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 885195136.0000 - val_loss: 1940377088.0000\n",
      "Epoch 610/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 889352512.0000 - val_loss: 1770500480.0000\n",
      "Epoch 611/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 887807296.0000 - val_loss: 1740960128.0000\n",
      "Epoch 612/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 879267008.0000 - val_loss: 1773815296.0000\n",
      "Epoch 613/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 883864448.0000 - val_loss: 1831150208.0000\n",
      "Epoch 614/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 881401152.0000 - val_loss: 1779179648.0000\n",
      "Epoch 615/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 893778624.0000 - val_loss: 1759033600.0000\n",
      "Epoch 616/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 887830080.0000 - val_loss: 1756415744.0000\n",
      "Epoch 617/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 882229248.0000 - val_loss: 1814273280.0000\n",
      "Epoch 618/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 889525760.0000 - val_loss: 1771062656.0000\n",
      "Epoch 619/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 879592768.0000 - val_loss: 1726102912.0000\n",
      "Epoch 620/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 870460352.0000 - val_loss: 1745283072.0000\n",
      "Epoch 621/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 879753408.0000 - val_loss: 1712428032.0000\n",
      "Epoch 622/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 882180544.0000 - val_loss: 1746599424.0000\n",
      "Epoch 623/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 883677504.0000 - val_loss: 1708520960.0000\n",
      "Epoch 624/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 879277760.0000 - val_loss: 1734611840.0000\n",
      "Epoch 625/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 871213632.0000 - val_loss: 1776523392.0000\n",
      "Epoch 626/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 869948480.0000 - val_loss: 1737335168.0000\n",
      "Epoch 627/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 874187136.0000 - val_loss: 1740590080.0000\n",
      "Epoch 628/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 880221824.0000 - val_loss: 1770039808.0000\n",
      "Epoch 629/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 857523328.0000 - val_loss: 1668105088.0000\n",
      "Epoch 630/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 860611072.0000 - val_loss: 1681563520.0000\n",
      "Epoch 631/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 865025600.0000 - val_loss: 1683539456.0000\n",
      "Epoch 632/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 862476608.0000 - val_loss: 1677277312.0000\n",
      "Epoch 633/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 864585088.0000 - val_loss: 1774478208.0000\n",
      "Epoch 634/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 862127872.0000 - val_loss: 1642886528.0000\n",
      "Epoch 635/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 857181952.0000 - val_loss: 1647256192.0000\n",
      "Epoch 636/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 864772224.0000 - val_loss: 1653584512.0000\n",
      "Epoch 637/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 849576768.0000 - val_loss: 1662881920.0000\n",
      "Epoch 638/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 853620096.0000 - val_loss: 1645796736.0000\n",
      "Epoch 639/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 859089856.0000 - val_loss: 1627379328.0000\n",
      "Epoch 640/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 855610432.0000 - val_loss: 1681501568.0000\n",
      "Epoch 641/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 857277504.0000 - val_loss: 1646989056.0000\n",
      "Epoch 642/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 859663872.0000 - val_loss: 1697286400.0000\n",
      "Epoch 643/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 868076736.0000 - val_loss: 1594841344.0000\n",
      "Epoch 644/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 855911296.0000 - val_loss: 1640345984.0000\n",
      "Epoch 645/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 851801536.0000 - val_loss: 1583277952.0000\n",
      "Epoch 646/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 848989120.0000 - val_loss: 1594044800.0000\n",
      "Epoch 647/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 836593792.0000 - val_loss: 1633990144.0000\n",
      "Epoch 648/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 841878528.0000 - val_loss: 1593647616.0000\n",
      "Epoch 649/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 843664320.0000 - val_loss: 1639435136.0000\n",
      "Epoch 650/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 843562688.0000 - val_loss: 1570424704.0000\n",
      "Epoch 651/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 833103232.0000 - val_loss: 1588581504.0000\n",
      "Epoch 652/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 839029696.0000 - val_loss: 1580433920.0000\n",
      "Epoch 653/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 825004736.0000 - val_loss: 1593178880.0000\n",
      "Epoch 654/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 829771264.0000 - val_loss: 1588140928.0000\n",
      "Epoch 655/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 822924864.0000 - val_loss: 1657039104.0000\n",
      "Epoch 656/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 827263360.0000 - val_loss: 1557561472.0000\n",
      "Epoch 657/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 844834688.0000 - val_loss: 1573247104.0000\n",
      "Epoch 658/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 825081472.0000 - val_loss: 1534870400.0000\n",
      "Epoch 659/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 845056192.0000 - val_loss: 1553216000.0000\n",
      "Epoch 660/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 821337280.0000 - val_loss: 1553407232.0000\n",
      "Epoch 661/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 815041600.0000 - val_loss: 1641554304.0000\n",
      "Epoch 662/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 826343360.0000 - val_loss: 1617019776.0000\n",
      "Epoch 663/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 819100224.0000 - val_loss: 1576742528.0000\n",
      "Epoch 664/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 824693120.0000 - val_loss: 1567015808.0000\n",
      "Epoch 665/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 811274048.0000 - val_loss: 1550943104.0000\n",
      "Epoch 666/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 810919104.0000 - val_loss: 1562976256.0000\n",
      "Epoch 667/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 816354752.0000 - val_loss: 1620633984.0000\n",
      "Epoch 668/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 815546496.0000 - val_loss: 1545051008.0000\n",
      "Epoch 669/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 815287104.0000 - val_loss: 1540638720.0000\n",
      "Epoch 670/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 814829312.0000 - val_loss: 1534361344.0000\n",
      "Epoch 671/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 814154048.0000 - val_loss: 1567163136.0000\n",
      "Epoch 672/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 802805568.0000 - val_loss: 1541697408.0000\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 3ms/step - loss: 802422976.0000 - val_loss: 1493560064.0000\n",
      "Epoch 674/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 806987840.0000 - val_loss: 1498853632.0000\n",
      "Epoch 675/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 801433792.0000 - val_loss: 1486947840.0000\n",
      "Epoch 676/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 818112384.0000 - val_loss: 1563740032.0000\n",
      "Epoch 677/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 800298880.0000 - val_loss: 1544203392.0000\n",
      "Epoch 678/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 825998720.0000 - val_loss: 1589574784.0000\n",
      "Epoch 679/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 806656448.0000 - val_loss: 1467818624.0000\n",
      "Epoch 680/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 790740352.0000 - val_loss: 1558065152.0000\n",
      "Epoch 681/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 799400128.0000 - val_loss: 1452467968.0000\n",
      "Epoch 682/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 797583552.0000 - val_loss: 1468544768.0000\n",
      "Epoch 683/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 787852416.0000 - val_loss: 1485622784.0000\n",
      "Epoch 684/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 808100608.0000 - val_loss: 1476159616.0000\n",
      "Epoch 685/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 787606336.0000 - val_loss: 1554300032.0000\n",
      "Epoch 686/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 800294144.0000 - val_loss: 1469553536.0000\n",
      "Epoch 687/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 798415488.0000 - val_loss: 1460836608.0000\n",
      "Epoch 688/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 791280192.0000 - val_loss: 1453731712.0000\n",
      "Epoch 689/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 791047552.0000 - val_loss: 1433904768.0000\n",
      "Epoch 690/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 789470848.0000 - val_loss: 1453076352.0000\n",
      "Epoch 691/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 774705216.0000 - val_loss: 1439126144.0000\n",
      "Epoch 692/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 790705280.0000 - val_loss: 1449932032.0000\n",
      "Epoch 693/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 787499136.0000 - val_loss: 1424398720.0000\n",
      "Epoch 694/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 786734464.0000 - val_loss: 1446407168.0000\n",
      "Epoch 695/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 785022272.0000 - val_loss: 1477810560.0000\n",
      "Epoch 696/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 786233984.0000 - val_loss: 1432977792.0000\n",
      "Epoch 697/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 781704960.0000 - val_loss: 1420034432.0000\n",
      "Epoch 698/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 773935424.0000 - val_loss: 1413571072.0000\n",
      "Epoch 699/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 769551232.0000 - val_loss: 1423693312.0000\n",
      "Epoch 700/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 773339520.0000 - val_loss: 1390377728.0000\n",
      "Epoch 701/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 782207552.0000 - val_loss: 1448609280.0000\n",
      "Epoch 702/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 802167168.0000 - val_loss: 1410247040.0000\n",
      "Epoch 703/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 770785408.0000 - val_loss: 1425513216.0000\n",
      "Epoch 704/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 755306496.0000 - val_loss: 1443440256.0000\n",
      "Epoch 705/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 769896960.0000 - val_loss: 1352715776.0000\n",
      "Epoch 706/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 786261696.0000 - val_loss: 1447425408.0000\n",
      "Epoch 707/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 765219072.0000 - val_loss: 1359368320.0000\n",
      "Epoch 708/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 770407104.0000 - val_loss: 1386796160.0000\n",
      "Epoch 709/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 761848640.0000 - val_loss: 1336086656.0000\n",
      "Epoch 710/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 766800832.0000 - val_loss: 1340753792.0000\n",
      "Epoch 711/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 756401792.0000 - val_loss: 1362994944.0000\n",
      "Epoch 712/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 779984832.0000 - val_loss: 1325259392.0000\n",
      "Epoch 713/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 768983296.0000 - val_loss: 1329746944.0000\n",
      "Epoch 714/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 753110784.0000 - val_loss: 1398042752.0000\n",
      "Epoch 715/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 798041664.0000 - val_loss: 1425881600.0000\n",
      "Epoch 716/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 761760832.0000 - val_loss: 1325059072.0000\n",
      "Epoch 717/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 762864320.0000 - val_loss: 1341925632.0000\n",
      "Epoch 718/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 750463040.0000 - val_loss: 1393820032.0000\n",
      "Epoch 719/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 751970432.0000 - val_loss: 1328411776.0000\n",
      "Epoch 720/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 760003904.0000 - val_loss: 1345420416.0000\n",
      "Epoch 721/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 753045952.0000 - val_loss: 1470595584.0000\n",
      "Epoch 722/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 751989504.0000 - val_loss: 1317704704.0000\n",
      "Epoch 723/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 750461888.0000 - val_loss: 1358171392.0000\n",
      "Epoch 724/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 756547584.0000 - val_loss: 1310503296.0000\n",
      "Epoch 725/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 746206656.0000 - val_loss: 1367508864.0000\n",
      "Epoch 726/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 744725376.0000 - val_loss: 1311475968.0000\n",
      "Epoch 727/1000\n",
      "116/116 [==============================] - ETA: 0s - loss: 728033856.000 - 0s 1ms/step - loss: 737640384.0000 - val_loss: 1331505792.0000\n",
      "Epoch 728/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 764736000.0000 - val_loss: 1305655296.0000\n",
      "Epoch 729/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 731425792.0000 - val_loss: 1268829312.0000\n",
      "Epoch 730/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 721642112.0000 - val_loss: 1335536128.0000\n",
      "Epoch 731/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 731562112.0000 - val_loss: 1371769728.0000\n",
      "Epoch 732/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 743797504.0000 - val_loss: 1277523072.0000\n",
      "Epoch 733/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 734029888.0000 - val_loss: 1319984256.0000\n",
      "Epoch 734/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 740658816.0000 - val_loss: 1289291008.0000\n",
      "Epoch 735/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 732470272.0000 - val_loss: 1263842944.0000\n",
      "Epoch 736/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 732445632.0000 - val_loss: 1316414592.0000\n",
      "Epoch 737/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 737653120.0000 - val_loss: 1242836992.0000\n",
      "Epoch 738/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 738834560.0000 - val_loss: 1289501696.0000\n",
      "Epoch 739/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 724897280.0000 - val_loss: 1332909696.0000\n",
      "Epoch 740/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 4ms/step - loss: 734733696.0000 - val_loss: 1283342720.0000\n",
      "Epoch 741/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 726554048.0000 - val_loss: 1315196032.0000\n",
      "Epoch 742/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 725888320.0000 - val_loss: 1276239872.0000\n",
      "Epoch 743/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 719030464.0000 - val_loss: 1283664128.0000\n",
      "Epoch 744/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 729453504.0000 - val_loss: 1256291840.0000\n",
      "Epoch 745/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 746126144.0000 - val_loss: 1255379456.0000\n",
      "Epoch 746/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 717313344.0000 - val_loss: 1238086144.0000\n",
      "Epoch 747/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 728093888.0000 - val_loss: 1229637120.0000\n",
      "Epoch 748/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 719784256.0000 - val_loss: 1289288704.0000\n",
      "Epoch 749/1000\n",
      "116/116 [==============================] - ETA: 0s - loss: 679386816.000 - 0s 1ms/step - loss: 715774208.0000 - val_loss: 1257158784.0000\n",
      "Epoch 750/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 712275648.0000 - val_loss: 1261717376.0000\n",
      "Epoch 751/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 725894976.0000 - val_loss: 1336715392.0000\n",
      "Epoch 752/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 711984960.0000 - val_loss: 1308420352.0000\n",
      "Epoch 753/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 720010432.0000 - val_loss: 1253612288.0000\n",
      "Epoch 754/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 713361472.0000 - val_loss: 1226770304.0000\n",
      "Epoch 755/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 707305728.0000 - val_loss: 1398953472.0000\n",
      "Epoch 756/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 716506688.0000 - val_loss: 1367851136.0000\n",
      "Epoch 757/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 701606848.0000 - val_loss: 1191951104.0000\n",
      "Epoch 758/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 697769216.0000 - val_loss: 1211473536.0000\n",
      "Epoch 759/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 704331776.0000 - val_loss: 1174071552.0000\n",
      "Epoch 760/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 717575552.0000 - val_loss: 1424708224.0000\n",
      "Epoch 761/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 707404160.0000 - val_loss: 1203680896.0000\n",
      "Epoch 762/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 691339136.0000 - val_loss: 1204009856.0000\n",
      "Epoch 763/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 698398336.0000 - val_loss: 1173386368.0000\n",
      "Epoch 764/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 695652864.0000 - val_loss: 1190286720.0000\n",
      "Epoch 765/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 701898112.0000 - val_loss: 1191303040.0000\n",
      "Epoch 766/1000\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 704155520.0000 - val_loss: 1219722368.0000\n",
      "Epoch 767/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 690560064.0000 - val_loss: 1221129088.0000\n",
      "Epoch 768/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 697617280.0000 - val_loss: 1147071232.0000\n",
      "Epoch 769/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 707204800.0000 - val_loss: 1250223488.0000\n",
      "Epoch 770/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 676746176.0000 - val_loss: 1170944384.0000\n",
      "Epoch 771/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 673371584.0000 - val_loss: 1119545984.0000\n",
      "Epoch 772/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 699442048.0000 - val_loss: 1143929344.0000\n",
      "Epoch 773/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 686791616.0000 - val_loss: 1149294080.0000\n",
      "Epoch 774/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 691043520.0000 - val_loss: 1158509184.0000\n",
      "Epoch 775/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 686383808.0000 - val_loss: 1116589440.0000\n",
      "Epoch 776/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 674150720.0000 - val_loss: 1126147200.0000\n",
      "Epoch 777/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 675478336.0000 - val_loss: 1144587392.0000\n",
      "Epoch 778/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 678800064.0000 - val_loss: 1169607424.0000\n",
      "Epoch 779/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 675126080.0000 - val_loss: 1140971008.0000\n",
      "Epoch 780/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 685780224.0000 - val_loss: 1172743424.0000\n",
      "Epoch 781/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 672395392.0000 - val_loss: 1131316608.0000\n",
      "Epoch 782/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 678332992.0000 - val_loss: 1159902080.0000\n",
      "Epoch 783/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 663877632.0000 - val_loss: 1121105152.0000\n",
      "Epoch 784/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 691573312.0000 - val_loss: 1111220352.0000\n",
      "Epoch 785/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 662276928.0000 - val_loss: 1204402176.0000\n",
      "Epoch 786/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 669243968.0000 - val_loss: 1127995776.0000\n",
      "Epoch 787/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 661795520.0000 - val_loss: 1105008256.0000\n",
      "Epoch 788/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 660765824.0000 - val_loss: 1087370240.0000\n",
      "Epoch 789/1000\n",
      "116/116 [==============================] - ETA: 0s - loss: 670790912.000 - 0s 1ms/step - loss: 662327616.0000 - val_loss: 1076331776.0000\n",
      "Epoch 790/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 649269376.0000 - val_loss: 1091183232.0000\n",
      "Epoch 791/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 688535872.0000 - val_loss: 1127025280.0000\n",
      "Epoch 792/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 663555904.0000 - val_loss: 1159213696.0000\n",
      "Epoch 793/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 650925760.0000 - val_loss: 1064363392.0000\n",
      "Epoch 794/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 664361024.0000 - val_loss: 1077557248.0000\n",
      "Epoch 795/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 672524288.0000 - val_loss: 1122994048.0000\n",
      "Epoch 796/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 650794112.0000 - val_loss: 1097020416.0000\n",
      "Epoch 797/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 654588736.0000 - val_loss: 1073085760.0000\n",
      "Epoch 798/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 671504448.0000 - val_loss: 1088459904.0000\n",
      "Epoch 799/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 658045696.0000 - val_loss: 1102017152.0000\n",
      "Epoch 800/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 661438912.0000 - val_loss: 1096174976.0000\n",
      "Epoch 801/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 662082496.0000 - val_loss: 1046144320.0000\n",
      "Epoch 802/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 670382464.0000 - val_loss: 1095701504.0000\n",
      "Epoch 803/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 642964480.0000 - val_loss: 1060470464.0000\n",
      "Epoch 804/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 648620736.0000 - val_loss: 1114047744.0000\n",
      "Epoch 805/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 642864896.0000 - val_loss: 1048778368.0000\n",
      "Epoch 806/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 655906432.0000 - val_loss: 1094111872.0000\n",
      "Epoch 807/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 1ms/step - loss: 651450880.0000 - val_loss: 1033273024.0000\n",
      "Epoch 808/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 642805120.0000 - val_loss: 1043860096.0000\n",
      "Epoch 809/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 634530752.0000 - val_loss: 1040040320.0000\n",
      "Epoch 810/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 655017792.0000 - val_loss: 1034404672.0000\n",
      "Epoch 811/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 645541568.0000 - val_loss: 1043792448.0000\n",
      "Epoch 812/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 659621312.0000 - val_loss: 1025108160.0000\n",
      "Epoch 813/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 644812416.0000 - val_loss: 1059877440.0000\n",
      "Epoch 814/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 649359616.0000 - val_loss: 1036313472.0000\n",
      "Epoch 815/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 642452736.0000 - val_loss: 1038758208.0000\n",
      "Epoch 816/1000\n",
      "116/116 [==============================] - 1s 4ms/step - loss: 628356672.0000 - val_loss: 1025738752.0000\n",
      "Epoch 817/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 633688512.0000 - val_loss: 1023004928.0000\n",
      "Epoch 818/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 638730560.0000 - val_loss: 1116378112.0000\n",
      "Epoch 819/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 637920704.0000 - val_loss: 1044364672.0000\n",
      "Epoch 820/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 626882368.0000 - val_loss: 1001424896.0000\n",
      "Epoch 821/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 653735808.0000 - val_loss: 1018110208.0000\n",
      "Epoch 822/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 630341312.0000 - val_loss: 1027904320.0000\n",
      "Epoch 823/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 636385088.0000 - val_loss: 1057894144.0000\n",
      "Epoch 824/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 631601472.0000 - val_loss: 1000050432.0000\n",
      "Epoch 825/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 624539648.0000 - val_loss: 1030208896.0000\n",
      "Epoch 826/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 622034176.0000 - val_loss: 1053224192.0000\n",
      "Epoch 827/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 621817664.0000 - val_loss: 1024111616.0000\n",
      "Epoch 828/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 618618624.0000 - val_loss: 983619776.0000\n",
      "Epoch 829/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 623190400.0000 - val_loss: 1030713152.0000\n",
      "Epoch 830/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 627451264.0000 - val_loss: 1015699200.0000\n",
      "Epoch 831/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 614314816.0000 - val_loss: 1006261248.0000\n",
      "Epoch 832/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 619631808.0000 - val_loss: 1023946496.0000\n",
      "Epoch 833/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 661999104.0000 - val_loss: 987338944.0000\n",
      "Epoch 834/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 634532352.0000 - val_loss: 1027043584.0000\n",
      "Epoch 835/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 631421632.0000 - val_loss: 1006979584.0000\n",
      "Epoch 836/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 626219200.0000 - val_loss: 984568256.0000\n",
      "Epoch 837/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 626165120.0000 - val_loss: 991267008.0000\n",
      "Epoch 838/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 621830336.0000 - val_loss: 1024006976.0000\n",
      "Epoch 839/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 615261568.0000 - val_loss: 1077932416.0000\n",
      "Epoch 840/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 613784576.0000 - val_loss: 993259328.0000\n",
      "Epoch 841/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 616098560.0000 - val_loss: 975034688.0000\n",
      "Epoch 842/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 635096576.0000 - val_loss: 1078235648.0000\n",
      "Epoch 843/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 610898048.0000 - val_loss: 1087727872.0000\n",
      "Epoch 844/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 623642048.0000 - val_loss: 1012374464.0000\n",
      "Epoch 845/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 625518144.0000 - val_loss: 990860160.0000\n",
      "Epoch 846/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 610443712.0000 - val_loss: 969762624.0000\n",
      "Epoch 847/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 603320576.0000 - val_loss: 979998208.0000\n",
      "Epoch 848/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 606233792.0000 - val_loss: 1007719808.0000\n",
      "Epoch 849/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 610308544.0000 - val_loss: 1018467968.0000\n",
      "Epoch 850/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 606468864.0000 - val_loss: 985808640.0000\n",
      "Epoch 851/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 607739200.0000 - val_loss: 983388992.0000\n",
      "Epoch 852/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 598169792.0000 - val_loss: 946647808.0000\n",
      "Epoch 853/1000\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 593172928.0000 - val_loss: 938060800.0000\n",
      "Epoch 854/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 612524736.0000 - val_loss: 965604864.0000\n",
      "Epoch 855/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 603139584.0000 - val_loss: 964865920.0000\n",
      "Epoch 856/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 602507456.0000 - val_loss: 949820544.0000\n",
      "Epoch 857/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 594430592.0000 - val_loss: 1006050560.0000\n",
      "Epoch 858/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 615296704.0000 - val_loss: 1007119424.0000\n",
      "Epoch 859/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 621419712.0000 - val_loss: 994841088.0000\n",
      "Epoch 860/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 591083200.0000 - val_loss: 956493888.0000\n",
      "Epoch 861/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 598886400.0000 - val_loss: 963077888.0000\n",
      "Epoch 862/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 600442752.0000 - val_loss: 976559936.0000\n",
      "Epoch 863/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 588796480.0000 - val_loss: 948920832.0000\n",
      "Epoch 864/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 588232000.0000 - val_loss: 979301888.0000\n",
      "Epoch 865/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 601388032.0000 - val_loss: 998453248.0000\n",
      "Epoch 866/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 587412224.0000 - val_loss: 993422272.0000\n",
      "Epoch 867/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 605260672.0000 - val_loss: 943768832.0000\n",
      "Epoch 868/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 593272128.0000 - val_loss: 977646208.0000\n",
      "Epoch 869/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 600536064.0000 - val_loss: 968773440.0000\n",
      "Epoch 870/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 584993408.0000 - val_loss: 929534208.0000\n",
      "Epoch 871/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 578095360.0000 - val_loss: 936985920.0000\n",
      "Epoch 872/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 586305280.0000 - val_loss: 958480768.0000\n",
      "Epoch 873/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 589877568.0000 - val_loss: 964755712.0000\n",
      "Epoch 874/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 595510080.0000 - val_loss: 948539904.0000\n",
      "Epoch 875/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 576794432.0000 - val_loss: 945742784.0000\n",
      "Epoch 876/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 588237824.0000 - val_loss: 958260736.0000\n",
      "Epoch 877/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 589675456.0000 - val_loss: 973905600.0000\n",
      "Epoch 878/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 589640896.0000 - val_loss: 949019968.0000\n",
      "Epoch 879/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 586141376.0000 - val_loss: 949591424.0000\n",
      "Epoch 880/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 578008256.0000 - val_loss: 933672896.0000\n",
      "Epoch 881/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 577040192.0000 - val_loss: 951252480.0000\n",
      "Epoch 882/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 573504064.0000 - val_loss: 1038180416.0000\n",
      "Epoch 883/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 584795648.0000 - val_loss: 922330816.0000\n",
      "Epoch 884/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 565008704.0000 - val_loss: 958008192.0000\n",
      "Epoch 885/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 570993920.0000 - val_loss: 955692224.0000\n",
      "Epoch 886/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 584735744.0000 - val_loss: 965102976.0000\n",
      "Epoch 887/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 575907968.0000 - val_loss: 963551936.0000\n",
      "Epoch 888/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 577989248.0000 - val_loss: 929455104.0000\n",
      "Epoch 889/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 593869440.0000 - val_loss: 923888448.0000\n",
      "Epoch 890/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 586310912.0000 - val_loss: 913859200.0000\n",
      "Epoch 891/1000\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 578266816.0000 - val_loss: 967639296.0000\n",
      "Epoch 892/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 578575488.0000 - val_loss: 920706240.0000\n",
      "Epoch 893/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 563453760.0000 - val_loss: 1019350912.0000\n",
      "Epoch 894/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 566179904.0000 - val_loss: 942029568.0000\n",
      "Epoch 895/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 584163136.0000 - val_loss: 921248000.0000\n",
      "Epoch 896/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 582011136.0000 - val_loss: 978107136.0000\n",
      "Epoch 897/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 570854400.0000 - val_loss: 971482496.0000\n",
      "Epoch 898/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 568237632.0000 - val_loss: 942410624.0000\n",
      "Epoch 899/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 577580800.0000 - val_loss: 929767040.0000\n",
      "Epoch 900/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 562618304.0000 - val_loss: 923113088.0000\n",
      "Epoch 901/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 562603648.0000 - val_loss: 944092992.0000\n",
      "Epoch 902/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 566307712.0000 - val_loss: 970674880.0000\n",
      "Epoch 903/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 547046656.0000 - val_loss: 924637056.0000\n",
      "Epoch 904/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 576148736.0000 - val_loss: 898117760.0000\n",
      "Epoch 905/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 572802176.0000 - val_loss: 946489472.0000\n",
      "Epoch 906/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 572801216.0000 - val_loss: 920456704.0000\n",
      "Epoch 907/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 560344128.0000 - val_loss: 906504640.0000\n",
      "Epoch 908/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 547684352.0000 - val_loss: 977083648.0000\n",
      "Epoch 909/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 552644352.0000 - val_loss: 982411584.0000\n",
      "Epoch 910/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 569388160.0000 - val_loss: 890916288.0000\n",
      "Epoch 911/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 546961792.0000 - val_loss: 944206912.0000\n",
      "Epoch 912/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 554833280.0000 - val_loss: 908608192.0000\n",
      "Epoch 913/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 578768384.0000 - val_loss: 945110208.0000\n",
      "Epoch 914/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 544408640.0000 - val_loss: 905544448.0000\n",
      "Epoch 915/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 552357056.0000 - val_loss: 896601280.0000\n",
      "Epoch 916/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 562267520.0000 - val_loss: 917461440.0000\n",
      "Epoch 917/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 547544832.0000 - val_loss: 915732288.0000\n",
      "Epoch 918/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 552074560.0000 - val_loss: 919082176.0000\n",
      "Epoch 919/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 558870464.0000 - val_loss: 890905792.0000\n",
      "Epoch 920/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 536061152.0000 - val_loss: 906620096.0000\n",
      "Epoch 921/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 547286784.0000 - val_loss: 942199104.0000\n",
      "Epoch 922/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 556211840.0000 - val_loss: 902590720.0000\n",
      "Epoch 923/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 539460800.0000 - val_loss: 884416960.0000\n",
      "Epoch 924/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 549608640.0000 - val_loss: 971226496.0000\n",
      "Epoch 925/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 550193280.0000 - val_loss: 918214400.0000\n",
      "Epoch 926/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 546767808.0000 - val_loss: 899520960.0000\n",
      "Epoch 927/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 545003968.0000 - val_loss: 895017344.0000\n",
      "Epoch 928/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 550500352.0000 - val_loss: 907150016.0000\n",
      "Epoch 929/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 555067200.0000 - val_loss: 902138112.0000\n",
      "Epoch 930/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 553601728.0000 - val_loss: 948462784.0000\n",
      "Epoch 931/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 535694080.0000 - val_loss: 921548800.0000\n",
      "Epoch 932/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 545003904.0000 - val_loss: 1004963712.0000\n",
      "Epoch 933/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 567205184.0000 - val_loss: 906488704.0000\n",
      "Epoch 934/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 534152416.0000 - val_loss: 933987456.0000\n",
      "Epoch 935/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 551698304.0000 - val_loss: 920609664.0000\n",
      "Epoch 936/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 544805824.0000 - val_loss: 912235776.0000\n",
      "Epoch 937/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 551070720.0000 - val_loss: 893209344.0000\n",
      "Epoch 938/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 529889056.0000 - val_loss: 888101504.0000\n",
      "Epoch 939/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 538999872.0000 - val_loss: 957834112.0000\n",
      "Epoch 940/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 545676288.0000 - val_loss: 970142592.0000\n",
      "Epoch 941/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 529693184.0000 - val_loss: 904757056.0000\n",
      "Epoch 942/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 541592704.0000 - val_loss: 992056128.0000\n",
      "Epoch 943/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 554012800.0000 - val_loss: 906507840.0000\n",
      "Epoch 944/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 532647808.0000 - val_loss: 894742208.0000\n",
      "Epoch 945/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 534688288.0000 - val_loss: 958934912.0000\n",
      "Epoch 946/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 557579712.0000 - val_loss: 1004449472.0000\n",
      "Epoch 947/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 526044352.0000 - val_loss: 924033152.0000\n",
      "Epoch 948/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 544766784.0000 - val_loss: 927596992.0000\n",
      "Epoch 949/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 537484096.0000 - val_loss: 1029637888.0000\n",
      "Epoch 950/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 541148864.0000 - val_loss: 913912448.0000\n",
      "Epoch 951/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 522163968.0000 - val_loss: 927502272.0000\n",
      "Epoch 952/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 534110080.0000 - val_loss: 920510976.0000\n",
      "Epoch 953/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 522471360.0000 - val_loss: 907739968.0000\n",
      "Epoch 954/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 519774944.0000 - val_loss: 893074432.0000\n",
      "Epoch 955/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 526470304.0000 - val_loss: 921013952.0000\n",
      "Epoch 956/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 535019520.0000 - val_loss: 908055296.0000\n",
      "Epoch 957/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 520455456.0000 - val_loss: 936728960.0000\n",
      "Epoch 958/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 513104608.0000 - val_loss: 943358400.0000\n",
      "Epoch 959/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 516795872.0000 - val_loss: 920201408.0000\n",
      "Epoch 960/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 535643520.0000 - val_loss: 915441024.0000\n",
      "Epoch 961/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 511123744.0000 - val_loss: 996106688.0000\n",
      "Epoch 962/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 534283264.0000 - val_loss: 898533888.0000\n",
      "Epoch 963/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 537690304.0000 - val_loss: 905583808.0000\n",
      "Epoch 964/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 515731936.0000 - val_loss: 907295424.0000\n",
      "Epoch 965/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 524373472.0000 - val_loss: 900344960.0000\n",
      "Epoch 966/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 535483968.0000 - val_loss: 929128064.0000\n",
      "Epoch 967/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 525084768.0000 - val_loss: 909262592.0000\n",
      "Epoch 968/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 520184992.0000 - val_loss: 909923200.0000\n",
      "Epoch 969/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 513196640.0000 - val_loss: 927380992.0000\n",
      "Epoch 970/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 540488192.0000 - val_loss: 916186432.0000\n",
      "Epoch 971/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 508732000.0000 - val_loss: 896888192.0000\n",
      "Epoch 972/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 536617344.0000 - val_loss: 928541312.0000\n",
      "Epoch 973/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 511232384.0000 - val_loss: 934289856.0000\n",
      "Epoch 974/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 529191008.0000 - val_loss: 942269952.0000\n",
      "Epoch 975/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 515009920.0000 - val_loss: 969598144.0000\n",
      "Epoch 976/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 518389632.0000 - val_loss: 955993024.0000\n",
      "Epoch 977/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 498642848.0000 - val_loss: 903155712.0000\n",
      "Epoch 978/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 513943712.0000 - val_loss: 915059648.0000\n",
      "Epoch 979/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 509932288.0000 - val_loss: 912322880.0000\n",
      "Epoch 980/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 496243104.0000 - val_loss: 912136768.0000\n",
      "Epoch 981/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 552413632.0000 - val_loss: 999985664.0000\n",
      "Epoch 982/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 503822848.0000 - val_loss: 941995968.0000\n",
      "Epoch 983/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 501620800.0000 - val_loss: 900726976.0000\n",
      "Epoch 984/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 503526304.0000 - val_loss: 949258432.0000\n",
      "Epoch 985/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 508125056.0000 - val_loss: 918062656.0000\n",
      "Epoch 986/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 507884736.0000 - val_loss: 905547648.0000\n",
      "Epoch 987/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 494227648.0000 - val_loss: 915624960.0000\n",
      "Epoch 988/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 494183232.0000 - val_loss: 917423936.0000\n",
      "Epoch 989/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 505164704.0000 - val_loss: 1045637440.0000\n",
      "Epoch 990/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 518031392.0000 - val_loss: 952572736.0000\n",
      "Epoch 991/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 506200064.0000 - val_loss: 920853504.0000\n",
      "Epoch 992/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 502288704.0000 - val_loss: 917953344.0000\n",
      "Epoch 993/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 512418976.0000 - val_loss: 897970176.0000\n",
      "Epoch 994/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 515360288.0000 - val_loss: 907428928.0000\n",
      "Epoch 995/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 491990208.0000 - val_loss: 919998080.0000\n",
      "Epoch 996/1000\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 488445184.0000 - val_loss: 965516992.0000\n",
      "Epoch 997/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 492386208.0000 - val_loss: 953979072.0000\n",
      "Epoch 998/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 508471168.0000 - val_loss: 943249792.0000\n",
      "Epoch 999/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 498942560.0000 - val_loss: 942590272.0000\n",
      "Epoch 1000/1000\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 508584960.0000 - val_loss: 1092634624.0000\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from numpy.random import seed\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(50, kernel_initializer = 'he_uniform',activation='relu',input_dim = X_train.shape[1]))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense( 25, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense( 50, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense( 1, kernel_initializer = 'he_uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss='mean_squared_error', optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, y_train.values, validation_split=0.20, batch_size = 10, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=classifier.predict(df_test_new.drop(['SalePrice'],axis=1).values)\n",
    "y_pred=classifier.predict(df_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[194835.03],\n",
       "       [168613.34],\n",
       "       [288248.7 ],\n",
       "       ...,\n",
       "       [341344.62],\n",
       "       [283259.7 ],\n",
       "       [427212.56]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot training and validation loss values\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(y_pred)\n",
    "\n",
    "\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
